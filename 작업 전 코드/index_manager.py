#!/usr/bin/env python3
"""
ë²¼ë¦¬í†¡@ê²½ìƒë‚¨ë„ì¸ì¬ê°œë°œì› (ê²½ìƒë‚¨ë„ì¸ì¬ê°œë°œì› RAG ì±—ë´‡) - index_manager.py (OpenAI í˜¸í™˜ì„± ìˆ˜ì • ë²„ì „)

IndexManager ì‹±ê¸€í†¤: ëª¨ë“  ë²¡í„°ìŠ¤í† ì–´ ì¤‘ì•™ ê´€ë¦¬
- ì•± ê¸°ë™ ì‹œ ëª¨ë“  FAISS ì¸ë±ìŠ¤ ì‚¬ì „ ë¡œë“œ
- ì €ì¥ëœ BM25 íŒŒì¼ ë¡œë“œ
- í•´ì‹œ ê¸°ë°˜ íŒŒì¼ ë³€ê²½ ê°ì§€ë¡œ í•«ìŠ¤ì™‘
- ì „ì—­ ê³µìœ ë¡œ í•¸ë“¤ëŸ¬ ê°„ ì¼ê´€ì„± ë³´ì¥
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë‹¨ì¼ ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬

ğŸš¨ ì£¼ìš” ìˆ˜ì •ì‚¬í•­:
âœ… OpenAIEmbeddings ì´ˆê¸°í™” ë°©ì‹ ìˆ˜ì • (í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°)
âœ… API í‚¤ ëª…ì‹œì  ì „ë‹¬
âœ… Graceful Degradation ì ìš©
âœ… ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”
"""

import hashlib
import logging
import threading
import time
import pickle
import traceback
from pathlib import Path
from typing import Dict, Optional, Any, List, Tuple
from datetime import datetime
from dataclasses import dataclass, field

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ
from utils.config import config
from utils.contracts import HandlerType
from utils.textifier import TextChunk

# ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬
from langchain_community.vectorstores import FAISS
from rank_bm25 import BM25Okapi
import numpy as np

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# ================================================================
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
# ================================================================
try:
    ROOT_DIR = Path(__file__).parent.parent.absolute()
except NameError:
    ROOT_DIR = Path(".").absolute()

# ================================================================
# 1. ë²¡í„°ìŠ¤í† ì–´ ë©”íƒ€ë°ì´í„° í´ë˜ìŠ¤
# ================================================================

@dataclass
class VectorStoreMetadata:
    """
    ë²¡í„°ìŠ¤í† ì–´ ë©”íƒ€ë°ì´í„° ë° ìƒíƒœ ê´€ë¦¬ (BM25 íŒŒì¼ ì§€ì›)
    """
    domain: str
    vectorstore_base_dir: Path
    
    # post_initì—ì„œ ì„¤ì •ë˜ë¯€ë¡œ init=Falseë¡œ ì„¤ì •
    vectorstore_path: Path = field(init=False)
    faiss_path: Path = field(init=False)
    pkl_path: Path = field(init=False)
    bm25_path: Path = field(init=False)
    
    # ëŸ°íƒ€ì„ ì†ì„±
    embeddings: Optional[Any] = None  # OpenAIEmbeddings íƒ€ì… íŒíŠ¸ ì œê±°
    vectorstore: Optional[FAISS] = None
    bm25: Optional[BM25Okapi] = None
    documents: List[TextChunk] = field(default_factory=list)
    last_loaded: Optional[datetime] = None
    load_count: int = 0
    error_count: int = 0
    last_hash: Optional[str] = None
    
    def __post_init__(self):
        # data_ingestion.pyì™€ ë™ì¼í•œ ê²½ë¡œ ë§¤í•‘ ì‚¬ìš©
        self.vectorstore_path = self._get_vectorstore_path()
        self.faiss_path = self.vectorstore_path / f"{self.domain}_index.faiss"
        self.pkl_path = self.vectorstore_path / f"{self.domain}_index.pkl"
        self.bm25_path = self.vectorstore_path / f"{self.domain}_index.bm25"
        
        # âœ… OpenAIEmbeddings ì•ˆì „í•œ ì´ˆê¸°í™”
        self.embeddings = self._init_embeddings()
    
    def _init_embeddings(self) -> Optional[Any]:
        """
        OpenAIEmbeddings ì•ˆì „í•œ ì´ˆê¸°í™” (í˜¸í™˜ì„± ìˆ˜ì •)
        """
        try:
            # LangChain OpenAI Embeddings í˜¸í™˜ì„± ìˆ˜ì •
            from langchain_openai import OpenAIEmbeddings
            
            # API í‚¤ í™•ì¸
            api_key = config.OPENAI_API_KEY
            if not api_key:
                logger.warning("âš ï¸ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ì„ë² ë”©ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            # ìµœì†Œí•œì˜ ë§¤ê°œë³€ìˆ˜ë¡œ ì•ˆì „í•œ ì´ˆê¸°í™” (proxies ì˜¤ë¥˜ ë°©ì§€)
            embeddings = OpenAIEmbeddings(
                api_key=api_key,
                model=config.EMBEDDING_MODEL
            )
            
            logger.debug(f"âœ… {self.domain} ë„ë©”ì¸ìš© OpenAIEmbeddings ì´ˆê¸°í™” ì™„ë£Œ")
            return embeddings
            
        except ImportError as e:
            logger.error(f"âŒ LangChain OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
            return None
        except Exception as e:
            logger.error(f"âŒ {self.domain} ë„ë©”ì¸ OpenAIEmbeddings ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return None
    
    def _get_vectorstore_path(self) -> Path:
        """ë„ë©”ì¸ë³„ ë²¡í„°ìŠ¤í† ì–´ ê²½ë¡œ ë§¤í•‘"""
        domain_mapping = {
            "course_satisfaction": "vectorstore_course_satisfaction",
            "subject_satisfaction": "vectorstore_subject_satisfaction", 
            "satisfaction": "vectorstore_unified_satisfaction",
            "publish": "vectorstore_unified_publish",
            "general": "vectorstore_general",
            "cyber": "vectorstore_cyber",
            "notice": "vectorstore_notice",
            "menu": "vectorstore_menu"
        }
        
        vectorstore_dir_name = domain_mapping.get(self.domain, f"vectorstore_{self.domain}")
        return self.vectorstore_base_dir / vectorstore_dir_name
    
    def exists(self) -> bool:
        """í•„ìˆ˜ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
        return (
            self.faiss_path.exists() and 
            self.pkl_path.exists() and
            self.vectorstore_path.exists()
        )
    
    def get_file_hash(self) -> str:
        """íŒŒì¼ ë³€ê²½ ê°ì§€ìš© í•´ì‹œ ê³„ì‚°"""
        try:
            if not self.exists():
                return ""
                
            hash_content = ""
            
            # FAISS íŒŒì¼ í•´ì‹œ
            if self.faiss_path.exists():
                hash_content += str(self.faiss_path.stat().st_mtime)
            
            # PKL íŒŒì¼ í•´ì‹œ
            if self.pkl_path.exists():
                hash_content += str(self.pkl_path.stat().st_mtime)
                
            # BM25 íŒŒì¼ í•´ì‹œ (ì„ íƒì )
            if self.bm25_path.exists():
                hash_content += str(self.bm25_path.stat().st_mtime)
            
            return hashlib.md5(hash_content.encode()).hexdigest()
        except Exception as e:
            logger.warning(f"âš ï¸ {self.domain} í•´ì‹œ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return ""

# ================================================================
# 2. IndexManager ì‹±ê¸€í†¤ í´ë˜ìŠ¤
# ================================================================

class IndexManager:
    """
    ëª¨ë“  ë²¡í„°ìŠ¤í† ì–´ë¥¼ ê´€ë¦¬í•˜ëŠ” ì‹±ê¸€í†¤ í´ë˜ìŠ¤ (OpenAI í˜¸í™˜ì„± ìˆ˜ì •)
    """
    _instance = None
    _instance_lock = threading.Lock()
    
    def __new__(cls):
        if cls._instance is None:
            with cls._instance_lock:
                if cls._instance is None:
                    cls._instance = super(IndexManager, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        if hasattr(self, '_initialized'):
            return
            
        self.metadata: Dict[str, VectorStoreMetadata] = {}
        
        # âœ… ê¸€ë¡œë²Œ OpenAIEmbeddings ì•ˆì „í•œ ì´ˆê¸°í™”
        self.embeddings = self._init_global_embeddings()
        
        for domain in config.HANDLERS:
            self.metadata[domain] = VectorStoreMetadata(
                domain=domain,
                vectorstore_base_dir=Path(config.VECTORSTORE_DIR)
            )
        
        logger.info(f"ğŸš€ IndexManager ì‹±ê¸€í†¤ ì´ˆê¸°í™” ì™„ë£Œ: {len(self.metadata)}ê°œ ë„ë©”ì¸")
        self.load_all_domains()
        self._initialized = True

    def _init_global_embeddings(self) -> Optional[Any]:
        """
        ê¸€ë¡œë²Œ OpenAIEmbeddings ì•ˆì „í•œ ì´ˆê¸°í™”
        """
        try:
            from langchain_openai import OpenAIEmbeddings
            
            api_key = config.OPENAI_API_KEY
            if not api_key:
                logger.warning("âš ï¸ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ì„ë² ë”© ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤.")
                return None
            
            embeddings = OpenAIEmbeddings(
                api_key=api_key,
                model=config.EMBEDDING_MODEL
            )
            
            logger.info(f"âœ… ê¸€ë¡œë²Œ OpenAIEmbeddings ì´ˆê¸°í™” ì™„ë£Œ: {config.EMBEDDING_MODEL}")
            return embeddings
            
        except ImportError as e:
            logger.error(f"âŒ LangChain OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
            logger.info("ğŸ”„ Graceful Degradation: ì„ë² ë”© ì—†ì´ ê¸°ë³¸ ê¸°ëŠ¥ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤.")
            return None
        except Exception as e:
            logger.error(f"âŒ ê¸€ë¡œë²Œ OpenAIEmbeddings ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            logger.info("ğŸ”„ Graceful Degradation: ì„ë² ë”© ì—†ì´ ê¸°ë³¸ ê¸°ëŠ¥ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤.")
            return None

    def _load_domain(self, domain: str):
        """
        ë‹¨ì¼ ë„ë©”ì¸ì˜ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ë¡œë“œ (pickle ìš°íšŒ ì „ëµ)
        """
        meta = self.metadata[domain]
        
        logger.info(f"ğŸ”„ ë„ë©”ì¸ {domain} ë¡œë“œ ì‹œì‘...")
        logger.debug(f"  - FAISS ê²½ë¡œ: {meta.faiss_path}")
        logger.debug(f"  - PKL ê²½ë¡œ: {meta.pkl_path}")
        logger.debug(f"  - BM25 ê²½ë¡œ: {meta.bm25_path}")
        
        try:
            if not meta.exists():
                logger.warning(f"âš ï¸ ë„ë©”ì¸ {domain}ì— í•„ìš”í•œ ì¸ë±ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¡œë“œ ê±´ë„ˆëœë‹ˆë‹¤.")
                meta.vectorstore = None
                meta.bm25 = None
                return
            
            start_time = time.time()
            
            # ì„ë² ë”© ëª¨ë¸ ì‚¬ìš© (ê¸€ë¡œë²Œ ë˜ëŠ” ë„ë©”ì¸ë³„)
            embeddings_to_use = meta.embeddings or self.embeddings
            if not embeddings_to_use:
                logger.warning(f"âš ï¸ {domain} ì„ë² ë”© ëª¨ë¸ì´ ì—†ì–´ FAISS ë¡œë“œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
                meta.vectorstore = None
            else:
                # FAISS ì¸ë±ìŠ¤ ë¡œë“œ
                meta.vectorstore = FAISS.load_local(
                    str(meta.vectorstore_path),
                    embeddings_to_use,
                    index_name=f"{domain}_index",
                    allow_dangerous_deserialization=True
                )
                logger.info(f"âœ… ë„ë©”ì¸ {domain} FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ")
            
            # âœ… í•µì‹¬ ë³€ê²½: pickle íŒŒì¼ì„ ì™„ì „íˆ ë¬´ì‹œí•˜ê³  FAISSì—ì„œë§Œ ë¡œë“œ
            meta.documents = []
            documents_loaded = False
            
            # ìœ ì¼í•œ ì „ëµ: FAISS docstoreì—ì„œë§Œ ë¡œë“œ (pickle ì™„ì „ ìš°íšŒ)
            if meta.vectorstore:
                logger.info(f"ğŸ”„ {domain} FAISS docstoreì—ì„œ ë¬¸ì„œ ì§ì ‘ ë¡œë“œ (pickle ìš°íšŒ)")
                try:
                    # FAISS ë‚´ë¶€ docstore ì§ì ‘ ì ‘ê·¼
                    raw_documents = list(meta.vectorstore.docstore._dict.values())
                    logger.info(f"ğŸ“„ {domain} FAISS docstoreì—ì„œ {len(raw_documents)}ê°œ ë¬¸ì„œ ë°œê²¬")
                    
                    for i, doc in enumerate(raw_documents):
                        try:
                            # LangChain Document â†’ TextChunk ì§ì ‘ ë³€í™˜ (pickle ì—†ì´)
                            chunk = TextChunk(
                                text=doc.page_content,
                                metadata=doc.metadata if hasattr(doc, 'metadata') else {},
                                source_id=doc.metadata.get('source_id', f'{domain}_{i}') if hasattr(doc, 'metadata') else f'{domain}_{i}',
                                chunk_index=i
                            )
                            meta.documents.append(chunk)
                            
                            # ì§„í–‰ ìƒí™© ë¡œê¹… (í° ë°ì´í„°ì…‹ì˜ ê²½ìš°)
                            if i > 0 and i % 50 == 0:
                                logger.debug(f"ğŸ“ {domain} ë¬¸ì„œ ë³€í™˜ ì§„í–‰: {i}/{len(raw_documents)}")
                                
                        except Exception as chunk_error:
                            logger.warning(f"âš ï¸ {domain} ì²­í¬ {i} ë³€í™˜ ì‹¤íŒ¨: {chunk_error}")
                            # ë³€í™˜ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì²­í¬ë¼ë„ ìƒì„±
                            try:
                                fallback_chunk = TextChunk(
                                    text=str(doc.page_content) if hasattr(doc, 'page_content') else f"ë¬¸ì„œ {i} ë‚´ìš©",
                                    metadata={'fallback': True, 'domain': domain},
                                    source_id=f'{domain}_fallback_{i}',
                                    chunk_index=i
                                )
                                meta.documents.append(fallback_chunk)
                            except:
                                logger.warning(f"âš ï¸ {domain} ì²­í¬ {i} í´ë°±ë„ ì‹¤íŒ¨, ê±´ë„ˆëœ€")
                                continue
                    
                    if meta.documents:
                        documents_loaded = True
                        logger.info(f"âœ… {domain} FAISSì—ì„œ {len(meta.documents)}ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ")
                    else:
                        logger.warning(f"âš ï¸ {domain} FAISSì—ì„œ ë³€í™˜ëœ ë¬¸ì„œê°€ ì—†ìŒ")
                        
                except Exception as faiss_error:
                    logger.error(f"âŒ {domain} FAISS docstore ì ‘ê·¼ ì‹¤íŒ¨: {faiss_error}")
                    logger.debug(f"FAISS ì˜¤ë¥˜ ìƒì„¸:\n{traceback.format_exc()}")
            else:
                logger.warning(f"âš ï¸ {domain} ë²¡í„°ìŠ¤í† ì–´ê°€ ë¡œë“œë˜ì§€ ì•Šì•„ ë¬¸ì„œ ë¡œë“œ ë¶ˆê°€")
            
            # ë¬¸ì„œê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìœ¼ë©´ ê¸°ë³¸ ë”ë¯¸ ìƒì„±
            if not documents_loaded:
                logger.warning(f"âš ï¸ {domain} ëª¨ë“  ë¬¸ì„œ ë¡œë“œ ì‹¤íŒ¨, ë„ë©”ì¸ë³„ ë”ë¯¸ ë¬¸ì„œ ìƒì„±")
                
                # ë„ë©”ì¸ë³„ ì˜ë¯¸ìˆëŠ” ë”ë¯¸ ë°ì´í„° ìƒì„±
                domain_dummy_data = {
                    "satisfaction": "ë§Œì¡±ë„ ì¡°ì‚¬ ê²°ê³¼ì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.",
                    "general": "ê²½ìƒë‚¨ë„ì¸ì¬ê°œë°œì›ì˜ ì¼ë°˜ ì •ë³´ì™€ í•™ì¹™ì„ ì œê³µí•©ë‹ˆë‹¤.",
                    "publish": "êµìœ¡ê³„íšì„œì™€ í‰ê°€ì„œ ë“± ê³µì‹ ë°œí–‰ë¬¼ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.",
                    "cyber": "ì‚¬ì´ë²„ êµìœ¡ ì¼ì •ê³¼ ê³¼ì • ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.",
                    "menu": "êµ¬ë‚´ì‹ë‹¹ ë©”ë‰´ì™€ ì‹ë‹¨ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.",
                    "notice": "ê³µì§€ì‚¬í•­ê³¼ ì•ˆë‚´ì‚¬í•­ì„ ì œê³µí•©ë‹ˆë‹¤."
                }
                
                dummy_text = domain_dummy_data.get(domain, f"{domain} ë„ë©”ì¸ì˜ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.")
                dummy_chunk = TextChunk(
                    text=dummy_text,
                    metadata={'domain': domain, 'type': 'dummy', 'created_at': datetime.now().isoformat()},
                    source_id=f'{domain}_dummy',
                    chunk_index=0
                )
                meta.documents = [dummy_chunk]
                logger.info(f"ğŸ”„ {domain} ë”ë¯¸ ë¬¸ì„œ ìƒì„± ì™„ë£Œ: '{dummy_text[:50]}...'")
            
            # BM25 ì¸ë±ìŠ¤ ë¡œë“œ ì‹œë„ (ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰)
            bm25_loaded = False
            if meta.bm25_path.exists():
                try:
                    logger.info(f"ğŸ”„ {domain} BM25 ì¸ë±ìŠ¤ ë¡œë“œ ì‹œë„")
                    with open(meta.bm25_path, 'rb') as f:
                        bm25_data = pickle.load(f)
                        if isinstance(bm25_data, tuple):
                            meta.bm25, _ = bm25_data
                        else:
                            meta.bm25 = bm25_data
                    bm25_loaded = True
                    logger.info(f"âœ… ë„ë©”ì¸ {domain} BM25 ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ")
                except Exception as bm25_error:
                    logger.warning(f"âš ï¸ ë„ë©”ì¸ {domain} BM25 ë¡œë“œ ì‹¤íŒ¨: {bm25_error}")
                    meta.bm25 = None
            else:
                logger.debug(f"âš ï¸ ë„ë©”ì¸ {domain} BM25 ì¸ë±ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                meta.bm25 = None
            
            # ë¡œë“œ ìƒíƒœ ì—…ë°ì´íŠ¸
            meta.last_loaded = datetime.now()
            meta.load_count += 1
            meta.last_hash = meta.get_file_hash()
            elapsed = time.time() - start_time
            
            # ë¡œë“œ ìƒíƒœ ìš”ì•½
            status_parts = []
            if meta.vectorstore:
                status_parts.append("FAISS")
            if bm25_loaded:
                status_parts.append("BM25")
            if meta.documents:
                status_parts.append(f"ë¬¸ì„œ {len(meta.documents)}ê°œ")
            
            logger.info(f"âœ… ë„ë©”ì¸ {domain} ë¡œë“œ ì„±ê³µ! ({', '.join(status_parts)}, {elapsed:.2f}ì´ˆ)")
            
        except Exception as e:
            meta.error_count += 1
            logger.error(f"âŒ ë„ë©”ì¸ {domain} ë¡œë“œ ì‹¤íŒ¨: {e}")
            logger.debug(f"ìƒì„¸ ì˜¤ë¥˜:\n{traceback.format_exc()}")
            
            # ìµœì¢… ì•ˆì „ì¥ì¹˜: ì—ëŸ¬ ì‹œì—ë„ ìµœì†Œ ê¸°ëŠ¥ ì œê³µ
            try:
                meta.vectorstore = None
                meta.bm25 = None
                
                if not meta.documents:
                    error_chunk = TextChunk(
                        text=f"{domain} ë„ë©”ì¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ë¡œë“œí•˜ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.",
                        metadata={
                            'domain': domain, 
                            'type': 'error_fallback',
                            'error': str(e),
                            'created_at': datetime.now().isoformat()
                        },
                        source_id=f'{domain}_error',
                        chunk_index=0
                    )
                    meta.documents = [error_chunk]
                    logger.info(f"ğŸ†˜ {domain} ì—ëŸ¬ í´ë°± ë¬¸ì„œ ìƒì„± ì™„ë£Œ")
                    
            except Exception as final_error:
                logger.error(f"ğŸ’¥ {domain} ìµœì¢… í´ë°±ë„ ì‹¤íŒ¨: {final_error}")
                # ì´ ê²½ìš° meta.documentsëŠ” ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ë‚¨ìŒ



    def load_all_domains(self):
        """ëª¨ë“  ë„ë©”ì¸ ë¡œë“œ"""
        logger.info(f"ğŸ”„ ì „ì²´ ë„ë©”ì¸ ë¡œë“œ ì‹œì‘: {list(self.metadata.keys())}")
        
        start_time = time.time()
        loaded_count = 0
        
        for domain in self.metadata.keys():
            try:
                self._load_domain(domain)
                loaded_count += 1
            except Exception as e:
                logger.error(f"âŒ ë„ë©”ì¸ {domain} ë¡œë“œ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        
        elapsed = time.time() - start_time
        logger.info(f"ğŸ‰ ë„ë©”ì¸ ë¡œë“œ ì™„ë£Œ: {loaded_count}/{len(self.metadata)}ê°œ ì„±ê³µ ({elapsed:.2f}ì´ˆ)")

    def get_vectorstore(self, domain: str) -> Optional[FAISS]:
        """ë„ë©”ì¸ë³„ ë²¡í„°ìŠ¤í† ì–´ íšë“"""
        if domain not in self.metadata:
            logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ë„ë©”ì¸: {domain}")
            return None
        
        return self.metadata[domain].vectorstore

    def get_bm25(self, domain: str) -> Optional[BM25Okapi]:
        """ë„ë©”ì¸ë³„ BM25 ì¸ë±ìŠ¤ íšë“"""
        if domain not in self.metadata:
            logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ë„ë©”ì¸: {domain}")
            return None
        
        return self.metadata[domain].bm25

    def get_documents(self, domain: str) -> List[TextChunk]:
        """ë„ë©”ì¸ë³„ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ íšë“"""
        if domain not in self.metadata:
            logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ë„ë©”ì¸: {domain}")
            return []
        
        return self.metadata[domain].documents

    def health_check(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ìƒíƒœ ì²´í¬"""
        status = {
            "total_domains": len(self.metadata),
            "loaded_domains": 0,
            "failed_domains": 0,
            "domains_detail": {},
            "global_embeddings": self.embeddings is not None
        }
        
        for domain, meta in self.metadata.items():
            domain_status = {
                "loaded": meta.vectorstore is not None,
                "bm25_available": meta.bm25 is not None,
                "documents_count": len(meta.documents),
                "load_count": meta.load_count,
                "error_count": meta.error_count,
                "last_loaded": meta.last_loaded.isoformat() if meta.last_loaded else None
            }
            
            if domain_status["loaded"]:
                status["loaded_domains"] += 1
            else:
                status["failed_domains"] += 1
            
            status["domains_detail"][domain] = domain_status
        
        return status

# ================================================================
# 3. ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ íŒ©í„°ë¦¬ ë° í˜¸í™˜ì„± í•¨ìˆ˜
# ================================================================

_index_manager_instance = None

def get_index_manager() -> IndexManager:
    """IndexManager ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ íšë“"""
    global _index_manager_instance
    if _index_manager_instance is None:
        _index_manager_instance = IndexManager()
    return _index_manager_instance

def preload_all_indexes() -> Dict[str, Any]:
    """
    ëª¨ë“  ì¸ë±ìŠ¤ ì‚¬ì „ ë¡œë“œ (app.py í˜¸í™˜ì„± ê°œì„ )
    
    Returns:
        Dict[str, Any]: ë¡œë“œ ê²°ê³¼ ì •ë³´
    """
    logger.info("ğŸš€ ì¸ë±ìŠ¤ ì‚¬ì „ ë¡œë“œ ì‹œì‘")
    start_time = time.time()
    
    try:
        manager = get_index_manager()
        
        # ì¬ë¡œë“œ ì‹¤í–‰
        manager.load_all_domains()
        
        # ìƒíƒœ ì²´í¬
        status = manager.health_check()
        elapsed_time = time.time() - start_time
        
        logger.info(f"ğŸ“Š ì¸ë±ìŠ¤ ë¡œë“œ ìƒíƒœ: {status['loaded_domains']}/{status['total_domains']}ê°œ ì„±ê³µ")
        
        # app.pyì—ì„œ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
        return {
            "success": status["loaded_domains"] > 0,
            "loaded_indexes": list(status["domains_detail"].keys()),
            "performance": {
                "load_time": elapsed_time,
                "loaded_domains": status["loaded_domains"],
                "total_domains": status["total_domains"]
            },
            "error": None if status["loaded_domains"] > 0 else "No domains loaded"
        }
        
    except Exception as e:
        logger.error(f"âŒ ì¸ë±ìŠ¤ ì‚¬ì „ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {
            "success": False,
            "loaded_indexes": [],
            "performance": {},
            "error": str(e)
        }

def index_health_check() -> Dict[str, Any]:
    """
    IndexManager í—¬ìŠ¤ì²´í¬ (app.py í˜¸í™˜ì„± í•¨ìˆ˜)
    
    Returns:
        Dict[str, Any]: ì‹œìŠ¤í…œ ìƒíƒœ ì •ë³´
    """
    try:
        manager = get_index_manager()
        return manager.health_check()
    except Exception as e:
        logger.error(f"âŒ í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨: {e}")
        return {
            "total_domains": 0,
            "loaded_domains": 0,
            "failed_domains": 0,
            "domains_detail": {},
            "global_embeddings": False,
            "error": str(e)
        }

# ================================================================
# 4. í…ŒìŠ¤íŠ¸ ë° ê²€ì¦ 
# ================================================================

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    print("ğŸ§ª IndexManager í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    try:
        # ì‹±ê¸€í†¤ í…ŒìŠ¤íŠ¸
        manager1 = get_index_manager()
        manager2 = get_index_manager()
        assert manager1 is manager2, "ì‹±ê¸€í†¤ íŒ¨í„´ ì‹¤íŒ¨"
        print("âœ… ì‹±ê¸€í†¤ íŒ¨í„´ í…ŒìŠ¤íŠ¸ í†µê³¼")
        
        # ìƒíƒœ ì²´í¬
        status = manager1.health_check()
        print(f"ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ: {status}")
        
        print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        traceback.print_exc()
