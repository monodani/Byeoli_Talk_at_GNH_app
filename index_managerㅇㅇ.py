#!/usr/bin/env python3
"""
ê²½ìƒë‚¨ë„ì¸ì¬ê°œë°œì› RAG ì±—ë´‡ - index_manager.py (BM25 ë¡œë“œ ë° import ìˆ˜ì •)

IndexManager ì‹±ê¸€í†¤: ëª¨ë“  ë²¡í„°ìŠ¤í† ì–´ ì¤‘ì•™ ê´€ë¦¬
- ì•± ê¸°ë™ ì‹œ ëª¨ë“  FAISS ì¸ë±ìŠ¤ ì‚¬ì „ ë¡œë“œ
- ì €ì¥ëœ BM25 íŒŒì¼ ë¡œë“œ
- í•´ì‹œ ê¸°ë°˜ íŒŒì¼ ë³€ê²½ ê°ì§€ë¡œ í•«ìŠ¤ì™‘
- ì „ì—­ ê³µìœ ë¡œ í•¸ë“¤ëŸ¬ ê°„ ì¼ê´€ì„± ë³´ì¥
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë‹¨ì¼ ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬

í•µì‹¬ ìˆ˜ì •ì‚¬í•­:
âœ… TextChunk import ëˆ„ë½ ì˜¤ë¥˜ ìˆ˜ì •
âœ… ê²½ë¡œ ì˜¤ë¥˜ ìˆ˜ì •: VectorStoreMetadata ì´ˆê¸°í™” ì‹œ ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
âœ… preload_all_indexes í•¨ìˆ˜ ì¶”ê°€ (test_integration.py í˜¸í™˜)
âœ… traceback import ì¶”ê°€
âœ… embeddings ì´ˆê¸°í™” ëˆ„ë½ ìˆ˜ì •
"""

import hashlib
import logging
import threading
import time
import pickle
import traceback  # âœ… traceback import ì¶”ê°€
from pathlib import Path
from typing import Dict, Optional, Any, List, Tuple
from datetime import datetime

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ
from utils.config import config
from utils.contracts import HandlerType
from utils.textifier import TextChunk  # âœ… TextChunk í´ë˜ìŠ¤ import ì¶”ê°€

# ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import OpenAIEmbeddings
from rank_bm25 import BM25Okapi
import numpy as np

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)


# ================================================================
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì • (ê¸°ì¡´ê³¼ ë™ì¼)
# ================================================================
try:
    ROOT_DIR = Path(__file__).parent.parent.absolute()
except NameError:
    ROOT_DIR = Path(".").absolute()

# ================================================================
# 1. ë²¡í„°ìŠ¤í† ì–´ ë©”íƒ€ë°ì´í„° í´ë˜ìŠ¤ (BM25 íŒŒì¼ ì¶”ê°€)
# ================================================================

class VectorStoreMetadata:
    """
    ë²¡í„°ìŠ¤í† ì–´ ë©”íƒ€ë°ì´í„° ë° ìƒíƒœ ê´€ë¦¬ (BM25 íŒŒì¼ ì§€ì›)
    """
    
    def __init__(self, domain: str, vectorstore_dir: Path):
        self.domain = domain
        self.vectorstore_dir = ROOT_DIR / vectorstore_dir
        self.vectorstore_path = self.vectorstore_dir / f"vectorstore_{domain}"
        self.faiss_path = self.vectorstore_path / f"{domain}_index.faiss"
        self.pkl_path = self.vectorstore_path / f"{domain}_index.pkl"
        
        self.bm25_path = self.vectorstore_dir / f"{domain}_index.bm25"
        
        # âœ… embeddings ì´ˆê¸°í™” ì¶”ê°€
        self.embeddings = OpenAIEmbeddings()
        
        self.vectorstore: Optional[FAISS] = None
        self.bm25: Optional[BM25Okapi] = None
        self.documents: List[TextChunk] = []
        self.last_loaded: Optional[datetime] = None
        self.load_count: int = 0
        self.error_count: int = 0
        self.last_hash: Optional[str] = None

    def exists(self) -> bool:
        """
        í•„ìš”í•œ ì¸ë±ìŠ¤ íŒŒì¼ë“¤ì´ ëª¨ë‘ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        """
        return self.faiss_path.exists() and self.pkl_path.exists() and self.bm25_path.exists()

    @property
    def needs_reload(self) -> bool:
        """
        íŒŒì¼ ë³€ê²½ ì—¬ë¶€ë¥¼ ê°ì§€í•˜ì—¬ ë¦¬ë¡œë“œ í•„ìš”ì„±ì„ íŒë‹¨
        """
        if not self.exists():
            return False
        
        current_hash = self.get_file_hash()
        return current_hash != self.last_hash
    
    def get_file_hash(self) -> str:
        """
        ëª¨ë“  ì¸ë±ìŠ¤ íŒŒì¼ì˜ í•´ì‹œë¥¼ í•©ì³ì„œ ë°˜í™˜
        """
        hasher = hashlib.sha256()
        try:
            for path in [self.faiss_path, self.pkl_path, self.bm25_path]:
                if path.exists():
                    hasher.update(path.read_bytes())
            return hasher.hexdigest()
        except Exception as e:
            logger.error(f"âŒ ë„ë©”ì¸ {self.domain} íŒŒì¼ í•´ì‹œ ê³„ì‚° ì‹¤íŒ¨: {e}")
            self.error_count += 1
            return ""

# ================================================================
# 2. IndexManager ì‹±ê¸€í†¤ í´ë˜ìŠ¤
# ================================================================

class IndexManager:
    """
    ëª¨ë“  ë²¡í„°ìŠ¤í† ì–´ë¥¼ ê´€ë¦¬í•˜ëŠ” ì‹±ê¸€í†¤ í´ë˜ìŠ¤
    """
    
    def __init__(self):
        self.metadata: Dict[str, VectorStoreMetadata] = {}
        self.lock = threading.Lock()
        
        # âœ… ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì¶”ê°€
        self.embeddings = OpenAIEmbeddings()
        
        for domain in config.HANDLERS:
            self.metadata[domain] = VectorStoreMetadata(
                domain,
                Path(config.VECTORSTORE_DIR)
            )
        
        logger.info(f"ğŸš€ IndexManager ì‹±ê¸€í†¤ ì´ˆê¸°í™” ì™„ë£Œ: {len(self.metadata)}ê°œ ë„ë©”ì¸")
        self.load_all_domains()

    def _load_domain(self, domain: str):
        """
        ë‹¨ì¼ ë„ë©”ì¸ì˜ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ë¡œë“œ
        """
        meta = self.metadata[domain]
        
        logger.info(f"ğŸ”„ ë„ë©”ì¸ {domain} ë¡œë“œ ì‹œì‘...")
        
        try:
            if not meta.exists():
                logger.warning(f"âš ï¸ ë„ë©”ì¸ {domain}ì— í•„ìš”í•œ ì¸ë±ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¡œë“œ ê±´ë„ˆëœë‹ˆë‹¤.")
                meta.vectorstore = None
                meta.bm25 = None
                return
            
            start_time = time.time()
            meta.vectorstore = FAISS.load_local(
                str(meta.vectorstore_path),
                meta.embeddings,
                allow_dangerous_deserialization=True
            )
            
            with open(meta.pkl_path, "rb") as f:
                meta.documents = pickle.load(f)
            
            if meta.bm25_path.exists():
                with open(meta.bm25_path, 'rb') as f:
                    meta.bm25 = pickle.load(f)
                logger.info(f"âœ… ë„ë©”ì¸ {domain} BM25 ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ.")
            else:
                logger.warning(f"âš ï¸ ë„ë©”ì¸ {domain} BM25 ì¸ë±ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. BM25 ê²€ìƒ‰ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                meta.bm25 = None

            meta.last_loaded = datetime.now()
            meta.load_count += 1
            meta.last_hash = meta.get_file_hash()
            elapsed = time.time() - start_time
            logger.info(f"âœ… ë„ë©”ì¸ {domain} ë¡œë“œ ì„±ê³µ! ({len(meta.documents):,}ê°œ ë¬¸ì„œ, {elapsed:.2f}ì´ˆ)")

        except Exception as e:
            meta.error_count += 1
            logger.error(f"âŒ ë„ë©”ì¸ {domain} ë¡œë“œ ì‹¤íŒ¨: {e}")
            logger.debug(traceback.format_exc())
            meta.vectorstore = None
            meta.bm25 = None
            
    def load_all_domains(self):
        """ë³‘ë ¬ë¡œ ëª¨ë“  ë„ë©”ì¸ì„ ë¡œë“œ"""
        threads = []
        for domain in self.metadata:
            thread = threading.Thread(target=self._load_domain, args=(domain,))
            threads.append(thread)
            thread.start()
        
        for thread in threads:
            thread.join()
            
    def check_for_updates_and_reload(self):
        """
        íŒŒì¼ ë³€ê²½ì„ ê°ì§€í•˜ê³ , ë³€ê²½ëœ ë„ë©”ì¸ë§Œ í•«ìŠ¤ì™‘ ì‹¤í–‰
        """
        for domain, meta in self.metadata.items():
            if meta.needs_reload:
                logger.info(f"ğŸ”„ ë„ë©”ì¸ {domain} íŒŒì¼ ë³€ê²½ ê°ì§€, í•«ìŠ¤ì™‘ ì‹¤í–‰...")
                self._load_domain(domain)
    
    def get_vectorstore(self, domain: str) -> Optional[FAISS]:
        """ë„ë©”ì¸ì— í•´ë‹¹í•˜ëŠ” FAISS ë²¡í„°ìŠ¤í† ì–´ ë°˜í™˜ (base_handler í˜¸í™˜)"""
        meta = self.metadata.get(domain)
        return meta.vectorstore if meta else None
    
    def get_index(self, domain: str) -> Optional[FAISS]:
        """ë„ë©”ì¸ì— í•´ë‹¹í•˜ëŠ” FAISS ì¸ë±ìŠ¤ ë°˜í™˜ (ê¸°ì¡´ í˜¸í™˜ì„±)"""
        return self.get_vectorstore(domain)
    
    def get_documents(self, domain: str) -> List[TextChunk]:
        """ë„ë©”ì¸ì— í•´ë‹¹í•˜ëŠ” ì›ë³¸ ë¬¸ì„œ ì²­í¬ ë°˜í™˜"""
        meta = self.metadata.get(domain)
        return meta.documents if meta else []
        
    def get_bm25(self, domain: str) -> Optional[BM25Okapi]:
        """ë„ë©”ì¸ì— í•´ë‹¹í•˜ëŠ” BM25 ì¸ë±ìŠ¤ ë°˜í™˜"""
        meta = self.metadata.get(domain)
        return meta.bm25 if meta else None
        
    def get_status(self) -> Dict[str, Dict]:
        """
        ì „ì²´ ì¸ë±ìŠ¤ ìƒíƒœ ì •ë³´ ë°˜í™˜
        """
        status = {}
        
        for domain, meta in self.metadata.items():
            status[domain] = {
                'loaded': meta.vectorstore is not None,
                'documents_count': len(meta.documents),
                'has_bm25': meta.bm25 is not None,
                'last_loaded': meta.last_loaded.isoformat() if meta.last_loaded else None,
                'load_count': meta.load_count,
                'error_count': meta.error_count,
                'files_exist': meta.exists()
            }
        
        return status


# ================================================================
# 3. ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬
# ================================================================

_index_manager_instance: Optional[IndexManager] = None
_instance_lock = threading.Lock()


def get_index_manager() -> IndexManager:
    """
    IndexManager ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜
    """
    global _index_manager_instance
    
    if _index_manager_instance is None:
        with _instance_lock:
            if _index_manager_instance is None:
                _index_manager_instance = IndexManager()
    
    return _index_manager_instance


# ================================================================
# 4. âœ… test_integration.py í˜¸í™˜ì„±ì„ ìœ„í•œ ì¶”ê°€ í•¨ìˆ˜ë“¤
# ================================================================

def preload_all_indexes() -> Dict[str, bool]:
    """
    ëª¨ë“  ì¸ë±ìŠ¤ë¥¼ ì‚¬ì „ ë¡œë“œí•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜
    test_integration.pyì—ì„œ ìš”êµ¬í•˜ëŠ” í•¨ìˆ˜
    
    Returns:
        Dict[str, bool]: ë„ë©”ì¸ë³„ ë¡œë“œ ì„±ê³µ ì—¬ë¶€
    """
    logger.info("ğŸš€ ëª¨ë“  ì¸ë±ìŠ¤ ì‚¬ì „ ë¡œë“œ ì‹œì‘...")
    
    try:
        # IndexManager ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ìë™ìœ¼ë¡œ ëª¨ë“  ë„ë©”ì¸ ë¡œë“œë¨)
        index_manager = get_index_manager()
        
        # ê° ë„ë©”ì¸ë³„ ë¡œë“œ ê²°ê³¼ í™•ì¸
        results = {}
        status = index_manager.get_status()
        
        for domain, domain_status in status.items():
            is_loaded = domain_status['loaded'] and domain_status['documents_count'] > 0
            results[domain] = is_loaded
            
            if is_loaded:
                logger.info(f"âœ… {domain}: {domain_status['documents_count']}ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ")
            else:
                logger.warning(f"âš ï¸ {domain}: ë¡œë“œ ì‹¤íŒ¨ ë˜ëŠ” ë¬¸ì„œ ì—†ìŒ")
        
        success_count = sum(1 for success in results.values() if success)
        total_count = len(results)
        
        logger.info(f"ğŸ“Š ì¸ë±ìŠ¤ ì‚¬ì „ ë¡œë“œ ì™„ë£Œ: {success_count}/{total_count}ê°œ ë„ë©”ì¸ ì„±ê³µ")
        
        return results
        
    except Exception as e:
        logger.error(f"âŒ ì¸ë±ìŠ¤ ì‚¬ì „ ë¡œë“œ ì‹¤íŒ¨: {e}")
        # ëª¨ë“  ë„ë©”ì¸ì„ ì‹¤íŒ¨ë¡œ í‘œì‹œ
        return {domain: False for domain in config.HANDLERS}


def index_health_check() -> Dict[str, Any]:
    """
    ì¸ë±ìŠ¤ ìƒíƒœ ê±´ê°• ê²€ì§„
    
    Returns:
        Dict[str, Any]: ìƒíƒœ ì •ë³´ ë° ê±´ê°•ë„ ì§€í‘œ
    """
    try:
        index_manager = get_index_manager()
        status = index_manager.get_status()
        
        # ì „ì²´ í†µê³„ ê³„ì‚°
        total_domains = len(status)
        loaded_domains = sum(1 for s in status.values() if s['loaded'])
        total_documents = sum(s['documents_count'] for s in status.values())
        total_errors = sum(s['error_count'] for s in status.values())
        
        # ê±´ê°•ë„ ê³„ì‚° (0-100 ì ìˆ˜)
        health_score = int((loaded_domains / total_domains) * 100) if total_domains > 0 else 0
        
        # ìƒíƒœ ë“±ê¸‰ ê²°ì •
        if health_score >= 90:
            health_status = "healthy"
        elif health_score >= 70:
            health_status = "degraded"
        else:
            health_status = "critical"
        
        # ì¶”ê°€ ì²´í¬ í•­ëª©ë“¤
        checks = {
            "all_domains_loaded": loaded_domains == total_domains,
            "no_recent_errors": total_errors == 0,
            "sufficient_documents": total_documents > 100,  # ìµœì†Œ ë¬¸ì„œ ìˆ˜ ê¸°ì¤€
            "embeddings_available": hasattr(index_manager, 'metadata')
        }
        
        result = {
            "timestamp": datetime.now().isoformat(),
            "health_status": health_status,
            "health_score": health_score,
            "summary": {
                "total_domains": total_domains,
                "loaded_domains": loaded_domains,
                "total_documents": total_documents,
                "total_errors": total_errors
            },
            "checks": checks,
            "domain_details": status,
            "recommendations": []
        }
        
        # ê¶Œì¥ì‚¬í•­ ìƒì„±
        if health_score < 100:
            failed_domains = [domain for domain, s in status.items() if not s['loaded']]
            if failed_domains:
                result["recommendations"].append(f"ë‹¤ìŒ ë„ë©”ì¸ ì¬êµ¬ì¶• í•„ìš”: {', '.join(failed_domains)}")
        
        if total_errors > 0:
            result["recommendations"].append("ì—ëŸ¬ê°€ ë°œìƒí•œ ë„ë©”ì¸ì˜ ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”")
        
        if total_documents < 100:
            result["recommendations"].append("ë¬¸ì„œ ìˆ˜ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ë°ì´í„° ì†ŒìŠ¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”")
        
        logger.info(f"ğŸ¥ ê±´ê°• ê²€ì§„ ì™„ë£Œ - ìƒíƒœ: {health_status}, ì ìˆ˜: {health_score}/100")
        
        return result
        
    except Exception as e:
        logger.error(f"âŒ ê±´ê°• ê²€ì§„ ì‹¤íŒ¨: {e}")
        return {
            "timestamp": datetime.now().isoformat(),
            "health_status": "error",
            "health_score": 0,
            "error": str(e),
            "recommendations": ["ì‹œìŠ¤í…œ ì¬ì‹œì‘ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤"]
        }


# ================================================================
# 5. ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ ë¡œê·¸
# ================================================================

logger.info("âœ… index_manager.py ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ (preload_all_indexes í¬í•¨)")