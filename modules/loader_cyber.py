"""
ì‚¬ì´ë²„ êµìœ¡ ë¡œë”
ë¯¼ê°„ìœ„íƒ ì‚¬ì´ë²„êµìœ¡(mingan.csv)ê³¼ ë‚˜ë¼ë°°ì›€í„°(nara.csv) ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ì—¬ ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
"""

import pandas as pd
from typing import List
from pathlib import Path

from .base_loader import BaseLoader
from utils.textifier import TextChunk
from utils.logging_utils import get_logger

logger = get_logger(__name__)

class CyberLoader(BaseLoader):
    """ì‚¬ì´ë²„ êµìœ¡ ë°ì´í„° ë¡œë”"""
    
    # ê¸°ì¡´ í…œí”Œë¦¿ ë³´ì¡´ (ì‚¬ìš©ì ìš”ì²­ì‚¬í•­)
    MINGAN_TEMPLATE = """'{êµìœ¡ê³¼ì •}' ê³¼ì •ì€, 2025ë…„ ê²½ìƒë‚¨ë„ì¸ì¬ê°œë°œì›ì—ì„œ ìš´ì˜í•˜ê³  ìˆëŠ” ë¯¼ê°„ìœ„íƒ ì‚¬ì´ë²„êµìœ¡ ê³¼ì • ì¤‘ í•˜ë‚˜ë¡œ, {ê°œë°œì—°ë„}ë…„ {ê°œë°œì›”}ì›”ì— ë§Œë“¤ì–´ì§„ êµìœ¡ ì½˜í…ì¸ ë¡œ ë‚´ìš© ë¶„ë¥˜ìƒ {êµ¬ë¶„}>{ëŒ€ë¶„ë¥˜}>{ì¤‘ë¶„ë¥˜}>{ì†Œë¶„ë¥˜}>{ì„¸ë¶„ë¥˜}ì— í•´ë‹¹ë˜ê³ , í•™ìŠµì‹œê°„ì€ {í•™ìŠµì‹œê°„}ì‹œê°„ì´ë©°, í•™ìŠµì— ëŒ€í•œ êµìœ¡ ì¸ì •ì‹œê°„ì€ {ì¸ì •ì‹œê°„}ì‹œê°„ì…ë‹ˆë‹¤.
---
"""

    NARA_TEMPLATE = """'{êµìœ¡ê³¼ì •}' ê³¼ì •ì€, 2025ë…„ ê²½ìƒë‚¨ë„ì¸ì¬ê°œë°œì› ë‚˜ë¼ë°°ì›€í„°ì—ì„œ ìš´ì˜í•˜ëŠ” ê³µë™í™œìš© ë‚˜ë¼ì½˜í…ì¸ ë¥¼ í™œìš©í•œ êµìœ¡ê³¼ì •ìœ¼ë¡œ, ë‚´ìš© ë¶„ë¥˜ìƒ {ë¶„ë¥˜}ì— í•´ë‹¹ë˜ë©°, í•™ìŠµì‹œê°„ì€ {í•™ìŠµì°¨ì‹œ}ì´ê³  í•™ìŠµì— ëŒ€í•œ êµìœ¡ ì¸ì •ì‹œê°„ì€ {ì¸ì •ì‹œê°„}ì…ë‹ˆë‹¤. ì°¸ê³ ì‚¬í•­ìœ¼ë¡œ, ë³¸ ê³¼ì •ì€ êµìœ¡ ë§ë¯¸ì— ì§„í–‰ë˜ëŠ” ë³„ë„ì˜ í‰ê°€ê°€ {í‰ê°€ìœ ë¬´}.
---
"""
    
    def __init__(self):
        super().__init__(
            loader_id="cyber",
            source_dir="data/cyber",
            target_dir="vectorstores/vectorstore_cyber",
            schema_dir="schemas"
        )
    
    def get_file_patterns(self) -> List[str]:
        """ì²˜ë¦¬í•  íŒŒì¼ íŒ¨í„´ ë°˜í™˜"""
        return ["mingan.csv", "nara.csv"]
    
    def process_domain_data(self, chunks: List[TextChunk]) -> List[TextChunk]:
        """
        ì‚¬ì´ë²„ êµìœ¡ ë°ì´í„°ë¥¼ ë„ë©”ì¸ë³„ í…œí”Œë¦¿ìœ¼ë¡œ ì²˜ë¦¬
        
        Args:
            chunks: textifierë¡œ ì¶”ì¶œëœ CSV ì›ë³¸ ì²­í¬ë“¤
            
        Returns:
            í…œí”Œë¦¿ì´ ì ìš©ëœ ì²˜ë¦¬ëœ ì²­í¬ë“¤
        """
        processed_chunks = []
        
        for chunk in chunks:
            try:
                # ì†ŒìŠ¤ íŒŒì¼ì— ë”°ë¼ ë‹¤ë¥¸ ì²˜ë¦¬
                source_file = chunk.metadata.get("file_path", "")
                
                if "mingan.csv" in source_file:
                    processed_chunk = self._process_mingan_chunk(chunk)
                elif "nara.csv" in source_file:
                    processed_chunk = self._process_nara_chunk(chunk)
                else:
                    logger.warning(f"Unknown source file for chunk: {source_file}")
                    continue
                
                if processed_chunk:
                    processed_chunks.append(processed_chunk)
                    
            except Exception as e:
                logger.error(f"Failed to process chunk from {chunk.source_id}: {e}")
                continue
        
        logger.info(f"Processed {len(processed_chunks)} cyber education chunks")
        return processed_chunks
    
    def _process_mingan_chunk(self, chunk: TextChunk) -> TextChunk:
        """ë¯¼ê°„ìœ„íƒ ì‚¬ì´ë²„êµìœ¡ ì²­í¬ ì²˜ë¦¬"""
        try:
            # CSV í–‰ ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ì—¬ í…œí”Œë¦¿ì— ì ìš©
            row_data = self._parse_csv_chunk(chunk.content)
            if not row_data:
                return None
            
            # í•„ìˆ˜ í•„ë“œ í™•ì¸
            required_fields = ['êµìœ¡ê³¼ì •', 'ê°œë°œì—°ë„', 'ê°œë°œì›”', 'êµ¬ë¶„', 'ëŒ€ë¶„ë¥˜', 
                             'ì¤‘ë¶„ë¥˜', 'ì†Œë¶„ë¥˜', 'ì„¸ë¶„ë¥˜', 'í•™ìŠµì‹œê°„', 'ì¸ì •ì‹œê°„']
            
            missing_fields = [field for field in required_fields if field not in row_data]
            if missing_fields:
                logger.warning(f"Missing fields in mingan data: {missing_fields}")
                return None
            
            # í…œí”Œë¦¿ ì ìš©
            formatted_content = self.MINGAN_TEMPLATE.format(**row_data)
            
            # ìƒˆë¡œìš´ ì²­í¬ ìƒì„±
            new_metadata = {
                **chunk.metadata,
                "template_type": "mingan",
                "education_course": row_data.get('êµìœ¡ê³¼ì •', ''),
                "category_path": f"{row_data.get('êµ¬ë¶„', '')}>{row_data.get('ëŒ€ë¶„ë¥˜', '')}>{row_data.get('ì¤‘ë¶„ë¥˜', '')}>{row_data.get('ì†Œë¶„ë¥˜', '')}>{row_data.get('ì„¸ë¶„ë¥˜', '')}",
                "learning_hours": row_data.get('í•™ìŠµì‹œê°„', ''),
                "recognition_hours": row_data.get('ì¸ì •ì‹œê°„', '')
            }
            
            return TextChunk(
                content=formatted_content,
                metadata=new_metadata,
                source_id=chunk.source_id,
                chunk_index=chunk.chunk_index
            )
            
        except Exception as e:
            logger.error(f"Failed to process mingan chunk: {e}")
            return None
    
    def _process_nara_chunk(self, chunk: TextChunk) -> TextChunk:
        """ë‚˜ë¼ë°°ì›€í„° ì²­í¬ ì²˜ë¦¬"""
        try:
            # CSV í–‰ ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ì—¬ í…œí”Œë¦¿ì— ì ìš©
            row_data = self._parse_csv_chunk(chunk.content)
            if not row_data:
                return None
            
            # í•„ìˆ˜ í•„ë“œ í™•ì¸
            required_fields = ['êµìœ¡ê³¼ì •', 'ë¶„ë¥˜', 'í•™ìŠµì°¨ì‹œ', 'ì¸ì •ì‹œê°„', 'í‰ê°€ìœ ë¬´']
            
            missing_fields = [field for field in required_fields if field not in row_data]
            if missing_fields:
                logger.warning(f"Missing fields in nara data: {missing_fields}")
                return None
            
            # í…œí”Œë¦¿ ì ìš©
            formatted_content = self.NARA_TEMPLATE.format(**row_data)
            
            # ìƒˆë¡œìš´ ì²­í¬ ìƒì„±
            new_metadata = {
                **chunk.metadata,
                "template_type": "nara",
                "education_course": row_data.get('êµìœ¡ê³¼ì •', ''),
                "category": row_data.get('ë¶„ë¥˜', ''),
                "learning_sessions": row_data.get('í•™ìŠµì°¨ì‹œ', ''),
                "recognition_hours": row_data.get('ì¸ì •ì‹œê°„', ''),
                "evaluation_required": row_data.get('í‰ê°€ìœ ë¬´', '')
            }
            
            return TextChunk(
                content=formatted_content,
                metadata=new_metadata,
                source_id=chunk.source_id,
                chunk_index=chunk.chunk_index
            )
            
        except Exception as e:
            logger.error(f"Failed to process nara chunk: {e}")
            return None
    
    def _parse_csv_chunk(self, content: str) -> dict:
        """
        CSV ì²­í¬ ë‚´ìš©ì„ íŒŒì‹±í•˜ì—¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        
        Args:
            content: "í•„ë“œëª…: ê°’ | í•„ë“œëª…: ê°’" í˜•íƒœì˜ í…ìŠ¤íŠ¸
            
        Returns:
            í•„ë“œëª…-ê°’ ë”•ì…”ë„ˆë¦¬
        """
        try:
            data = {}
            
            # " | "ë¡œ í•„ë“œ ë¶„ë¦¬
            fields = content.split(" | ")
            
            for field in fields:
                if ":" in field:
                    key, value = field.split(":", 1)
                    data[key.strip()] = value.strip()
            
            return data
            
        except Exception as e:
            logger.error(f"Failed to parse CSV chunk content: {e}")
            return {}
    
    def get_template_info(self) -> dict:
        """í…œí”Œë¦¿ ì •ë³´ ë°˜í™˜ (ë””ë²„ê¹…/ëª¨ë‹ˆí„°ë§ìš©)"""
        return {
            "mingan_template": self.MINGAN_TEMPLATE,
            "nara_template": self.NARA_TEMPLATE,
            "required_fields": {
                "mingan": ['êµìœ¡ê³¼ì •', 'ê°œë°œì—°ë„', 'ê°œë°œì›”', 'êµ¬ë¶„', 'ëŒ€ë¶„ë¥˜', 
                          'ì¤‘ë¶„ë¥˜', 'ì†Œë¶„ë¥˜', 'ì„¸ë¶„ë¥˜', 'í•™ìŠµì‹œê°„', 'ì¸ì •ì‹œê°„'],
                "nara": ['êµìœ¡ê³¼ì •', 'ë¶„ë¥˜', 'í•™ìŠµì°¨ì‹œ', 'ì¸ì •ì‹œê°„', 'í‰ê°€ìœ ë¬´']
            }
        }

# í¸ì˜ í•¨ìˆ˜ë“¤
def build_cyber_index(force_rebuild: bool = False) -> bool:
    """ì‚¬ì´ë²„ êµìœ¡ ì¸ë±ìŠ¤ ë¹Œë“œ"""
    loader = CyberLoader()
    return loader.build_index(force_rebuild=force_rebuild)

def get_cyber_status() -> dict:
    """ì‚¬ì´ë²„ êµìœ¡ ë¡œë” ìƒíƒœ ì¡°íšŒ"""
    loader = CyberLoader()
    return loader.get_status()

# ìŠ¤í¬ë¦½íŠ¸ ì§ì ‘ ì‹¤í–‰ìš©
if __name__ == "__main__":
    import sys
    
    # ëª…ë ¹í–‰ ì¸ì ì²˜ë¦¬
    force_rebuild = "--force" in sys.argv
    
    print(f"Building cyber education index (force_rebuild={force_rebuild})...")
    
    success = build_cyber_index(force_rebuild=force_rebuild)
    
    if success:
        status = get_cyber_status()
        print(f"âœ… Build completed successfully!")
        print(f"ğŸ“Š Status: {status}")
    else:
        print("âŒ Build failed!")
        sys.exit(1)
