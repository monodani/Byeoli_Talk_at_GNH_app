#!/usr/bin/env python3
"""
ê²½ìƒë‚¨ë„ì¸ì¬ê°œë°œì› RAG ì±—ë´‡ - ê°œì„ ëœ ìŠ¤ë§ˆíŠ¸ ê³µì§€ì‚¬í•­ ë¡œë”

- ë™ì  í”ŒëŸ¬ê·¸ì¸ ê¸°ë°˜ íŒŒì‹± ì‹œìŠ¤í…œ
- í…ìŠ¤íŠ¸ íŒ¨í„´ ì˜ì¡´ë„ë¥¼ ë‚®ì¶”ê³  ìœ ì—°ì„± ê°•í™”
- ìŠ¤íŠ¸ë¦¬ë° ê¸°ë°˜ íŒŒì¼ ì²˜ë¦¬ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ ê°œì„ 
"""

import logging
import re
import json
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple, Union
from datetime import datetime
from collections import defaultdict

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì„í¬íŠ¸ (ê°€ì •)
# from modules.base_loader import BaseLoader
# from utils.textifier import TextChunk
# from utils.config import config

# ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°€ì •ì„ ìœ„í•œ ë”ë¯¸ í´ë˜ìŠ¤
class BaseLoader:
    def __init__(self, domain, source_dir, vectorstore_dir, index_name):
        self.domain = domain
        self.source_dir = source_dir
        self.vectorstore_dir = vectorstore_dir
        self.index_name = index_name

    def process_domain_data(self) -> List:
        raise NotImplementedError

class TextChunk:
    def __init__(self, text, metadata):
        self.text = text
        self.metadata = metadata

class Config:
    def __init__(self):
        self.ROOT_DIR = Path('.')

config = Config()

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)


# ================================================================
# 1. ë™ì  íŒŒì‹±ì„ ìœ„í•œ í”ŒëŸ¬ê·¸ì¸ êµ¬ì¡°
# ================================================================

class NoticeParser:
    """
    ê³µì§€ì‚¬í•­ íŒŒì„œì˜ ê¸°ë³¸ ì¶”ìƒ í´ë˜ìŠ¤.
    ëª¨ë“  íŒŒì„œëŠ” ì´ í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ì•„ì•¼ í•©ë‹ˆë‹¤.
    """
    _registry = {}

    def __init_subclass__(cls, **kwargs):
        super().__init_subclass__(**kwargs)
        if hasattr(cls, 'TOPIC_TYPE') and cls.TOPIC_TYPE:
            NoticeParser._registry[cls.TOPIC_TYPE] = cls

    def can_parse(self, title: str, text: str, patterns: Dict[str, Any]) -> bool:
        """ì´ íŒŒì„œê°€ í•´ë‹¹ ê³µì§€ì‚¬í•­ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ”ì§€ íŒë‹¨í•˜ëŠ” ë©”ì„œë“œ"""
        raise NotImplementedError

    def parse(self, notice_text: str, patterns: Dict[str, Any]) -> Dict[str, Any]:
        """ê³µì§€ì‚¬í•­ í…ìŠ¤íŠ¸ë¥¼ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¥¼ ë°˜í™˜"""
        raise NotImplementedError
    
    def create_chunks(self, parsed_notice: Dict[str, Any], notice_number: int) -> List[TextChunk]:
        """íŒŒì‹±ëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ RAGìš© ì²­í¬ë¥¼ ìƒì„±"""
        raise NotImplementedError

# ì˜ˆì‹œ: í‰ê°€ ê³µì§€ì‚¬í•­ íŒŒì„œ
class EvaluationNoticeParser(NoticeParser):
    TOPIC_TYPE = "evaluation"
    
    def can_parse(self, title: str, text: str, patterns: Dict[str, Any]) -> bool:
        """ì œëª© ë˜ëŠ” ë‚´ìš©ì— 'í‰ê°€', 'ê³¼ì œ', 'ì œì¶œê¸°í•œ' í‚¤ì›Œë“œê°€ ìˆëŠ”ì§€ í™•ì¸"""
        keywords = patterns['topic_patterns'][self.TOPIC_TYPE]['keywords']
        return any(keyword in (title + text) for keyword in keywords)

    def parse(self, notice_text: str, patterns: Dict[str, Any]) -> Dict[str, Any]:
        """í‰ê°€ ê´€ë ¨ ì£¼ìš” ì •ë³´(ë§ˆê°ê¸°í•œ, ì ìˆ˜) ì¶”ì¶œ"""
        parsed = {}
        # ë§ˆê°ê¸°í•œ ì¶”ì¶œ
        deadline_match = re.search(r'ì œì¶œê¸°í•œ\s*[:ï¼š]\s*([^\n]+)', notice_text)
        if deadline_match:
            parsed['deadline'] = deadline_match.group(1).strip()
        # ë§Œì  ì ìˆ˜ ì¶”ì¶œ
        score_match = re.search(r'(\d+)\s*ì \s*ë§Œì ', notice_text)
        if score_match:
            parsed['max_score'] = int(score_match.group(1))
        
        return parsed
        
    def create_chunks(self, parsed_notice: Dict[str, Any], notice_number: int) -> List[TextChunk]:
        """í‰ê°€ ê³µì§€ì‚¬í•­ ì²­í¬ ìƒì„± ë¡œì§"""
        title = parsed_notice.get('title', 'ì œëª© ì—†ìŒ')
        full_text = parsed_notice.get('full_text', '')
        metadata = {
            'source_file': 'notice.txt',
            'notice_number': notice_number,
            'notice_title': title,
            'topic_type': self.TOPIC_TYPE,
            'processing_date': datetime.now().isoformat()
        }
        
        # ë©”ì¸ ì²­í¬: ì œëª©ê³¼ í•µì‹¬ ìš”ì•½
        summary = f"[{title}] ì´ ê³µì§€ì‚¬í•­ì€ í‰ê°€ì— ê´€í•œ ì¤‘ìš” ë‚´ìš©ì…ë‹ˆë‹¤. ë§ˆê°ê¸°í•œì€ {parsed_notice.get('deadline', 'ë³„ë„ ëª…ì‹œ ì—†ìŒ')}ì…ë‹ˆë‹¤."
        main_chunk = TextChunk(text=summary, metadata={**metadata, 'chunk_type': 'summary'})
        
        # ì„¸ë¶€ ì²­í¬: ì›ë¬¸ ì „ì²´
        detail_chunk = TextChunk(text=f"[{title} - ì›ë¬¸]\n\n{full_text}", metadata={**metadata, 'chunk_type': 'full_text'})
        
        return [main_chunk, detail_chunk]


# ì˜ˆì‹œ: ì…êµ ê³µì§€ì‚¬í•­ íŒŒì„œ
class EnrollmentNoticeParser(NoticeParser):
    TOPIC_TYPE = "enrollment"

    def can_parse(self, title: str, text: str, patterns: Dict[str, Any]) -> bool:
        keywords = patterns['topic_patterns'][self.TOPIC_TYPE]['keywords']
        return any(keyword in (title + text) for keyword in keywords)

    def parse(self, notice_text: str, patterns: Dict[str, Any]) -> Dict[str, Any]:
        """ì²´í¬ë¦¬ìŠ¤íŠ¸ì™€ ì—°ë½ì²˜ ì¶”ì¶œ"""
        parsed = {}
        # ì²´í¬ë¦¬ìŠ¤íŠ¸ í•­ëª© ì¶”ì¶œ (ì •ê·œí‘œí˜„ì‹ ì˜ì¡´ë„ ë‚®ì¶”ê¸° ìœ„í•´ ìœ ì—°í•˜ê²Œ)
        checklist_items = re.findall(r'(?:\d+\.|\-|â—‹)\s*([^\n]+)', notice_text)
        if checklist_items:
            parsed['checklist'] = [item.strip() for item in checklist_items]
        
        return parsed

    def create_chunks(self, parsed_notice: Dict[str, Any], notice_number: int) -> List[TextChunk]:
        """ì…êµ ê³µì§€ì‚¬í•­ ì²­í¬ ìƒì„± ë¡œì§"""
        title = parsed_notice.get('title', 'ì œëª© ì—†ìŒ')
        full_text = parsed_notice.get('full_text', '')
        metadata = {
            'source_file': 'notice.txt',
            'notice_number': notice_number,
            'notice_title': title,
            'topic_type': self.TOPIC_TYPE,
            'processing_date': datetime.now().isoformat()
        }
        
        # ë©”ì¸ ì²­í¬: ì œëª©ê³¼ í•µì‹¬ ìš”ì•½
        summary = f"[{title}] ì´ ê³µì§€ì‚¬í•­ì€ ì…êµ ì¤€ë¹„ì‚¬í•­ì— ëŒ€í•œ ì•ˆë‚´ì…ë‹ˆë‹¤. ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
        main_chunk = TextChunk(text=summary, metadata={**metadata, 'chunk_type': 'summary'})

        # ì²´í¬ë¦¬ìŠ¤íŠ¸ ì²­í¬
        checklist_text = "\n".join(f"- {item}" for item in parsed_notice.get('checklist', []))
        checklist_chunk = TextChunk(text=f"[{title} - ì²´í¬ë¦¬ìŠ¤íŠ¸]\n\n{checklist_text}", metadata={**metadata, 'chunk_type': 'checklist'})

        return [main_chunk, checklist_chunk]


# ================================================================
# 2. ë©”ì¸ ë¡œë” (ë™ì  íŒŒì„œ í™œìš©)
# ================================================================

class SmartNoticeLoader(BaseLoader):
    def __init__(self):
        super().__init__(
            domain="notice",
            source_dir=config.ROOT_DIR / "data" / "notice",
            vectorstore_dir=config.ROOT_DIR / "vectorstores" / "vectorstore_notice",
            index_name="notice_index"
        )
        self.config = self._load_patterns_config()
        self.parsers = NoticeParser._registry
        logger.info(f"âœ¨ ë™ì ìœ¼ë¡œ ë“±ë¡ëœ íŒŒì„œ: {list(self.parsers.keys())}")

    def _load_patterns_config(self) -> Dict[str, Any]:
        config_path = config.ROOT_DIR / "configs" / "notice_patterns.json"
        if config_path.exists():
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        else:
            return {
                "topic_patterns": {
                    "evaluation": {"keywords": ["í‰ê°€", "ê³¼ì œ", "ì œì¶œê¸°í•œ"], "priority": 25},
                    "enrollment": {"keywords": ["ì…êµ", "êµìœ¡ìƒ", "ì¤€ë¹„ë¬¼"], "priority": 20},
                    "general": {"keywords": ["ê³µì§€", "ì•ˆë‚´"], "priority": 10}
                }
            }

    def process_domain_data(self) -> List[TextChunk]:
        all_chunks = []
        notice_file = self.source_dir / "notice.txt"
        
        if not notice_file.exists():
            logger.warning(f"ê³µì§€ì‚¬í•­ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {notice_file}")
            return all_chunks

        try:
            logger.info(f"ğŸ§  ê°œì„ ëœ ìŠ¤ë§ˆíŠ¸ ì²˜ë¦¬ ì‹œì‘: {notice_file}")
            
            # ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ íŒŒì¼ ì½ê¸° (ì„¹ì…˜ë³„ë¡œ ì²˜ë¦¬)
            with open(notice_file, 'r', encoding='utf-8') as f:
                sections = f.read().split('---')

            for idx, section in enumerate(sections):
                if not section.strip():
                    continue

                try:
                    # 1. ì£¼ì œ ë¶„ë¥˜ ë° íŒŒì„œ ì„ íƒ
                    title = self._extract_title(section)
                    parser = self._select_parser(title, section)
                    
                    # 2. íŒŒì‹± ë° ì²­í¬ ìƒì„±
                    parsed_notice = parser.parse(section, self.config)
                    parsed_notice['title'] = title
                    parsed_notice['full_text'] = section
                    
                    chunks = parser.create_chunks(parsed_notice, idx + 1)
                    all_chunks.extend(chunks)
                    logger.info(f"ğŸ“‹ ê³µì§€ì‚¬í•­ #{idx + 1} ({parser.TOPIC_TYPE}) ì²˜ë¦¬ ì™„ë£Œ")

                except Exception as e:
                    logger.error(f"ê³µì§€ì‚¬í•­ #{idx + 1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜, í´ë°± ì²˜ë¦¬: {e}")
                    fallback_chunk = self._create_fallback_chunk(section, idx + 1)
                    if fallback_chunk:
                        all_chunks.append(fallback_chunk)
            
            logger.info(f"âœ… ê°œì„ ëœ ì²˜ë¦¬ ì™„ë£Œ: {len(all_chunks)}ê°œ ì²­í¬ ìƒì„±")
        except Exception as e:
            logger.error(f"ì „ì²´ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            
        return all_chunks

    def _extract_title(self, text: str) -> str:
        """ì²« ë²ˆì§¸ ì¤„ì—ì„œ ì œëª©ì„ ì¶”ì¶œí•˜ëŠ” ìœ ì—°í•œ ë¡œì§"""
        first_line = text.strip().split('\n')[0]
        title_match = re.search(r'\[(.*?)\]', first_line)
        return title_match.group(1).strip() if title_match else first_line.strip()

    def _select_parser(self, title: str, text: str) -> NoticeParser:
        """ê°€ì¥ ì í•©í•œ íŒŒì„œë¥¼ ë™ì ìœ¼ë¡œ ì„ íƒ"""
        best_parser = self.parsers.get('general', FallbackNoticeParser()) # ê¸°ë³¸ íŒŒì„œ
        best_score = -1
        
        # ëª¨ë“  ë“±ë¡ëœ íŒŒì„œì— ëŒ€í•´ ì ìˆ˜ ê³„ì‚°
        for topic_type, parser_cls in self.parsers.items():
            parser_instance = parser_cls()
            if parser_instance.can_parse(title, text, self.config):
                score = self.config['topic_patterns'].get(topic_type, {}).get('priority', 0)
                if score > best_score:
                    best_score = score
                    best_parser = parser_instance
                    
        return best_parser

    def _create_fallback_chunk(self, text: str, notice_number: int) -> TextChunk:
        """í´ë°±(Fallback) ì²­í¬ ìƒì„± (ì •ë³´ ì†ì‹¤ ìµœì†Œí™”)"""
        title = self._extract_title(text)
        content = text[:500]  # ì²˜ìŒ 500ì
        
        fallback_text = f"""
[ê³µì§€ì‚¬í•­ #{notice_number}] {title}

{content}

[ì£¼ì˜] ì´ ê³µì§€ì‚¬í•­ì€ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ ê¸°ë³¸ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.
ì •í™•í•œ ì •ë³´ëŠ” ì›ë³¸ íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.
""".strip()
        
        return TextChunk(
            text=fallback_text,
            metadata={
                'source_file': 'notice.txt',
                'notice_number': notice_number,
                'notice_title': title,
                'topic_type': 'fallback',
                'quality_level': 'fallback'
            }
        )

# í´ë°± ì²˜ë¦¬ë¥¼ ìœ„í•œ ê¸°ë³¸ íŒŒì„œ
class FallbackNoticeParser(NoticeParser):
    TOPIC_TYPE = "general"
    
    def can_parse(self, title: str, text: str, patterns: Dict[str, Any]) -> bool:
        return True # í•­ìƒ ì²˜ë¦¬ ê°€ëŠ¥

    def parse(self, notice_text: str, patterns: Dict[str, Any]) -> Dict[str, Any]:
        """ê¸°ë³¸ íŒŒì‹±: ì›ë¬¸ ì „ì²´ë¥¼ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë°˜í™˜"""
        return {"full_text": notice_text}
        
    def create_chunks(self, parsed_notice: Dict[str, Any], notice_number: int) -> List[TextChunk]:
        """ì›ë¬¸ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ì²­í¬ë¡œ ìƒì„±"""
        title = parsed_notice.get('title', 'ì œëª© ì—†ìŒ')
        full_text = parsed_notice.get('full_text', '')
        metadata = {
            'source_file': 'notice.txt',
            'notice_number': notice_number,
            'notice_title': title,
            'topic_type': 'general',
            'processing_date': datetime.now().isoformat()
        }
        return [TextChunk(text=f"[{title} - ì›ë¬¸]\n\n{full_text}", metadata=metadata)]

# ================================================================
# 3. í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ì½”ë“œ ë¸”ë¡ì„ ìœ„í•´ ì£¼ì„ ì²˜ë¦¬)
# ================================================================
# if __name__ == '__main__':
#     # ë¡œê¹… ì„¤ì •
#     logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
#     
#     # í…ŒìŠ¤íŠ¸ìš© íŒŒì¼ ë° í´ë” ìƒì„±
#     Path("data/notice").mkdir(parents=True, exist_ok=True)
#     with open("data/notice/notice.txt", "w", encoding="utf-8") as f:
#         f.write("[í‰ê°€ì•ˆë‚´] 2025ë…„ ê³¼ì œ ì œì¶œ ì•ˆë‚´\n\n- ì œì¶œê¸°í•œ: 2025ë…„ 12ì›” 31ì¼\n- ê³¼ì œì ìˆ˜: 100ì  ë§Œì \n---\n[ì…êµì•ˆë‚´] 1ì°¨ êµìœ¡ìƒ ì¤€ë¹„ë¬¼\n\nâ—‹ ë³µì¥: ë‹¨ì •í•œ ë³µì¥\nâ—‹ ì¤€ë¹„ë¬¼: ê°œì¸ ë…¸íŠ¸ë¶\n---")
#
#     # ë¡œë” ì‹¤í–‰
#     loader = SmartNoticeLoader()
#     chunks = loader.process_domain_data()
#     
#     # ê²°ê³¼ ì¶œë ¥
#     print("\n--- ìƒì„±ëœ ì²­í¬ ëª©ë¡ ---")
#     for chunk in chunks:
#         print(f"[{chunk.metadata['chunk_type']}] - {chunk.metadata['notice_title']}")
#         print(f"ë‚´ìš©: {chunk.text[:50].replace('\n', ' ')}...")
#         print(f"ë©”íƒ€ë°ì´í„°: {chunk.metadata}")
#         print("-" * 20)
