"""
ë§Œì¡±ë„ í†µí•© ë¡œë” - BaseLoader íŒ¨í„´ ì¤€ìˆ˜ ë¦¬íŒ©í† ë§
êµìœ¡ê³¼ì • ë§Œì¡±ë„(course_satisfaction.csv)ì™€ êµê³¼ëª© ë§Œì¡±ë„(subject_satisfaction.csv)ë¥¼ 
í†µí•© ì²˜ë¦¬í•˜ì—¬ ë‹¨ì¼ ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
"""

from typing import List, Dict, Any, Optional
from pathlib import Path

from modules.base_loader import BaseLoader, TextChunk
from utils.logging_utils import get_logger

logger = get_logger(__name__)

class SatisfactionLoader(BaseLoader):
    """ë§Œì¡±ë„ ë°ì´í„° í†µí•© ë¡œë” - BaseLoader í‘œì¤€ ì¤€ìˆ˜"""
    
    # ê¸°ì¡´ í…œí”Œë¦¿ ë³´ì¡´ (ì½”ë©ì—ì„œ ê²€ì¦ëœ ë¡œì§)
    COURSE_TEMPLATE = (
        "{êµìœ¡ì£¼ì°¨}ì— ê°œì„¤ëœ 'ì œ{êµìœ¡ê³¼ì •_ê¸°ìˆ˜}ê¸° {êµìœ¡ê³¼ì •}'ì€(ëŠ”) '{êµìœ¡ê³¼ì •_ìœ í˜•}'ìœ¼ë¡œ ë¶„ë¥˜ë˜ëŠ” êµìœ¡ê³¼ì •ìœ¼ë¡œ "
        "{êµìœ¡ì¼ì} {êµìœ¡ì¥ì†Œ}ì—ì„œ ì§„í–‰ë˜ì—ˆìœ¼ë©°, êµìœ¡ì¸ì›ì€ ì´ {êµìœ¡ì¸ì›}ëª…ì´ì—ˆìŠµë‹ˆë‹¤. "
        "'ì œ{êµìœ¡ê³¼ì •_ê¸°ìˆ˜}ê¸° {êµìœ¡ê³¼ì •}' êµìœ¡ìƒì˜ êµìœ¡ì— ëŒ€í•œ 'ì „ë°˜ì ì¸ ë§Œì¡±ë„'ëŠ” {ì „ë°˜ë§Œì¡±ë„}ì , "
        "êµìœ¡íš¨ê³¼ ì²´ê°ë„ ì§€í‘œì¸ 'ì—­ëŸ‰í–¥ìƒë„' ì ìˆ˜ëŠ” {ì—­ëŸ‰í–¥ìƒë„}ì , 'í˜„ì—…ì ìš©ë„'ëŠ” {í˜„ì—…ì ìš©ë„}ì ì´ì—ˆìŠµë‹ˆë‹¤. "
        "ë˜í•œ, 'êµê³¼í¸ì„± ë§Œì¡±ë„' {êµê³¼í¸ì„±_ë§Œì¡±ë„}ì , 'ì œ{êµìœ¡ê³¼ì •_ê¸°ìˆ˜}ê¸° {êµìœ¡ê³¼ì •}' ì „ì²´ ê°•ì˜ì— ëŒ€í•œ 'ê°•ì˜ë§Œì¡±ë„' í‰ê· ì€ {êµìœ¡ê³¼ì •ë³„_ê°•ì˜ë§Œì¡±ë„_í‰ê· }ì ì´ì—ˆìœ¼ë©°, "
        "'ì œ{êµìœ¡ê³¼ì •_ê¸°ìˆ˜}ê¸° {êµìœ¡ê³¼ì •}'ì— ëŒ€í•œ ëª¨ë“  ë§Œì¡±ë„ ì§€í‘œ í‰ê· ì¸ 'ì œ{êµìœ¡ê³¼ì •_ê¸°ìˆ˜}ê¸° {êµìœ¡ê³¼ì •}'ì˜ 'ì¢…í•©ë§Œì¡±ë„'ëŠ” {ì¢…í•©ë§Œì¡±ë„}ì ìœ¼ë¡œ "
        "'{êµìœ¡ì—°ë„}ë…„' ì „ì²´ êµìœ¡ê³¼ì • ì¤‘ '{êµìœ¡ê³¼ì •_ìˆœìœ„}ìœ„'ë¥¼ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤."
    )
    
    SUBJECT_TEMPLATE = (
        "{êµìœ¡ì£¼ì°¨}ì— ê°œì„¤ëœ 'ì œ{êµìœ¡ê³¼ì •_ê¸°ìˆ˜}ê¸° {êµìœ¡ê³¼ì •}'ì˜ '{êµê³¼ëª©(ê°•ì˜)}' êµê³¼ëª©(ê°•ì˜)ì— ëŒ€í•œ "
        "'ê°•ì˜ë§Œì¡±ë„'ëŠ” {ê°•ì˜ë§Œì¡±ë„}ì ìœ¼ë¡œ '{êµìœ¡ì—°ë„}ë…„' ìš´ì˜ëœ ì „ì²´ êµê³¼ëª©(ê°•ì˜) ì¤‘ '{êµê³¼ëª©(ê°•ì˜)_ìˆœìœ„}ìœ„'ë¥¼ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤."
    )
    
    def __init__(self):
        super().__init__(
            loader_id="satisfaction",
            source_dir="data/satisfaction",
            target_dir="vectorstores/vectorstore_unified_satisfaction",
            schema_dir="schemas"
        )
    
    def get_file_patterns(self) -> List[str]:
        """ì²˜ë¦¬í•  íŒŒì¼ íŒ¨í„´ ë°˜í™˜"""
        return ["course_satisfaction.csv", "subject_satisfaction.csv"]
    
    def process_domain_data(self, chunks: List[TextChunk]) -> List[TextChunk]:
        """
        ë§Œì¡±ë„ ë°ì´í„°ë¥¼ í†µí•© ì²˜ë¦¬ (BaseLoader í‘œì¤€ ì¤€ìˆ˜)
        
        Args:
            chunks: textifierë¡œ ì¶”ì¶œëœ CSV ì›ë³¸ ì²­í¬ë“¤ (row_data í¬í•¨)
            
        Returns:
            í…œí”Œë¦¿ì´ ì ìš©ëœ í†µí•© ì²˜ë¦¬ëœ ì²­í¬ë“¤
        """
        course_chunks = []
        subject_chunks = []
        
        # ì†ŒìŠ¤ë³„ë¡œ ì²­í¬ ë¶„ë¥˜
        for chunk in chunks:
            source_file = chunk.metadata.get("file_path", "")
            
            if "course_satisfaction.csv" in source_file:
                course_chunks.append(chunk)
            elif "subject_satisfaction.csv" in source_file:
                subject_chunks.append(chunk)
            else:
                logger.warning(f"Unknown satisfaction source file: {source_file}")
        
        # ê°ê° ì²˜ë¦¬
        processed_course = self._process_course_chunks(course_chunks)
        processed_subject = self._process_subject_chunks(subject_chunks)
        
        # í†µí•© ë°˜í™˜
        all_processed = processed_course + processed_subject
        logger.info(f"Processed {len(processed_course)} course + {len(processed_subject)} subject = {len(all_processed)} total satisfaction chunks")
        
        return all_processed
    
    def _process_course_chunks(self, chunks: List[TextChunk]) -> List[TextChunk]:
        """êµìœ¡ê³¼ì • ë§Œì¡±ë„ ì²­í¬ ì²˜ë¦¬ (BaseLoader íŒ¨í„´ ì¤€ìˆ˜)"""
        processed_chunks = []
        
        for chunk in chunks:
            try:
                # âœ… textifierê°€ ì €ì¥í•œ ì›ë³¸ row_data ì§ì ‘ ì‚¬ìš©
                row_data = chunk.metadata.get("row_data", {})
                if not row_data:
                    logger.warning(f"No row_data found in chunk metadata: {chunk.source_id}")
                    continue
                
                # í•„ìˆ˜ í•„ë“œ í™•ì¸ ë° ì•ˆì „í•œ ì²˜ë¦¬
                safe_row_data = self._validate_and_clean_course_data(row_data, chunk.source_id)
                if not safe_row_data:
                    continue
                
                # âœ… í…œí”Œë¦¿ ì§ì ‘ ì ìš© (íŒŒì‹± ê³¼ì • ìƒëµ)
                try:
                    formatted_content = self.COURSE_TEMPLATE.format(**safe_row_data)
                except KeyError as e:
                    logger.error(f"Template formatting failed for {chunk.source_id}: missing field {e}")
                    continue
                
                # ê²€ìƒ‰ ìµœì í™” ë©”íƒ€ë°ì´í„° ìƒì„±
                enhanced_metadata = {
                    **chunk.metadata,
                    "satisfaction_type": "course",
                    "education_course": safe_row_data.get('êµìœ¡ê³¼ì •', ''),
                    "course_session": self._safe_convert_to_string(safe_row_data.get('êµìœ¡ê³¼ì •_ê¸°ìˆ˜', '')),
                    "course_type": safe_row_data.get('êµìœ¡ê³¼ì •_ìœ í˜•', ''),
                    "education_week": safe_row_data.get('êµìœ¡ì£¼ì°¨', ''),
                    "education_year": self._safe_convert_to_string(safe_row_data.get('êµìœ¡ì—°ë„', '')),
                    "overall_satisfaction": self._safe_convert_to_float(safe_row_data.get('ì „ë°˜ë§Œì¡±ë„', '')),
                    "comprehensive_satisfaction": self._safe_convert_to_float(safe_row_data.get('ì¢…í•©ë§Œì¡±ë„', '')),
                    "course_ranking": self._safe_convert_to_int(safe_row_data.get('êµìœ¡ê³¼ì •_ìˆœìœ„', '')),
                    "capacity_improvement": self._safe_convert_to_float(safe_row_data.get('ì—­ëŸ‰í–¥ìƒë„', '')),
                    "work_application": self._safe_convert_to_float(safe_row_data.get('í˜„ì—…ì ìš©ë„', '')),
                    "curriculum_satisfaction": self._safe_convert_to_float(safe_row_data.get('êµê³¼í¸ì„±_ë§Œì¡±ë„', '')),
                    "lecture_satisfaction_avg": self._safe_convert_to_float(safe_row_data.get('êµìœ¡ê³¼ì •ë³„_ê°•ì˜ë§Œì¡±ë„_í‰ê· ', ''))
                }
                
                processed_chunk = TextChunk(
                    content=formatted_content,
                    metadata=enhanced_metadata,
                    source_id=chunk.source_id,
                    chunk_index=chunk.chunk_index
                )
                
                processed_chunks.append(processed_chunk)
                
            except Exception as e:
                logger.error(f"Failed to process course chunk from {chunk.source_id}: {e}")
                continue
        
        logger.info(f"Processed {len(processed_chunks)} course satisfaction chunks")
        return processed_chunks
    
    def _process_subject_chunks(self, chunks: List[TextChunk]) -> List[TextChunk]:
        """êµê³¼ëª© ë§Œì¡±ë„ ì²­í¬ ì²˜ë¦¬ (BaseLoader íŒ¨í„´ ì¤€ìˆ˜)"""
        processed_chunks = []
        
        for chunk in chunks:
            try:
                # âœ… textifierê°€ ì €ì¥í•œ ì›ë³¸ row_data ì§ì ‘ ì‚¬ìš©
                row_data = chunk.metadata.get("row_data", {})
                if not row_data:
                    logger.warning(f"No row_data found in chunk metadata: {chunk.source_id}")
                    continue
                
                # í•„ìˆ˜ í•„ë“œ í™•ì¸ ë° ì•ˆì „í•œ ì²˜ë¦¬
                safe_row_data = self._validate_and_clean_subject_data(row_data, chunk.source_id)
                if not safe_row_data:
                    continue
                
                # âœ… í…œí”Œë¦¿ ì§ì ‘ ì ìš© (íŒŒì‹± ê³¼ì • ìƒëµ)
                try:
                    formatted_content = self.SUBJECT_TEMPLATE.format(**safe_row_data)
                except KeyError as e:
                    logger.error(f"Template formatting failed for {chunk.source_id}: missing field {e}")
                    continue
                
                # ê²€ìƒ‰ ìµœì í™” ë©”íƒ€ë°ì´í„° ìƒì„±
                enhanced_metadata = {
                    **chunk.metadata,
                    "satisfaction_type": "subject",
                    "education_course": safe_row_data.get('êµìœ¡ê³¼ì •', ''),
                    "course_session": self._safe_convert_to_string(safe_row_data.get('êµìœ¡ê³¼ì •_ê¸°ìˆ˜', '')),
                    "subject_name": safe_row_data.get('êµê³¼ëª©(ê°•ì˜)', ''),
                    "education_week": safe_row_data.get('êµìœ¡ì£¼ì°¨', ''),
                    "education_year": self._safe_convert_to_string(safe_row_data.get('êµìœ¡ì—°ë„', '')),
                    "lecture_satisfaction": self._safe_convert_to_float(safe_row_data.get('ê°•ì˜ë§Œì¡±ë„', '')),
                    "subject_ranking": self._safe_convert_to_int(safe_row_data.get('êµê³¼ëª©(ê°•ì˜)_ìˆœìœ„', ''))
                }
                
                processed_chunk = TextChunk(
                    content=formatted_content,
                    metadata=enhanced_metadata,
                    source_id=chunk.source_id,
                    chunk_index=chunk.chunk_index
                )
                
                processed_chunks.append(processed_chunk)
                
            except Exception as e:
                logger.error(f"Failed to process subject chunk from {chunk.source_id}: {e}")
                continue
        
        logger.info(f"Processed {len(processed_chunks)} subject satisfaction chunks")
        return processed_chunks
    
    def _validate_and_clean_course_data(self, row_data: Dict[str, str], source_id: str) -> Optional[Dict[str, str]]:
        """êµìœ¡ê³¼ì • ë°ì´í„° ê²€ì¦ ë° ì •ì œ (validation_utils í™œìš©)"""
        from utils.validation_utils import satisfaction_validator
        
        try:
            clean_data = satisfaction_validator.validate_and_clean_course_data(row_data, source_id)
            return clean_data
        except Exception as e:
            logger.error(f"Course data validation failed for {source_id}: {e}")
            return None
    
    def _validate_and_clean_subject_data(self, row_data: Dict[str, str], source_id: str) -> Optional[Dict[str, str]]:
        """êµê³¼ëª© ë°ì´í„° ê²€ì¦ ë° ì •ì œ (validation_utils í™œìš©)"""
        from utils.validation_utils import satisfaction_validator
        
        try:
            clean_data = satisfaction_validator.validate_and_clean_subject_data(row_data, source_id)
            return clean_data
        except Exception as e:
            logger.error(f"Subject data validation failed for {source_id}: {e}")
            return None
    
    def _safe_convert_to_float(self, value: Any) -> float:
        """ì•ˆì „í•œ float ë³€í™˜ (validation_utils í™œìš©)"""
        from utils.validation_utils import satisfaction_validator
        return satisfaction_validator.safe_float_convert(value)
    
    def _safe_convert_to_int(self, value: Any) -> int:
        """ì•ˆì „í•œ int ë³€í™˜ (validation_utils í™œìš©)"""
        from utils.validation_utils import satisfaction_validator
        return satisfaction_validator.safe_int_convert(value)
    
    def _safe_convert_to_string(self, value: Any) -> str:
        """ì•ˆì „í•œ string ë³€í™˜ (validation_utils í™œìš©)"""
        from utils.validation_utils import satisfaction_validator
        return satisfaction_validator.clean_text_field(str(value) if value else '')
    
    def get_satisfaction_statistics(self) -> dict:
        """ë§Œì¡±ë„ í†µê³„ ì •ë³´ ë°˜í™˜ (ëª¨ë‹ˆí„°ë§ìš©)"""
        metadata = self.load_metadata()
        if not metadata:
            return {"status": "not_built"}
        
        return {
            "loader_id": self.loader_id,
            "total_chunks": metadata.total_chunks,
            "total_files": metadata.total_files,
            "last_build": metadata.last_build.isoformat(),
            "supported_types": ["course", "subject"],
            "templates_preserved": True,
            "baseloader_compliant": True,
            "templates": {
                "course_fields": [
                    "êµìœ¡ì£¼ì°¨", "êµìœ¡ê³¼ì •_ê¸°ìˆ˜", "êµìœ¡ê³¼ì •", "êµìœ¡ê³¼ì •_ìœ í˜•",
                    "ì „ë°˜ë§Œì¡±ë„", "ì—­ëŸ‰í–¥ìƒë„", "í˜„ì—…ì ìš©ë„", "ì¢…í•©ë§Œì¡±ë„", "êµìœ¡ê³¼ì •_ìˆœìœ„"
                ],
                "subject_fields": [
                    "êµìœ¡ì£¼ì°¨", "êµìœ¡ê³¼ì •_ê¸°ìˆ˜", "êµìœ¡ê³¼ì •", "êµê³¼ëª©(ê°•ì˜)",
                    "ê°•ì˜ë§Œì¡±ë„", "êµê³¼ëª©(ê°•ì˜)_ìˆœìœ„"
                ]
            }
        }
    
    def search_by_satisfaction_type(self, satisfaction_type: str) -> dict:
        """
        ë§Œì¡±ë„ íƒ€ì…ë³„ ê²€ìƒ‰ ì§€ì› ì •ë³´
        
        Args:
            satisfaction_type: "course" ë˜ëŠ” "subject"
            
        Returns:
            í•´ë‹¹ íƒ€ì…ì˜ ë©”íƒ€ë°ì´í„° í•„í„° ì •ë³´
        """
        if satisfaction_type == "course":
            return {
                "filter": {"satisfaction_type": "course"},
                "searchable_fields": [
                    "education_course", "course_type", "education_year",
                    "overall_satisfaction", "comprehensive_satisfaction",
                    "capacity_improvement", "work_application"
                ]
            }
        elif satisfaction_type == "subject":
            return {
                "filter": {"satisfaction_type": "subject"},
                "searchable_fields": [
                    "education_course", "subject_name", "education_year",
                    "lecture_satisfaction", "subject_ranking"
                ]
            }
        else:
            return {"error": "Invalid satisfaction_type. Use 'course' or 'subject'"}

# í¸ì˜ í•¨ìˆ˜ë“¤ (ê¸°ì¡´ API í˜¸í™˜ì„± ìœ ì§€)
def build_satisfaction_index(force_rebuild: bool = False) -> bool:
    """í†µí•© ë§Œì¡±ë„ ì¸ë±ìŠ¤ ë¹Œë“œ"""
    loader = SatisfactionLoader()
    return loader.build_index(force_rebuild=force_rebuild)

def get_satisfaction_status() -> dict:
    """ë§Œì¡±ë„ ë¡œë” ìƒíƒœ ì¡°íšŒ"""
    loader = SatisfactionLoader()
    return loader.get_satisfaction_statistics()

def search_course_satisfaction_info() -> dict:
    """êµìœ¡ê³¼ì • ë§Œì¡±ë„ ê²€ìƒ‰ ì§€ì› ì •ë³´"""
    loader = SatisfactionLoader()
    return loader.search_by_satisfaction_type("course")

def search_subject_satisfaction_info() -> dict:
    """êµê³¼ëª© ë§Œì¡±ë„ ê²€ìƒ‰ ì§€ì› ì •ë³´"""
    loader = SatisfactionLoader()
    return loader.search_by_satisfaction_type("subject")

# ìŠ¤í¬ë¦½íŠ¸ ì§ì ‘ ì‹¤í–‰ìš©
if __name__ == "__main__":
    import sys
    
    # ëª…ë ¹í–‰ ì¸ì ì²˜ë¦¬
    force_rebuild = "--force" in sys.argv
    show_stats = "--stats" in sys.argv
    
    if show_stats:
        stats = get_satisfaction_status()
        print(f"ğŸ“Š Satisfaction Statistics:")
        for key, value in stats.items():
            print(f"  {key}: {value}")
        sys.exit(0)
    
    print(f"Building unified satisfaction index (force_rebuild={force_rebuild})...")
    
    success = build_satisfaction_index(force_rebuild=force_rebuild)
    
    if success:
        stats = get_satisfaction_status()
        print(f"âœ… Build completed successfully!")
        print(f"ğŸ“Š Course + Subject combined: {stats.get('total_chunks', 0)} chunks")
        print(f"ğŸ” Search capabilities:")
        print(f"  - Course satisfaction: {search_course_satisfaction_info()}")
        print(f"  - Subject satisfaction: {search_subject_satisfaction_info()}")
    else:
        print("âŒ Build failed!")
        sys.exit(1)
