#!/usr/bin/env python3
"""
ê²½ìƒë‚¨ë„ì¸ì¬ê°œë°œì› RAG ì±—ë´‡ - ì¼ë°˜ ë„ë©”ì¸ ë¡œë” (BaseLoader íŒ¨í„´ ì¤€ìˆ˜)

notice ë¡œë” íŒ¨í„´ì„ ë”°ë¼ ì™„ì „íˆ ìˆ˜ì •ë¨:
- process_domain_data(self) ì‹œê·¸ë‹ˆì²˜ë¡œ ë³€ê²½
- ì›ë³¸ íŒŒì¼ ì§ì ‘ ì½ê¸° ë¡œì§ ì¶”ê°€
- BaseLoader í‘œì¤€ íŒ¨í„´ ì™„ì „ ì¤€ìˆ˜
- ê¸°ì¡´ í…œí”Œë¦¿ ì‹œìŠ¤í…œ ìœ ì§€
"""

import logging
import pandas as pd
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime

# PyPDF2 ì§ì ‘ ì„í¬íŠ¸ (PDFProcessor ì˜ì¡´ì„± ì œê±°)
try:
    from PyPDF2 import PdfReader
    PDF_AVAILABLE = True
except ImportError:
    PDF_AVAILABLE = False

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì„í¬íŠ¸
from modules.base_loader import BaseLoader
from utils.textifier import TextChunk, PDFProcessor
from utils.config import config

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)


class GeneralLoader(BaseLoader):
    """
    ì¼ë°˜ ë„ë©”ì¸ ë¡œë” - BaseLoader í‘œì¤€ íŒ¨í„´ ì¤€ìˆ˜
    
    ì²˜ë¦¬ ëŒ€ìƒ:
    - data/general/hakchik.pdf (í•™ì¹™+ê°ì ê¸°ì¤€+ì „ê²°ê·œì • í†µí•©ë¬¸ì„œ)
    - data/general/operation_test.pdf (ìš´ì˜/í‰ê°€ ê³„íš)
    - data/general/task_telephone.csv (ì—…ë¬´ë‹´ë‹¹ì ì—°ë½ì²˜)
    
    íŠ¹ì§•:
    - notice ë¡œë”ì™€ ë™ì¼í•œ process_domain_data(self) ì‹œê·¸ë‹ˆì²˜
    - ì›ë³¸ íŒŒì¼ ì§ì ‘ ì½ê¸°
    - PyPDF2 ì§ì ‘ ì‚¬ìš© (PDFProcessor ì˜ì¡´ì„± ì œê±°)
    - ê¸°ì¡´ ì½”ë© í…œí”Œë¦¿ ì™„ë²½ ë³´ì¡´
    - í•´ì‹œ ê¸°ë°˜ ì¦ë¶„ ë¹Œë“œ ì§€ì›
    """
    
    def __init__(self):
        super().__init__(
            domain="general",
            source_dir=config.ROOT_DIR / "data" / "general",
            vectorstore_dir=config.ROOT_DIR / "vectorstores" / "vectorstore_general",
            index_name="general_index"
        )

        
        # ì²˜ë¦¬í•  íŒŒì¼ ì •ì˜
        self.hakchik_file = self.source_dir / "hakchik.pdf"
        self.operation_file = self.source_dir / "operation_test.pdf"
        self.telephone_file = self.source_dir / "task_telephone.csv"
    
    def process_domain_data(self) -> List[TextChunk]:
        """
        BaseLoader ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„: ì¼ë°˜ ë„ë©”ì¸ ë°ì´í„° ì²˜ë¦¬
        
        âœ… notice ë¡œë”ì™€ ë™ì¼í•œ ì‹œê·¸ë‹ˆì²˜: process_domain_data(self)
        """
        all_chunks = []
        
        # 1. PDF íŒŒì¼ë“¤ ì²˜ë¦¬
        pdf_chunks = self._process_pdf_files()
        all_chunks.extend(pdf_chunks)
        
        # 2. CSV íŒŒì¼ ì²˜ë¦¬ (ì—…ë¬´ë‹´ë‹¹ì ì—°ë½ì²˜)
        csv_chunks = self._process_telephone_csv()
        all_chunks.extend(csv_chunks)
        
        logger.info(f"âœ… ì¼ë°˜ ë„ë©”ì¸ í†µí•© ì²˜ë¦¬ ì™„ë£Œ: PDF {len(pdf_chunks)}ê°œ + CSV {len(csv_chunks)}ê°œ = ì´ {len(all_chunks)}ê°œ ì²­í¬")
        
        return all_chunks
    
    def _process_pdf_files(self) -> List[TextChunk]:
        """PDF íŒŒì¼ë“¤ ì§ì ‘ ì½ê¸° ë° ì²˜ë¦¬ (PyPDF2 ì§ì ‘ ì‚¬ìš©)"""
        chunks = []
        
        if not PDF_AVAILABLE:
            logger.error("âŒ PyPDF2 ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return chunks
        
        pdf_files = [
            (self.hakchik_file, "regulations", "í†µí•©ê·œì •ë¬¸ì„œ"),
            (self.operation_file, "operations", "ìš´ì˜í‰ê°€ê³„íš")
        ]
        
        for pdf_file, category, doc_type in pdf_files:
            if not pdf_file.exists():
                logger.warning(f"PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {pdf_file}")
                continue
            
            try:
                logger.info(f"ğŸ“„ PDF ì²˜ë¦¬ ì‹œì‘: {pdf_file}")
                
                # PyPDF2ë¡œ ì§ì ‘ PDF ì½ê¸°
                with open(pdf_file, 'rb') as file:
                    pdf_reader = PdfReader(file)
                    total_pages = len(pdf_reader.pages)
                    
                    logger.info(f"PDF ì´ í˜ì´ì§€ ìˆ˜: {total_pages}")
                    
                    for page_num, page in enumerate(pdf_reader.pages, 1):
                        try:
                            # í˜ì´ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                            page_text = page.extract_text()
                            
                            if not page_text or len(page_text.strip()) < 50:
                                logger.debug(f"í˜ì´ì§€ {page_num}: í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ê±°ë‚˜ ì—†ìŒ (ê±´ë„ˆëœ€)")
                                continue
                            
                            # í…ìŠ¤íŠ¸ ì²­í¬ ìƒì„±
                            chunk_text = f"[{doc_type}] í˜ì´ì§€ {page_num}\n\n{page_text.strip()}"
                            
                            # ë©”íƒ€ë°ì´í„° ìƒì„±
                            metadata = {
                                'source_file': pdf_file.name,
                                'file_type': 'pdf',
                                'category': category,
                                'doc_type': doc_type,
                                'domain': 'general',
                                'page_number': page_num,
                                'total_pages': total_pages,
                                'char_count': len(page_text),
                                'cache_ttl': 2592000,  # 30ì¼ TTL
                                'processing_date': datetime.now().isoformat(),
                                'chunk_type': 'document'
                            }
                            
                            chunk = TextChunk(
                                text=chunk_text,
                                source_id=f'general/{pdf_file.name}#page_{page_num}',
                                metadata=metadata
                            )
                            
                            chunks.append(chunk)
                            
                        except Exception as e:
                            logger.error(f"í˜ì´ì§€ {page_num} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                            continue
                
                logger.info(f"âœ… {pdf_file.name} ì²˜ë¦¬ ì™„ë£Œ: {len([c for c in chunks if c.metadata.get('source_file') == pdf_file.name])}ê°œ ì²­í¬")
                
            except Exception as e:
                logger.error(f"âŒ PDF íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨ ({pdf_file}): {e}")
                continue
        
        return chunks
    
    def _process_telephone_csv(self) -> List[TextChunk]:
        """ì—…ë¬´ë‹´ë‹¹ì ì—°ë½ì²˜ CSV ì§ì ‘ ì½ê¸° ë° ì²˜ë¦¬ (ê¸°ì¡´ ì½”ë© í…œí”Œë¦¿ ë³´ì¡´)"""
        chunks = []
        
        if not self.telephone_file.exists():
            logger.warning(f"ì—°ë½ì²˜ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {self.telephone_file}")
            return chunks
        
        try:
            logger.info(f"ğŸ“ ì—°ë½ì²˜ CSV ì²˜ë¦¬ ì‹œì‘: {self.telephone_file}")
            
            # CSV ì¸ì½”ë”© ìë™ ê°ì§€ ë° ì½ê¸°
            df = self._read_csv_with_encoding(self.telephone_file)
            
            if df is None:
                return chunks
            
            logger.info(f"ğŸ“„ ì—°ë½ì²˜ ë°ì´í„°: {len(df)}í–‰ ë¡œë“œë¨")
            
            # ê° í–‰ì„ ê¸°ì¡´ ì½”ë© í…œí”Œë¦¿ìœ¼ë¡œ ë³€í™˜
            for idx, row in df.iterrows():
                try:
                    # ê¸°ì¡´ ì½”ë© í…œí”Œë¦¿ ì™„ë²½ ë³´ì¡´
                    chunk_text = (
                        f"ë‹´ë‹¹ì—…ë¬´: {row['ë‹´ë‹¹ì—…ë¬´']}\n"
                        f"  - ë‹´ë‹¹ì: {row['ë¶€ì„œ']} {row['ì§ì±…']}\n"
                        f"  - ì—°ë½ì²˜: {row['ì „í™”ë²ˆí˜¸']}\n"
                    )
                    
                    # ë©”íƒ€ë°ì´í„° ìƒì„±
                    metadata = {
                        'source_file': 'task_telephone.csv',
                        'file_type': 'csv',
                        'category': 'contact',
                        'doc_type': 'ì—…ë¬´ë‹´ë‹¹ìì—°ë½ì²˜',
                        'domain': 'general',
                        'row_index': idx,
                        'department': str(row['ë¶€ì„œ']),
                        'position': str(row['ì§ì±…']),
                        'phone': str(row['ì „í™”ë²ˆí˜¸']),
                        'task_area': str(row['ë‹´ë‹¹ì—…ë¬´']),
                        'cache_ttl': 2592000,  # 30ì¼ TTL
                        'processing_date': datetime.now().isoformat(),
                        'chunk_type': 'contact'
                    }
                    
                    chunk = TextChunk(
                        text=chunk_text,
                        source_id=f'general/task_telephone.csv#row_{idx}',
                        metadata=metadata
                    )
                    
                    chunks.append(chunk)
                    
                except Exception as e:
                    logger.error(f"ì—°ë½ì²˜ í–‰ {idx} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    continue
            
            logger.info(f"âœ… ì—°ë½ì²˜ CSV ì²˜ë¦¬ ì™„ë£Œ: {len(chunks)}ê°œ ì²­í¬ ìƒì„± (ê¸°ì¡´ í…œí”Œë¦¿ ë³´ì¡´)")
            
        except Exception as e:
            logger.error(f"âŒ ì—°ë½ì²˜ CSV íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        
        return chunks
    
    def _read_csv_with_encoding(self, csv_file: Path) -> Optional[pd.DataFrame]:
        """ì¸ì½”ë”© ìë™ ê°ì§€ë¡œ CSV ì½ê¸°"""
        encodings = ['utf-8', 'cp949', 'euc-kr', 'utf-8-sig']
        
        for encoding in encodings:
            try:
                df = pd.read_csv(csv_file, encoding=encoding)
                logger.info(f"CSV íŒŒì¼ ë¡œë“œ ì„±ê³µ (ì¸ì½”ë”©: {encoding})")
                
                # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
                required_columns = ['ë¶€ì„œ', 'ì§ì±…', 'ì „í™”ë²ˆí˜¸', 'ë‹´ë‹¹ì—…ë¬´']
                missing_columns = [col for col in required_columns if col not in df.columns]
                
                if missing_columns:
                    logger.error(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_columns}")
                    logger.error(f"ì‹¤ì œ ì»¬ëŸ¼: {list(df.columns)}")
                    return None
                
                return df
                
            except UnicodeDecodeError:
                logger.debug(f"ì¸ì½”ë”© {encoding} ì‹¤íŒ¨, ë‹¤ìŒ ì‹œë„...")
                continue
            except Exception as e:
                logger.error(f"CSV íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ (ì¸ì½”ë”©: {encoding}): {e}")
                continue
        
        logger.error(f"ëª¨ë“  ì¸ì½”ë”© ì‹œë„ ì‹¤íŒ¨: {csv_file}")
        return None


# ================================================================
# ê°œë°œ/í…ŒìŠ¤íŠ¸ìš© ì§„ì…ì 
# ================================================================

def main():
    """ê°œë°œ/í…ŒìŠ¤íŠ¸ìš© ì§„ì…ì """
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    loader = GeneralLoader()
    
    try:
        # BaseLoaderì˜ í‘œì¤€ ì¸í„°í˜ì´ìŠ¤ ì‚¬ìš©
        success = loader.build_vectorstore()
        
        if success:
            logger.info("âœ… ì¼ë°˜ ë„ë©”ì¸ ë²¡í„°ìŠ¤í† ì–´ êµ¬ì¶• ì™„ë£Œ")
        else:
            logger.error("âŒ ì¼ë°˜ ë„ë©”ì¸ ë²¡í„°ìŠ¤í† ì–´ êµ¬ì¶• ì‹¤íŒ¨")
            
    except Exception as e:
        logger.error(f"âŒ ë¡œë” ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        raise


if __name__ == '__main__':
    main()
