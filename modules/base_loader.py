#!/usr/bin/env python3
"""
ê²½ìƒë‚¨ë„ì¸ì¬ê°œë°œì› RAG ì±—ë´‡ - BaseLoader ê¸°ë³¸ í´ë˜ìŠ¤ (ê°œì„ ë²„ì „)

ì£¼ìš” ê°œì„ ì‚¬í•­:
- config.pyì—ì„œ ì„ë² ë”© ëª¨ë¸ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
- ì°¨ì› ê²€ì¦ ì¶”ê°€
- ë” ê°•í™”ëœ ì—ëŸ¬ ì²˜ë¦¬
- ë§ˆì´ê·¸ë ˆì´ì…˜ ì§€ì›
"""

import logging
import hashlib
import time
import pickle
import os
from abc import ABC, abstractmethod
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì„í¬íŠ¸
from utils.textifier import TextChunk

# Config ì„í¬íŠ¸ (ë™ì  ì„í¬íŠ¸ë¡œ ì—ëŸ¬ ë°©ì§€)
try:
    from config import config
    CONFIG_AVAILABLE = True
    EMBEDDING_MODEL = config.EMBEDDING_MODEL
    EMBEDDING_DIMENSION = config.EMBEDDING_DIMENSION
except ImportError:
    CONFIG_AVAILABLE = False
    EMBEDDING_MODEL = "text-embedding-3-large"  # í´ë°±
    EMBEDDING_DIMENSION = 3072
    logging.warning("config.pyë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ê°’ ì‚¬ìš©")

# ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì„ íƒì )
try:
    from langchain_community.vectorstores import FAISS
    from langchain_openai import OpenAIEmbeddings
    FAISS_AVAILABLE = True
except ImportError:
    try:
        from langchain.vectorstores import FAISS
        from langchain.embeddings import OpenAIEmbeddings
        FAISS_AVAILABLE = True
    except ImportError:
        FAISS_AVAILABLE = False

# BM25 ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì„ íƒì )
try:
    from rank_bm25 import BM25Okapi
    BM25_AVAILABLE = True
except ImportError:
    BM25_AVAILABLE = False

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)


class BaseLoader(ABC):
    """
    ëª¨ë“  ë„ë©”ì¸ ë¡œë”ì˜ ê¸°ë³¸ í´ë˜ìŠ¤ (ê°œì„ ë²„ì „)
    
    ê°œì„ ì‚¬í•­:
    - config ê¸°ë°˜ ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©
    - ì°¨ì› ê²€ì¦ ì¶”ê°€
    - ë§ˆì´ê·¸ë ˆì´ì…˜ ì§€ì›
    """
    
    def __init__(self, domain=None, loader_id=None, source_dir=None, vectorstore_dir=None, target_dir=None, index_name=None, schema_dir=None, **kwargs):
        """
        BaseLoader ì´ˆê¸°í™”
        """
        # í˜¸í™˜ì„± ì²˜ë¦¬
        self.domain = domain or loader_id
        self.source_dir = Path(source_dir or ".")
    
        # target_dirë„ ë°›ê¸° (vectorstore_dir ëŒ€ì‹ )
        if target_dir:
            self.vectorstore_dir = Path(target_dir)
        else:
            self.vectorstore_dir = Path(vectorstore_dir or ".")
    
        # index_name ê¸°ë³¸ê°’ ì„¤ì •  
        self.index_name = index_name or f"{self.domain}_index"
        
        # ì„ë² ë”© ì„¤ì • ì´ˆê¸°í™”
        self.embedding_model = EMBEDDING_MODEL
        self.embedding_dimension = EMBEDDING_DIMENSION
        self.embeddings = None
        
        # ë””ë ‰í„°ë¦¬ ìƒì„±
        self.vectorstore_dir.mkdir(parents=True, exist_ok=True)
        
        # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        self._initialize_embeddings()
    
        logger.info(f"âœ¨ {self.domain.upper()} BaseLoader ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info(f"   - ì„ë² ë”© ëª¨ë¸: {self.embedding_model}")
        logger.info(f"   - ì˜ˆìƒ ì°¨ì›: {self.embedding_dimension}")
    
    def _initialize_embeddings(self):
        """ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            if not FAISS_AVAILABLE:
                logger.warning("FAISS ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ì–´ ì„ë² ë”© ì´ˆê¸°í™” ê±´ë„ˆëœ€")
                return
            
            self.embeddings = OpenAIEmbeddings(
                model=self.embedding_model,
                api_key=os.getenv("OPENAI_API_KEY")
            )
            
            # ì°¨ì› ê²€ì¦ (í…ŒìŠ¤íŠ¸ ì„ë² ë”©)
            try:
                test_vector = self.embeddings.embed_query("test")
                actual_dimension = len(test_vector)
                
                if actual_dimension != self.embedding_dimension:
                    logger.warning(
                        f"âš ï¸ {self.domain} ì°¨ì› ë¶ˆì¼ì¹˜: "
                        f"ì˜ˆìƒ={self.embedding_dimension}, ì‹¤ì œ={actual_dimension}"
                    )
                    self.embedding_dimension = actual_dimension  # ì‹¤ì œ ì°¨ì›ìœ¼ë¡œ ì—…ë°ì´íŠ¸
                
                logger.info(f"âœ… {self.domain} ì„ë² ë”© ì´ˆê¸°í™” ì„±ê³µ ({actual_dimension}ì°¨ì›)")
                
            except Exception as e:
                logger.warning(f"âš ï¸ {self.domain} ì°¨ì› ê²€ì¦ ì‹¤íŒ¨: {e}")
                
        except Exception as e:
            logger.error(f"âŒ {self.domain} ì„ë² ë”© ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.embeddings = None
    
    @abstractmethod
    def process_domain_data(self) -> List[TextChunk]:
        """
        ë„ë©”ì¸ë³„ ë°ì´í„° ì²˜ë¦¬ (ê° ë¡œë”ì—ì„œ êµ¬í˜„)
        
        Returns:
            List[TextChunk]: ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸ ì²­í¬ë“¤
        """
        pass
    
    def get_supported_extensions(self) -> List[str]:
        """ì§€ì›í•˜ëŠ” íŒŒì¼ í™•ì¥ì (ì„ íƒì  ì˜¤ë²„ë¼ì´ë“œ)"""
        return ['.pdf', '.csv', '.txt', '.png', '.jpg']
    
    def validate_schema(self, file_path: Path, schema_path: Path) -> bool:
        """
        ìŠ¤í‚¤ë§ˆ ê²€ì¦ (ì„ íƒì )
        
        Args:
            file_path: ê²€ì¦í•  íŒŒì¼ ê²½ë¡œ
            schema_path: ìŠ¤í‚¤ë§ˆ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            bool: ê²€ì¦ ì„±ê³µ ì—¬ë¶€
        """
        try:
            # ê°„ë‹¨í•œ íŒŒì¼ ì¡´ì¬ ê²€ì¦
            return file_path.exists()
        except Exception as e:
            logger.warning(f"ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return True  # ê²€ì¦ ì‹¤íŒ¨í•´ë„ ì²˜ë¦¬ ê³„ì†
    
    def calculate_source_hash(self) -> str:
        """ì†ŒìŠ¤ ë°ì´í„° í•´ì‹œ ê³„ì‚° (ì¦ë¶„ ë¹Œë“œìš©)"""
        try:
            hash_md5 = hashlib.md5()
            
            # ì„ë² ë”© ëª¨ë¸ë„ í•´ì‹œì— í¬í•¨ (ëª¨ë¸ ë³€ê²½ ì‹œ ì¬ë¹Œë“œ)
            hash_md5.update(self.embedding_model.encode())
            
            # ì†ŒìŠ¤ ë””ë ‰í„°ë¦¬ì˜ ëª¨ë“  íŒŒì¼ í•´ì‹œ ê³„ì‚°
            for file_path in self.source_dir.rglob('*'):
                if file_path.is_file() and file_path.suffix in self.get_supported_extensions():
                    hash_md5.update(str(file_path.stat().st_mtime).encode())
                    hash_md5.update(str(file_path.stat().st_size).encode())
            
            return hash_md5.hexdigest()[:16]
        except Exception as e:
            logger.warning(f"í•´ì‹œ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return str(int(time.time()))  # í´ë°±: íƒ€ì„ìŠ¤íƒ¬í”„
    
    def check_existing_dimension(self) -> Optional[int]:
        """ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ì˜ ì°¨ì› í™•ì¸"""
        try:
            # ì°¨ì› ì •ë³´ íŒŒì¼ í™•ì¸
            dimension_file = self.vectorstore_dir / f"{self.index_name}_dimension_info.json"
            if dimension_file.exists():
                import json
                with open(dimension_file, 'r') as f:
                    info = json.load(f)
                return info.get('dimension')
            
            # FAISS íŒŒì¼ì—ì„œ ì§ì ‘ í™•ì¸
            faiss_file = self.vectorstore_dir / f"{self.index_name}.faiss"
            if faiss_file.exists() and self.embeddings:
                try:
                    vectorstore = FAISS.load_local(
                        folder_path=str(self.vectorstore_dir),
                        embeddings=self.embeddings,
                        index_name=self.index_name,
                        allow_dangerous_deserialization=True
                    )
                    if hasattr(vectorstore, 'index'):
                        return vectorstore.index.d
                except Exception:
                    pass
            
            return None
            
        except Exception as e:
            logger.warning(f"ê¸°ì¡´ ì°¨ì› í™•ì¸ ì‹¤íŒ¨: {e}")
            return None
    
    def needs_rebuild(self) -> bool:
        """ì¬ë¹Œë“œ í•„ìš” ì—¬ë¶€ í™•ì¸ (ì°¨ì› ê²€ì¦ í¬í•¨)"""
        try:
            # FAISS íŒŒì¼ í™•ì¸
            faiss_file = self.vectorstore_dir / f"{self.index_name}.faiss"
            pkl_file = self.vectorstore_dir / f"{self.index_name}.pkl"
            bm25_file = self.vectorstore_dir / f"{self.index_name}.bm25"
            
            # FAISS íŒŒì¼ì´ ì—†ìœ¼ë©´ ë¹Œë“œ í•„ìš”
            if not (faiss_file.exists() and pkl_file.exists()):
                logger.info(f"ğŸ”¨ {self.domain}: FAISS íŒŒì¼ì´ ì—†ì–´ì„œ ìƒˆë¡œ ë¹Œë“œ")
                return True
                
            # BM25 íŒŒì¼ì´ ì—†ìœ¼ë©´ ë¹Œë“œ í•„ìš”
            if not bm25_file.exists():
                logger.info(f"ğŸ”¨ {self.domain}: BM25 íŒŒì¼ì´ ì—†ì–´ì„œ ìƒˆë¡œ ë¹Œë“œ")
                return True
            
            # ì°¨ì› í˜¸í™˜ì„± í™•ì¸
            existing_dimension = self.check_existing_dimension()
            if existing_dimension and existing_dimension != self.embedding_dimension:
                logger.info(
                    f"ğŸ”¨ {self.domain}: ì°¨ì› ë¶ˆì¼ì¹˜ë¡œ ì¬ë¹Œë“œ í•„ìš” "
                    f"(ê¸°ì¡´={existing_dimension}, í˜„ì¬={self.embedding_dimension})"
                )
                return True
            
            # í•´ì‹œ íŒŒì¼ í™•ì¸
            hash_file = self.vectorstore_dir / ".source_hash"
            if not hash_file.exists():
                logger.info(f"ğŸ”¨ {self.domain}: í•´ì‹œ íŒŒì¼ì´ ì—†ì–´ì„œ ìƒˆë¡œ ë¹Œë“œ")
                return True
            
            # í•´ì‹œ ë¹„êµ
            current_hash = self.calculate_source_hash()
            with open(hash_file, 'r') as f:
                stored_hash = f.read().strip()
            
            if current_hash != stored_hash:
                logger.info(f"ğŸ”¨ {self.domain}: ì†ŒìŠ¤ ë°ì´í„° ë³€ê²½ìœ¼ë¡œ ì¬ë¹Œë“œ")
                return True
            
            logger.info(f"âœ… {self.domain}: FAISS + BM25ê°€ ìµœì‹  ìƒíƒœ")
            return False
            
        except Exception as e:
            logger.warning(f"ì¬ë¹Œë“œ í™•ì¸ ì‹¤íŒ¨: {e}")
            return True  # í™•ì¸ ì‹¤íŒ¨ ì‹œ ì•ˆì „í•˜ê²Œ ì¬ë¹Œë“œ
    
    def save_source_hash(self):
        """í˜„ì¬ ì†ŒìŠ¤ í•´ì‹œ ì €ì¥"""
        try:
            current_hash = self.calculate_source_hash()
            hash_file = self.vectorstore_dir / ".source_hash"
            with open(hash_file, 'w') as f:
                f.write(current_hash)
            logger.debug(f"ğŸ“ {self.domain}: ì†ŒìŠ¤ í•´ì‹œ ì €ì¥ë¨")
        except Exception as e:
            logger.warning(f"í•´ì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def save_dimension_info(self, vector_count: int):
        """ì°¨ì› ì •ë³´ ì €ì¥ (ë””ë²„ê¹…ìš©)"""
        try:
            dimension_info = {
                'model': self.embedding_model,
                'dimension': self.embedding_dimension,
                'vector_count': vector_count,
                'created_at': datetime.now().isoformat(),
                'domain': self.domain
            }
            
            dimension_file = self.vectorstore_dir / f"{self.index_name}_dimension_info.json"
            import json
            with open(dimension_file, 'w') as f:
                json.dump(dimension_info, f, indent=2)
                
            logger.debug(f"ğŸ“ {self.domain}: ì°¨ì› ì •ë³´ ì €ì¥ë¨")
            
        except Exception as e:
            logger.warning(f"ì°¨ì› ì •ë³´ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def build_vectorstore(self, force_rebuild: bool = False) -> bool:
        """
        ë²¡í„°ìŠ¤í† ì–´ ë¹Œë“œ (ì¦ë¶„ ë¹Œë“œ ì§€ì›)
        
        Args:
            force_rebuild: ê°•ì œ ì¬ë¹Œë“œ ì—¬ë¶€
            
        Returns:
            bool: ë¹Œë“œ ì„±ê³µ ì—¬ë¶€
        """
        try:
            # ì„ë² ë”© ëª¨ë¸ í™•ì¸
            if not self.embeddings:
                logger.error(f"âŒ {self.domain}: ì„ë² ë”© ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
                return False
            
            # ì¬ë¹Œë“œ í•„ìš”ì„± í™•ì¸
            if not force_rebuild and not self.needs_rebuild():
                logger.info(f"â­ï¸ {self.domain}: ì´ë¯¸ ìµœì‹  ë²¡í„°ìŠ¤í† ì–´ ì¡´ì¬")
                return True
            
            logger.info(f"ğŸ”¨ {self.domain}: ë²¡í„°ìŠ¤í† ì–´ ë¹Œë“œ ì‹œì‘...")
            logger.info(f"   - ëª¨ë¸: {self.embedding_model}")
            logger.info(f"   - ì°¨ì›: {self.embedding_dimension}")
            start_time = time.time()
            
            # 1. ë„ë©”ì¸ ë°ì´í„° ì²˜ë¦¬
            chunks = self.process_domain_data()
            
            if not chunks:
                logger.warning(f"âš ï¸ {self.domain}: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                return False
            
            logger.info(f"ğŸ“„ {self.domain}: {len(chunks)}ê°œ ì²­í¬ ìƒì„±ë¨")
            
            # 2. FAISS ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
            if not FAISS_AVAILABLE:
                logger.error(f"âŒ {self.domain}: FAISS ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
                return False
            
            success = self._create_faiss_vectorstore(chunks)
            
            if success:
                # 3. í•´ì‹œ ë° ì°¨ì› ì •ë³´ ì €ì¥
                self.save_source_hash()
                self.save_dimension_info(len(chunks))
                
                elapsed_time = time.time() - start_time
                logger.info(f"âœ… {self.domain}: ë²¡í„°ìŠ¤í† ì–´ ë¹Œë“œ ì™„ë£Œ ({elapsed_time:.2f}s)")
                return True
            else:
                logger.error(f"âŒ {self.domain}: ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            logger.error(f"âŒ {self.domain}: ë²¡í„°ìŠ¤í† ì–´ ë¹Œë“œ ì¤‘ ì˜ˆì™¸: {e}")
            return False
    
    def _create_faiss_vectorstore(self, chunks: List[TextChunk]) -> bool:
        """FAISS ë²¡í„°ìŠ¤í† ì–´ + BM25 ì¸ë±ìŠ¤ í†µí•© ìƒì„±"""
        try:
            # í…ìŠ¤íŠ¸ì™€ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
            texts = [chunk.text for chunk in chunks]
            metadatas = [chunk.metadata for chunk in chunks]
            
            logger.info(f"ğŸ”„ {self.domain}: FAISS ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì¤‘...")
            
            # FAISS ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
            vectorstore = FAISS.from_texts(
                texts=texts,
                embedding=self.embeddings,
                metadatas=metadatas
            )
            
            # ì°¨ì› ê²€ì¦
            if hasattr(vectorstore, 'index'):
                actual_dim = vectorstore.index.d
                if actual_dim != self.embedding_dimension:
                    logger.warning(
                        f"âš ï¸ {self.domain} ìƒì„±ëœ ë²¡í„°ìŠ¤í† ì–´ ì°¨ì› ë¶ˆì¼ì¹˜: "
                        f"ì˜ˆìƒ={self.embedding_dimension}, ì‹¤ì œ={actual_dim}"
                    )
                    self.embedding_dimension = actual_dim  # ì‹¤ì œ ì°¨ì›ìœ¼ë¡œ ì—…ë°ì´íŠ¸
            
            # FAISS ì €ì¥
            vectorstore.save_local(
                folder_path=str(self.vectorstore_dir),
                index_name=self.index_name
            )
            
            # âœ… BM25 ì¸ë±ìŠ¤ ìƒì„± ë° ì €ì¥
            bm25_success = self._create_bm25_index(texts, metadatas)
            
            # ìƒì„± í™•ì¸
            faiss_file = self.vectorstore_dir / f"{self.index_name}.faiss"
            pkl_file = self.vectorstore_dir / f"{self.index_name}.pkl"
            bm25_file = self.vectorstore_dir / f"{self.index_name}.bm25"
            
            if faiss_file.exists() and pkl_file.exists():
                faiss_size = faiss_file.stat().st_size / (1024*1024)
                bm25_size = bm25_file.stat().st_size / (1024*1024) if bm25_file.exists() else 0
                
                logger.info(f"ğŸ’¾ {self.domain}: FAISS ì €ì¥ë¨ ({faiss_size:.1f}MB)")
                if bm25_success:
                    logger.info(f"ğŸ’¾ {self.domain}: BM25 ì €ì¥ë¨ ({bm25_size:.1f}MB)")
                else:
                    logger.warning(f"âš ï¸ {self.domain}: BM25 ìƒì„± ì‹¤íŒ¨")
                
                return True
            else:
                logger.error(f"âŒ {self.domain}: ë²¡í„°ìŠ¤í† ì–´ íŒŒì¼ ìƒì„± ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            logger.error(f"âŒ {self.domain}: FAISS ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def _create_bm25_index(self, texts: List[str], metadatas: List[Dict]) -> bool:
        """BM25 ì¸ë±ìŠ¤ ìƒì„± ë° ì €ì¥"""
        try:
            if not BM25_AVAILABLE:
                logger.warning(f"âš ï¸ {self.domain}: rank_bm25 ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ì–´ BM25 ì¸ë±ìŠ¤ ê±´ë„ˆëœ€")
                return False
            
            logger.info(f"ğŸ” {self.domain}: BM25 ì¸ë±ìŠ¤ ìƒì„± ì¤‘...")
            
            # í…ìŠ¤íŠ¸ í† í°í™” (ê°„ë‹¨í•œ ê³µë°± ê¸°ë°˜)
            tokenized_texts = [text.lower().split() for text in texts]
            
            # BM25 ì¸ë±ìŠ¤ ìƒì„±
            bm25_index = BM25Okapi(tokenized_texts)
            
            # BM25 ë°ì´í„° íŒ¨í‚¤ì§•
            bm25_data = {
                'bm25_index': bm25_index,
                'texts': texts,
                'metadatas': metadatas,
                'tokenized_texts': tokenized_texts,
                'domain': self.domain,
                'embedding_model': self.embedding_model,  # ëª¨ë¸ ì •ë³´ ì¶”ê°€
                'embedding_dimension': self.embedding_dimension,  # ì°¨ì› ì •ë³´ ì¶”ê°€
                'created_at': datetime.now().isoformat(),
                'total_documents': len(texts)
            }
            
            # .bm25 íŒŒì¼ë¡œ ì €ì¥
            bm25_file = self.vectorstore_dir / f"{self.index_name}.bm25"
            with open(bm25_file, 'wb') as f:
                pickle.dump(bm25_data, f)
            
            logger.info(f"âœ… {self.domain}: BM25 ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ ({len(texts)}ê°œ ë¬¸ì„œ)")
            return True
            
        except Exception as e:
            logger.error(f"âŒ {self.domain}: BM25 ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
            return False
    
    def load_vectorstore(self) -> Optional[FAISS]:
        """ìƒì„±ëœ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ"""
        try:
            if not FAISS_AVAILABLE:
                logger.error("FAISS ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
                return None
            
            if not self.embeddings:
                logger.error(f"âŒ {self.domain}: ì„ë² ë”© ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
                return None
            
            vectorstore = FAISS.load_local(
                folder_path=str(self.vectorstore_dir),
                embeddings=self.embeddings,
                index_name=self.index_name,
                allow_dangerous_deserialization=True
            )
            
            # ì°¨ì› ê²€ì¦
            if hasattr(vectorstore, 'index'):
                actual_dim = vectorstore.index.d
                if actual_dim != self.embedding_dimension:
                    logger.warning(
                        f"âš ï¸ {self.domain} ë¡œë“œëœ ë²¡í„°ìŠ¤í† ì–´ ì°¨ì› ë¶ˆì¼ì¹˜: "
                        f"ì˜ˆìƒ={self.embedding_dimension}, ì‹¤ì œ={actual_dim}"
                    )
            
            logger.info(f"ğŸ“š {self.domain}: ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì„±ê³µ")
            return vectorstore
            
        except Exception as e:
            logger.error(f"âŒ {self.domain}: ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def load_bm25_index(self) -> Optional[Dict]:
        """ìƒì„±ëœ BM25 ì¸ë±ìŠ¤ ë¡œë“œ"""
        try:
            bm25_file = self.vectorstore_dir / f"{self.index_name}.bm25"
            
            if not bm25_file.exists():
                logger.warning(f"âš ï¸ {self.domain}: BM25 íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
                return None
            
            with open(bm25_file, 'rb') as f:
                bm25_data = pickle.load(f)
            
            # ëª¨ë¸ í˜¸í™˜ì„± í™•ì¸
            stored_model = bm25_data.get('embedding_model')
            if stored_model and stored_model != self.embedding_model:
                logger.warning(
                    f"âš ï¸ {self.domain} BM25ì˜ ì„ë² ë”© ëª¨ë¸ ë¶ˆì¼ì¹˜: "
                    f"ì €ì¥ë¨({stored_model}) vs í˜„ì¬({self.embedding_model})"
                )
            
            logger.info(f"ğŸ“š {self.domain}: BM25 ì¸ë±ìŠ¤ ë¡œë“œ ì„±ê³µ")
            return bm25_data
            
        except Exception as e:
            logger.error(f"âŒ {self.domain}: BM25 ì¸ë±ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def get_stats(self) -> Dict[str, Any]:
        """ë²¡í„°ìŠ¤í† ì–´ + BM25 í†µê³„ ì •ë³´"""
        try:
            faiss_file = self.vectorstore_dir / f"{self.index_name}.faiss"
            pkl_file = self.vectorstore_dir / f"{self.index_name}.pkl"
            bm25_file = self.vectorstore_dir / f"{self.index_name}.bm25"
            dimension_file = self.vectorstore_dir / f"{self.index_name}_dimension_info.json"
            
            stats = {
                'domain': self.domain,
                'embedding_model': self.embedding_model,
                'embedding_dimension': self.embedding_dimension,
                'vectorstore_exists': faiss_file.exists() and pkl_file.exists(),
                'bm25_exists': bm25_file.exists(),
                'dimension_info_exists': dimension_file.exists(),
                'faiss_size_mb': faiss_file.stat().st_size / (1024*1024) if faiss_file.exists() else 0,
                'bm25_size_mb': bm25_file.stat().st_size / (1024*1024) if bm25_file.exists() else 0,
                'last_modified': datetime.fromtimestamp(faiss_file.stat().st_mtime).isoformat() if faiss_file.exists() else None,
                'source_dir': str(self.source_dir),
                'vectorstore_dir': str(self.vectorstore_dir)
            }
            
            # ì°¨ì› ì •ë³´ ì¶”ê°€
            if dimension_file.exists():
                try:
                    import json
                    with open(dimension_file, 'r') as f:
                        dimension_info = json.load(f)
                    stats['stored_dimension_info'] = dimension_info
                except Exception:
                    pass
            
            return stats
            
        except Exception as e:
            logger.error(f"í†µê³„ ì •ë³´ ìƒì„± ì‹¤íŒ¨: {e}")
            return {'domain': self.domain, 'error': str(e)}


# ================================================================
# ê°œë°œ/í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ë“¤
# ================================================================

def test_base_loader():
    """BaseLoader ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    
    class TestLoader(BaseLoader):
        """í…ŒìŠ¤íŠ¸ìš© ë¡œë”"""
        
        def process_domain_data(self) -> List[TextChunk]:
            return [
                TextChunk(
                    text="í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.",
                    metadata={'test': True},
                    source_id="test.txt"
                )
            ]
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    loader = TestLoader(
        domain="test",
        source_dir=Path("test_data"),
        vectorstore_dir=Path("test_vectorstore"),
        index_name="test_index"
    )
    
    print("âœ… BaseLoader í…ŒìŠ¤íŠ¸ ì™„ë£Œ")


if __name__ == "__main__":
    test_base_loader()
