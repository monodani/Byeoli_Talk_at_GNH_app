# ================================================================
# 5. ContextManager ë©”ì¸ í´ë˜ìŠ¤ (OpenAI í˜¸í™˜ì„± ìˆ˜ì •)
# ================================================================

class ContextManager:
    """ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ ì‹±ê¸€í†¤"""
    
    _instance = None
    _initialized = False
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        if self._initialized:
            return
            
        # âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì•ˆì „í•œ ì´ˆê¸°í™” (ì—ëŸ¬ í•¸ë“¤ë§ ê°•í™”)
        try:
            self.openai_client = openai.OpenAI(api_key=config.OPENAI_API_KEY)
            logger.info("âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
        except TypeError as e:
            if 'proxies' in str(e):
                logger.warning("âš ï¸ proxies ë§¤ê°œë³€ìˆ˜ ì˜¤ë¥˜ ë°œìƒ, ëŒ€ì²´ ì´ˆê¸°í™” ì‹œë„")
                # proxies ì˜¤ë¥˜ ì‹œ ëŒ€ì²´ ì´ˆê¸°í™” ë°©ì‹
                try:
                    self.openai_client = openai.OpenAI(
                        api_key=config.OPENAI_API_KEY,
                        timeout=30.0
                    )
                    logger.info("âœ… ëŒ€ì²´ ë°©ì‹ìœ¼ë¡œ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
                except Exception as e2:
                    logger.error(f"âŒ ëŒ€ì²´ ì´ˆê¸°í™”ë„ ì‹¤íŒ¨: {e2}")
                    self.openai_client = None
            else:
                logger.error(f"âŒ OpenAI ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.openai_client = None
        except Exception as e:
            logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ OpenAI ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
            self.openai_client = None
        
        # ë©”ëª¨ë¦¬ ê¸°ë°˜ ì„¸ì…˜ ì €ì¥ì†Œ (st.session_stateì™€ ì—°ë™)
        self.conversations: Dict[str, ConversationContext] = {}
        
        # ì„¤ì •ê°’
        self.recent_messages_window = config.CONVERSATION_RECENT_MESSAGES_WINDOW  # 6í„´
        self.summary_update_interval = config.CONVERSATION_SUMMARY_UPDATE_INTERVAL  # 4í„´
        self.summary_token_threshold = config.CONVERSATION_SUMMARY_TOKEN_THRESHOLD  # 1000í† í°
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” (OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒíƒœì— ë”°ë¥¸ ì•ˆì „í•œ ì´ˆê¸°í™”)
        self.entity_extractor = EntityExtractor()
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ìˆì„ ë•Œë§Œ AI ê¸°ë°˜ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        if self.openai_client:
            try:
                self.context_summarizer = ContextSummarizer(self.openai_client)
                self.followup_detector = FollowUpDetector(self.openai_client)
                self.query_expander = QueryExpander(self.openai_client)
                logger.info("âœ… AI ê¸°ë°˜ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"âš ï¸ AI ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}, ê¸°ë³¸ ëª¨ë“œë¡œ ë™ì‘")
                self.context_summarizer = None
                self.followup_detector = None
                self.query_expander = None
        else:
            logger.warning("âš ï¸ OpenAI í´ë¼ì´ì–¸íŠ¸ ì—†ìŒ, AI ê¸°ëŠ¥ ì—†ì´ ê¸°ë³¸ ëª¨ë“œë¡œ ë™ì‘")
            self.context_summarizer = None
            self.followup_detector = None
            self.query_expander = None
        
        self._initialized = True
        
        # ì´ˆê¸°í™” ìƒíƒœ ë¡œê¹…
        status = "ì™„ì „" if self.openai_client else "ì œí•œì "
        logger.info(f"ğŸ¯ ContextManager {status} ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _estimate_tokens(self, text: str) -> int:
        """í…ìŠ¤íŠ¸ í† í° ìˆ˜ ì¶”ì • (1í† í° â‰ˆ 3~4ê¸€ì)"""
        return len(text) // 3
    
    def _create_context_hash(self, summary: str, entities: List[str]) -> str:
        """ì»¨í…ìŠ¤íŠ¸ í•´ì‹œ ìƒì„± (ìºì‹œ í‚¤ìš©)"""
        context_data = {
            "summary": summary,
            "entities": sorted(entities)  # ìˆœì„œ ë¬´ê´€í•˜ê²Œ ì •ë ¬
        }
        context_str = json.dumps(context_data, sort_keys=True, ensure_ascii=False)
        return hashlib.md5(context_str.encode('utf-8')).hexdigest()[:16]
    
    def get_or_create_context(self, conversation_id: str) -> ConversationContext:
        """ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±"""
        if conversation_id not in self.conversations:
            self.conversations[conversation_id] = ConversationContext(
                conversation_id=conversation_id,
                summary="",
                recent_messages=[],
                entities=[],
                updated_at=datetime.now(timezone.utc)
            )
            logger.debug(f"ìƒˆ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìƒì„±: {conversation_id}")
        
        return self.conversations[conversation_id]
    
    def add_message(self, conversation_id: str, role: str, text: str) -> ConversationContext:
        """ë©”ì‹œì§€ ì¶”ê°€ ë° ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ (AI ê¸°ëŠ¥ ì•ˆì „ ì²˜ë¦¬)"""
        context = self.get_or_create_context(conversation_id)
        
        # ìƒˆ ë©”ì‹œì§€ ì¶”ê°€
        new_message = ChatTurn(
            role=role,
            text=text,
            ts=datetime.now(timezone.utc)
        )
        context.recent_messages.append(new_message)
        
        # ìœˆë„ìš° í¬ê¸° ìœ ì§€ (ìµœê·¼ Ní„´ë§Œ ë³´ê´€)
        if len(context.recent_messages) > self.recent_messages_window:
            context.recent_messages = context.recent_messages[-self.recent_messages_window:]
        
        # ì—”í‹°í‹° ì—…ë°ì´íŠ¸ (ì‚¬ìš©ì ë©”ì‹œì§€ë§Œ)
        if role == "user":
            new_entities = self.entity_extractor.extract_entities(text)
            context.entities.extend(new_entities)
            context.entities = list(set(context.entities))[:30]  # ì¤‘ë³µ ì œê±° ë° ìµœëŒ€ 30ê°œ
        
        # ìš”ì•½ ì—…ë°ì´íŠ¸ (AI ê¸°ëŠ¥ ì‚¬ìš© ê°€ëŠ¥í•  ë•Œë§Œ)
        should_update_summary = (
            len(context.recent_messages) % self.summary_update_interval == 0 or  # ë§¤ Ní„´
            self._estimate_tokens(" ".join([msg.text for msg in context.recent_messages])) > self.summary_token_threshold  # í† í° ì„ê³„ê°’ ì´ˆê³¼
        )
        
        if should_update_summary and len(context.recent_messages) >= 2 and self.context_summarizer:
            try:
                context.summary = self.context_summarizer.generate_summary(context.recent_messages)
                logger.debug(f"ëŒ€í™” ìš”ì•½ ì—…ë°ì´íŠ¸: {conversation_id}")
            except Exception as e:
                logger.warning(f"ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
        
        context.updated_at = datetime.now(timezone.utc)
        
        return context
    
    def create_query_request(self, 
                           conversation_id: str, 
                           query_text: str, 
                           trace_id: Optional[str] = None) -> QueryRequest:
        """QueryRequest ê°ì²´ ìƒì„± (AI ê¸°ëŠ¥ ì•ˆì „ ì²˜ë¦¬)"""
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        context = self.add_message(conversation_id, "user", query_text)
        
        # í›„ì†ì§ˆë¬¸ ê°ì§€ (AI ê¸°ëŠ¥ ì‚¬ìš© ê°€ëŠ¥í•  ë•Œë§Œ)
        is_followup = False
        if self.followup_detector:
            try:
                is_followup = self.followup_detector.detect_followup(query_text, context.recent_messages)
            except Exception as e:
                logger.warning(f"í›„ì†ì§ˆë¬¸ ê°ì§€ ì‹¤íŒ¨: {e}")
        
        # ì¿¼ë¦¬ í™•ì¥ (í›„ì†ì§ˆë¬¸ì¸ ê²½ìš° + AI ê¸°ëŠ¥ ì‚¬ìš© ê°€ëŠ¥í•  ë•Œë§Œ)
        expanded_query = query_text
        if is_followup and self.query_expander:
            try:
                expanded_query = self.query_expander.expand_query(query_text, context)
            except Exception as e:
                logger.warning(f"ì¿¼ë¦¬ í™•ì¥ ì‹¤íŒ¨: {e}")
        
        # trace_id ìƒì„± (ì œê³µë˜ì§€ ì•Šì€ ê²½ìš°)
        if not trace_id:
            trace_id = f"{conversation_id}-{int(time.time())}"
        
        request = QueryRequest(
            text=expanded_query,  # í™•ì¥ëœ ì¿¼ë¦¬ ì‚¬ìš©
            context=context,
            follow_up=is_followup,
            trace_id=trace_id,
            routing_hints={}
        )
        
        logger.info(f"QueryRequest ìƒì„±: {conversation_id}, follow_up={is_followup}, expanded={expanded_query != query_text}")
        return request
    
    def add_response(self, conversation_id: str, response_text: str) -> ConversationContext:
        """ì‹œìŠ¤í…œ ì‘ë‹µ ì¶”ê°€"""
        return self.add_message(conversation_id, "assistant", response_text)
    
    def get_context_hash(self, conversation_id: str) -> str:
        """ì»¨í…ìŠ¤íŠ¸ í•´ì‹œ ë°˜í™˜ (ìºì‹œ í‚¤ìš©)"""
        if conversation_id not in self.conversations:
            return "empty"
        
        context = self.conversations[conversation_id]
        return self._create_context_hash(context.summary, context.entities)
    
    def clear_context(self, conversation_id: str):
        """íŠ¹ì • ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì‚­ì œ"""
        if conversation_id in self.conversations:
            del self.conversations[conversation_id]
            logger.info(f"ì»¨í…ìŠ¤íŠ¸ ì‚­ì œ: {conversation_id}")
    
    def cleanup_old_contexts(self, max_age_hours: int = 24):
        """ì˜¤ë˜ëœ ì»¨í…ìŠ¤íŠ¸ ì •ë¦¬"""
        cutoff_time = datetime.now(timezone.utc).timestamp() - (max_age_hours * 3600)
        
        old_conversations = [
            conv_id for conv_id, context in self.conversations.items()
            if context.updated_at and context.updated_at.timestamp() < cutoff_time
        ]
        
        for conv_id in old_conversations:
            del self.conversations[conv_id]
        
        if old_conversations:
            logger.info(f"ì˜¤ë˜ëœ ì»¨í…ìŠ¤íŠ¸ {len(old_conversations)}ê°œ ì •ë¦¬ ì™„ë£Œ")
    
    def get_conversation_stats(self) -> Dict[str, Any]:
        """ëŒ€í™” í†µê³„ ë°˜í™˜"""
        total_conversations = len(self.conversations)
        total_messages = sum(len(ctx.recent_messages) for ctx in self.conversations.values())
        
        active_conversations = sum(
            1 for ctx in self.conversations.values()
            if ctx.updated_at and (datetime.now(timezone.utc) - ctx.updated_at).seconds < 3600
        )
        
        return {
            "total_conversations": total_conversations,
            "active_conversations": active_conversations,
            "total_messages": total_messages,
            "avg_messages_per_conversation": total_messages / max(total_conversations, 1),
            "unique_entities": len(set(
                entity for ctx in self.conversations.values() 
                for entity in ctx.entities
            )),
            "ai_features_enabled": self.openai_client is not None
        }
    
    def export_conversation(self, conversation_id: str) -> Optional[Dict]:
        """ëŒ€í™” ë‚´ìš© ë‚´ë³´ë‚´ê¸° (ë””ë²„ê·¸ìš©)"""
        if conversation_id not in self.conversations:
            return None
        
        context = self.conversations[conversation_id]
        return {
            "conversation_id": conversation_id,
            "summary": context.summary,
            "entities": context.entities,
            "messages": [asdict(msg) for msg in context.recent_messages],
            "updated_at": context.updated_at.isoformat() if context.updated_at else None,
            "ai_features_enabled": self.openai_client is not None
        }
