"""
Context Manager Module: ëŒ€í™”í˜• RAGë¥¼ ìœ„í•œ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬

ì£¼ìš” ê¸°ëŠ¥:
1. ëŒ€í™” ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬ (ë©”ëª¨ë¦¬ ê¸°ë°˜)
2. ì»¨í…ìŠ¤íŠ¸ ìš”ì•½ ë° ì—”í‹°í‹° ì¶”ì¶œ
3. í›„ì†ì§ˆë¬¸ ê°ì§€ ë° ì²˜ë¦¬
4. ìºì‹œ í‚¤ ìƒì„± ë° í•´ì‹œ ê´€ë¦¬
"""

import hashlib
import json
import re
import time
from datetime import datetime, timezone
from typing import Dict, List, Optional, Set, Tuple, Any
from dataclasses import dataclass, asdict
from collections import defaultdict
import logging

import openai
from .config import get_config
from .contracts import ConversationContext, ChatTurn, QueryRequest
from .logging_utils import get_logger, log_timer

logger = get_logger(__name__)
config = get_config()


# ================================================================
# 1. EntityExtractor í´ë˜ìŠ¤ (ì‹¤ì œ ë°ì´í„° ê¸°ë°˜)
# ================================================================

class EntityExtractor:
    """ì‹¤ì œ í”„ë¡œì íŠ¸ ë°ì´í„° ê¸°ë°˜ ì—”í‹°í‹° ì¶”ì¶œê¸°"""
    
    def __init__(self):
        # ì‹¤ì œ í™•ì¸ëœ ë‹´ë‹¹ë¶€ì„œ ì—°ë½ì²˜
        self.department_contacts = {
            'ì´ë¬´ë‹´ë‹¹': '055-254-2013',
            'í‰ê°€ë¶„ì„ë‹´ë‹¹': '055-254-2023', 
            'êµìœ¡ê¸°íšë‹´ë‹¹': '055-254-2053',
            'êµìœ¡ìš´ì˜1ë‹´ë‹¹': '055-254-2063',
            'êµìœ¡ìš´ì˜2ë‹´ë‹¹': '055-254-2073',
            'ì‚¬ì´ë²„ë‹´ë‹¹': '055-254-2083'
        }
        
        # ì‹¤ì œ êµìœ¡ê³¼ì •ëª…ë“¤
        self.education_courses = [
            # ë¦¬ë”ì‹­ êµìœ¡
            'ì¤‘ê²¬ë¦¬ë” ê³¼ì •', 'ê³¼ì¥ê¸‰ í•„ìˆ˜ ì—­ëŸ‰í–¥ìƒ ê³¼ì •', '5ê¸‰ ê´€ë¦¬ì ë¦¬ë”ì‹­ ê³¼ì •',
            'ì‹œÂ·êµ° íŒ€ì¥ ë¦¬ë”ì‹­ ê³¼ì •', 'ì‹œÂ·êµ° íŒ€ì¥ ì—­ëŸ‰í–¥ìƒ ê³¼ì •', 'ì½”ì¹­ ë¦¬ë”ì‹­ ê³¼ì •',
            
            # ê¸°ë³¸êµìœ¡  
            'ì‹ ê·œ ì„ìš©(í›„ë³´)ì ê³¼ì •', 'ì‹ ê·œê³µë¬´ì› ì—­ëŸ‰í–¥ìƒ ì‹¬í™” ê³¼ì •',
            '7Â·8ê¸‰ ìŠ¹ì§„ì ì—­ëŸ‰í–¥ìƒ ê³¼ì •', '6ê¸‰ ìŠ¹ì§„ì ì—­ëŸ‰í–¥ìƒ ê³¼ì •', 
            'ì „ì…ê³µë¬´ì› ì—­ëŸ‰í–¥ìƒ ê³¼ì •', 'ì†Œí†µê³¼ ê³µê° ê³¼ì •',
            
            # ì§ë¬´êµìœ¡
            'í–‰ì‚¬ì‹¤ë¬´ ê³¼ì •', 'ê¸°íšëŠ¥ë ¥ í–¥ìƒ ê³¼ì •', 'ëª…í’ˆ ìŠ¤í”¼ì¹˜ ê³¼ì •',
            'ë©´ì ‘ê´€ ì–‘ì„± ê³¼ì •', 'ê³µê³µì–¸ì–´ ë°”ë¥´ê²Œ ì“°ê¸° ê³¼ì •',
            
            # ì‚¬ì´ë²„êµìœ¡
            'ì²­íƒê¸ˆì§€ë²•ì˜ ì´í•´', 'ê°œì¸ë³´í˜¸ ì¥ë¹„ê´€ë¦¬', 'êµ­ì œíšŒì˜ í˜‘ìƒê³¼ì •',
            'ì†Œë°©ê³µë¬´ì›ë²•', 'ì•Œê¸° ì‰¬ìš´ ì†Œë°©ì„¤ë¹„2', 'CISDë¦¬ë”ì˜ ì—­í•  ë° ë°©ë²•'
        ]
        
        # ë‚˜ë¼ë°°ì›€í„° ë¶„ë¥˜
        self.nara_categories = ['ì§ë¬´', 'ì†Œì–‘', 'ì‹œì±…', 'ë””ì§€í„¸', 'Gov-MOOC']
        
        # êµìœ¡ ë¶„ë¥˜ì²´ê³„
        self.domain_categories = {
            'ê¸°ë³¸ì—­ëŸ‰': ['ê³µì§ê°€ì¹˜', 'ë¯¸ë˜ ë³€í™” ëŒ€ì‘', 'ê¸€ë¡œë²Œ ë§ˆì¸ë“œ'],
            'ë¦¬ë”ì‹­ì—­ëŸ‰': ['ì˜ì‚¬ê²°ì •', 'ë™ê¸° ë¶€ì—¬', 'íŒ€ì›Œí¬ í˜•ì„±', 'ì—…ë¬´ê´€ê³„ë§ í˜•ì„±'],
            'ì§ë¬´ì—­ëŸ‰': ['ê¸°íšë ¥', 'ì„¤ë“/í˜‘ìƒë ¥', 'ì˜ì‚¬ í‘œí˜„ë ¥', 'í˜„ì¥ì§€í–¥ì„±']
        }
        
        # ë‚ ì§œ íŒ¨í„´ë“¤
        self.date_patterns = [
            r'2024[-ë…„\.]\d{1,2}[-ì›”\.]\d{1,2}[ì¼]?',
            r'2025[-ë…„\.]\d{1,2}[-ì›”\.]\d{1,2}[ì¼]?',
            r'\d{1,2}[-\.]\d{1,2}[-\.]\s*~\s*\d{1,2}[-\.]\d{1,2}[-\.]',
            r'\d{1,2}ì›”\s*\d{1,2}ì£¼ì°¨',
            r'[1-9]ê¸°',
            r'\d{1,2}ì£¼'
        ]
        
        # ì—°ë½ì²˜ íŒ¨í„´
        self.phone_pattern = r'055-254-\d{4}'
        
        logger.info("ğŸ” EntityExtractor ì´ˆê¸°í™” ì™„ë£Œ")
    
    def extract_entities(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì—”í‹°í‹° ì¶”ì¶œ (ìš°ì„ ìˆœìœ„ ê¸°ë°˜)"""
        entities = set()
        text_lower = text.lower()
        
        # 1. ë‹´ë‹¹ë¶€ì„œ ì¶”ì¶œ (ìµœìš°ì„ )
        for dept in self.department_contacts.keys():
            dept_variants = [dept, dept.replace('ë‹´ë‹¹', ''), dept + 'ë¶€ì„œ']
            for variant in dept_variants:
                if variant.lower() in text_lower:
                    entities.add(dept)
                    break
        
        # 2. êµìœ¡ê³¼ì •ëª… ì¶”ì¶œ (ì •í™• ë§¤ì¹­ + ìœ ì‚¬ë„)
        for course in self.education_courses:
            # ì •í™• ë§¤ì¹­
            if course.lower() in text_lower:
                entities.add(course)
            # ë¶€ë¶„ ë§¤ì¹­ (í‚¤ì›Œë“œ ê¸°ë°˜)
            elif any(keyword in text_lower for keyword in course.lower().split() if len(keyword) > 2):
                entities.add(course)
        
        # 3. ë‚ ì§œ/ì‹œê¸° ì¶”ì¶œ
        for pattern in self.date_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            entities.update(match for match in matches if len(match.strip()) > 1)
        
        # 4. ì—°ë½ì²˜ ì¶”ì¶œ
        phone_matches = re.findall(self.phone_pattern, text)
        entities.update(phone_matches)
        
        # 5. êµìœ¡ë¶„ë¥˜ ì¶”ì¶œ
        for category in self.nara_categories:
            if category in text_lower:
                entities.add(category)
        
        # ë„ë©”ì¸ ë¶„ë¥˜
        for domain, keywords in self.domain_categories.items():
            if any(keyword in text_lower for keyword in keywords):
                entities.add(domain)
        
        # 6. ì¼ë°˜ í‚¤ì›Œë“œ (ë§Œì¡±ë„, í‰ê°€ ë“±)
        general_keywords = ['ë§Œì¡±ë„', 'í‰ê°€', 'ì ìˆ˜', 'ì„±ì ', 'ì‚¬ì´ë²„êµìœ¡', 'ì˜¨ë¼ì¸', 
                          'ë¯¼ê°„ìœ„íƒ', 'ë‚˜ë¼ë°°ì›€í„°', 'ì‹ë‹¨', 'ë©”ë‰´', 'êµ¬ë‚´ì‹ë‹¹']
        for keyword in general_keywords:
            if keyword in text_lower:
                entities.add(keyword)
        
        result = list(entities)[:20]  # ìµœëŒ€ 20ê°œ ì œí•œ
        logger.debug(f"ì¶”ì¶œëœ ì—”í‹°í‹°: {result}")
        return result


# ================================================================
# 2. ContextSummarizer í´ë˜ìŠ¤
# ================================================================

class ContextSummarizer:
    """ëŒ€í™” ë‚´ìš© ìš”ì•½ ìƒì„±ê¸° (gpt-4o-mini ê¸°ë°˜)"""
    
    def __init__(self, openai_client):
        self.openai_client = openai_client
        self.model = config.OPENAI_MODEL_ROUTER  # gpt-4o-mini
        
        logger.info("ğŸ“ ContextSummarizer ì´ˆê¸°í™” ì™„ë£Œ")
    
    def generate_summary(self, recent_messages: List[ChatTurn]) -> str:
        """ëŒ€í™” ë‚´ìš©ì„ 200ì ì´ë‚´ë¡œ ìš”ì•½"""
        if not recent_messages:
            return ""
        
        # ëŒ€í™” ë‚´ìš© êµ¬ì„±
        conversation_text = []
        for msg in recent_messages[-6:]:  # ìµœê·¼ 6í„´ë§Œ
            role_kr = "ì‚¬ìš©ì" if msg.role == "user" else "ì‹œìŠ¤í…œ"
            conversation_text.append(f"{role_kr}: {msg.content}")
        
        conversation_str = "\n".join(conversation_text)
        
        # ê²½ë‚¨ì¸ì¬ê°œë°œì› íŠ¹í™” ìš”ì•½ í”„ë¡¬í”„íŠ¸
        prompt = f"""ë‹¤ìŒì€ ê²½ìƒë‚¨ë„ì¸ì¬ê°œë°œì› ê´€ë ¨ ëŒ€í™”ì…ë‹ˆë‹¤. í•µì‹¬ ë‚´ìš©ì„ 200ì ì´ë‚´ë¡œ ìš”ì•½í•˜ì„¸ìš”.

ìš”ì•½ ê¸°ì¤€:
- êµìœ¡ê³¼ì •ëª…, ë‹´ë‹¹ë¶€ì„œ, ë‚ ì§œ ë“± êµ¬ì²´ì  ì •ë³´ ìš°ì„ 
- ì‚¬ìš©ìì˜ ì£¼ìš” ì§ˆë¬¸ ì˜ë„ íŒŒì•…
- ê²½ë‚¨ì¸ì¬ê°œë°œì› ì—…ë¬´ ê´€ë ¨ í‚¤ì›Œë“œ ê°•ì¡°

ëŒ€í™” ë‚´ìš©:
{conversation_str}

ìš”ì•½ (200ì ì´ë‚´):"""

        try:
            with log_timer("context_summary_generation"):
                response = self.openai_client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": "ê²½ë‚¨ì¸ì¬ê°œë°œì› ì „ë¬¸ ìš”ì•½ AIì…ë‹ˆë‹¤. ê°„ê²°í•˜ê³  ì •í™•í•œ ìš”ì•½ì„ ì œê³µí•©ë‹ˆë‹¤."},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=100,
                    temperature=0.1,
                    timeout=5.0
                )
                
                summary = response.choices[0].message.content.strip()
                logger.debug(f"ìƒì„±ëœ ìš”ì•½: {summary[:100]}...")
                return summary
                
        except Exception as e:
            logger.warning(f"ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
            # í´ë°±: ìµœê·¼ ì‚¬ìš©ì ë©”ì‹œì§€ ê¸°ë°˜ ê°„ë‹¨ ìš”ì•½
            user_messages = [msg.content for msg in recent_messages[-3:] if msg.role == "user"]
            if user_messages:
                return f"ì‚¬ìš©ìê°€ {', '.join(user_messages[:2][:50])}ì— ëŒ€í•´ ì§ˆë¬¸í•¨"
            return "ëŒ€í™” ì§„í–‰ ì¤‘"


# ================================================================
# 3. FollowUpDetector í´ë˜ìŠ¤
# ================================================================

class FollowUpDetector:
    """í›„ì†ì§ˆë¬¸ ê°ì§€ê¸° (íŒ¨í„´ + LLM í•˜ì´ë¸Œë¦¬ë“œ)"""
    
    def __init__(self, openai_client):
        self.openai_client = openai_client
        self.model = config.OPENAI_MODEL_ROUTER  # gpt-4o-mini
        
        # ëª…í™•í•œ í›„ì†ì§ˆë¬¸ íŒ¨í„´ë“¤
        self.followup_patterns = {
            'reference': ['ê·¸ê²ƒ', 'ê·¸ê±°', 'ì´ê²ƒ', 'ì´ê±°', 'ìœ„ì˜', 'ì•ì˜', 'í•´ë‹¹', 'ê·¸', 'ì´', 'ì €ê²ƒ'],
            'continuation': ['ë˜', 'ê·¸ë¦¬ê³ ', 'ì¶”ê°€ë¡œ', 'ë”', 'ë‹¤ìŒ', 'ê³„ì†', 'ê·¸ëŸ°ë°', 'ê·¸ëŸ¼', 'ê·¸ëŸ¬ë©´'],
            'clarification': ['ìì„¸íˆ', 'êµ¬ì²´ì ìœ¼ë¡œ', 'ë” ì•Œë ¤', 'ì„¤ëª…í•´', 'ì–´ë–»ê²Œ', 'ì™œ', 'ì–¸ì œ', 'ì–´ë””ì„œ'],
            'comparison': ['ì°¨ì´', 'ë¹„êµ', 'ë‹¤ë¥¸', 'ê°™ì€', 'ë¹„ìŠ·í•œ', 'ë°˜ëŒ€ë¡œ'],
            'quantification': ['ëª‡', 'ì–¼ë§ˆ', 'ì–¸ì œê¹Œì§€', 'ë©°ì¹ ', 'ëª‡ ì‹œê°„']
        }
        
        logger.info("ğŸ”„ FollowUpDetector ì´ˆê¸°í™” ì™„ë£Œ")
    
    def detect_followup(self, current_query: str, recent_messages: List[ChatTurn]) -> bool:
        """í›„ì†ì§ˆë¬¸ ì—¬ë¶€ íŒë‹¨"""
        if not recent_messages or len(recent_messages) < 2:
            return False
        
        current_lower = current_query.lower().strip()
        
        # 1ì°¨: ëª…í™•í•œ íŒ¨í„´ ë§¤ì¹­ (ë¹ ë¥¸ íŒë‹¨)
        pattern_score = self._calculate_pattern_score(current_lower)
        
        if pattern_score >= 0.7:  # ëª…í™•í•œ í›„ì†ì§ˆë¬¸ íŒ¨í„´
            logger.debug(f"íŒ¨í„´ ê¸°ë°˜ í›„ì†ì§ˆë¬¸ ê°ì§€: {pattern_score:.3f}")
            return True
        elif pattern_score <= 0.2:  # ëª…í™•íˆ ë…ë¦½ì  ì§ˆë¬¸
            logger.debug(f"íŒ¨í„´ ê¸°ë°˜ ë…ë¦½ ì§ˆë¬¸ íŒë‹¨: {pattern_score:.3f}")
            return False
        
        # 2ì°¨: LLM ê¸°ë°˜ íŒë‹¨ (ëª¨í˜¸í•œ ê²½ìš°ë§Œ)
        return self._llm_based_detection(current_query, recent_messages)
    
    def _calculate_pattern_score(self, query: str) -> float:
        """íŒ¨í„´ ê¸°ë°˜ í›„ì†ì§ˆë¬¸ ì ìˆ˜ ê³„ì‚°"""
        score = 0.0
        word_count = len(query.split())
        
        # ì§€ì‹œëŒ€ëª…ì‚¬ (ê°•í•œ ì‹ í˜¸)
        for indicator in self.followup_patterns['reference']:
            if indicator in query:
                score += 0.4
        
        # ì—°ê²°ì‚¬ë¡œ ì‹œì‘ (ê°•í•œ ì‹ í˜¸)
        for indicator in self.followup_patterns['continuation']:
            if query.startswith(indicator):
                score += 0.5
        
        # ëª…í™•í™” ìš”ì²­
        for indicator in self.followup_patterns['clarification']:
            if indicator in query:
                score += 0.3
        
        # ë¹„êµ ìš”ì²­
        for indicator in self.followup_patterns['comparison']:
            if indicator in query:
                score += 0.2
        
        # ìˆ˜ëŸ‰í™” ìš”ì²­
        for indicator in self.followup_patterns['quantification']:
            if indicator in query:
                score += 0.2
        
        # ì§ˆë¬¸ì´ ë„ˆë¬´ ì§§ìœ¼ë©´ í›„ì†ì§ˆë¬¸ì¼ ê°€ëŠ¥ì„± ì¦ê°€
        if word_count <= 3:
            score += 0.2
        
        return min(score, 1.0)
    
    def _llm_based_detection(self, current_query: str, recent_messages: List[ChatTurn]) -> bool:
        """LLM ê¸°ë°˜ í›„ì†ì§ˆë¬¸ ê°ì§€"""
        try:
            # ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context_msgs = []
            for msg in recent_messages[-4:]:  # ìµœê·¼ 4í„´
                role_kr = "ì‚¬ìš©ì" if msg.role == "user" else "ì±—ë´‡"
                context_msgs.append(f"{role_kr}: {msg.content}")
            
            context_str = "\n".join(context_msgs)
            
            prompt = f"""ë‹¤ìŒ ëŒ€í™”ì—ì„œ ë§ˆì§€ë§‰ ì‚¬ìš©ì ì§ˆë¬¸ì´ ì´ì „ ëŒ€í™”ì˜ í›„ì†ì§ˆë¬¸ì¸ì§€ íŒë‹¨í•˜ì„¸ìš”.

ì´ì „ ëŒ€í™”:
{context_str}

í˜„ì¬ ì§ˆë¬¸: {current_query}

í›„ì†ì§ˆë¬¸ íŒë‹¨ ê¸°ì¤€:
- ì´ì „ ë‹µë³€ì˜ íŠ¹ì • ë¶€ë¶„ì— ëŒ€í•œ ì¶”ê°€ ì§ˆë¬¸
- ì§€ì‹œëŒ€ëª…ì‚¬ ì‚¬ìš© ("ê·¸ê²ƒ", "ì´ê²ƒ" ë“±)
- ì´ì „ ë§¥ë½ ì—†ì´ëŠ” ì´í•´í•˜ê¸° ì–´ë ¤ìš´ ì§ˆë¬¸
- ë¹„êµë‚˜ ì¶”ê°€ ì„¸ë¶€ì‚¬í•­ ìš”ì²­

ë‹µë³€: YES ë˜ëŠ” NOë§Œ ë‹µí•˜ì„¸ìš”."""

            response = self.openai_client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "í›„ì†ì§ˆë¬¸ íŒë‹¨ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=10,
                temperature=0.0,
                timeout=3.0
            )
            
            result = response.choices[0].message.content.strip().upper()
            is_followup = result == "YES"
            
            logger.debug(f"LLM ê¸°ë°˜ í›„ì†ì§ˆë¬¸ íŒë‹¨: {is_followup}")
            return is_followup
            
        except Exception as e:
            logger.warning(f"LLM ê¸°ë°˜ í›„ì†ì§ˆë¬¸ ê°ì§€ ì‹¤íŒ¨: {e}")
            # í´ë°±: íŒ¨í„´ ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨
            return self._calculate_pattern_score(current_query.lower()) >= 0.5


# ================================================================
# 4. QueryExpander í´ë˜ìŠ¤
# ================================================================

class QueryExpander:
    """ì¿¼ë¦¬ í™•ì¥ê¸° (ì§€ì‹œì–´/ëŒ€ëª…ì‚¬ í•´ì†Œ)"""
    
    def __init__(self, openai_client):
        self.openai_client = openai_client
        self.model = config.OPENAI_MODEL_ROUTER  # gpt-4o-mini
        
        logger.info("ğŸ” QueryExpander ì´ˆê¸°í™” ì™„ë£Œ")
    
    def expand_query(self, query: str, context: ConversationContext) -> str:
        """ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¿¼ë¦¬ í™•ì¥"""
        if not context or not context.recent_messages:
            return query
        
        # ì§€ì‹œì–´/ëŒ€ëª…ì‚¬ê°€ ìˆëŠ”ì§€ í™•ì¸
        pronouns = ['ê·¸ê²ƒ', 'ê·¸ê±°', 'ì´ê²ƒ', 'ì´ê±°', 'ê·¸', 'ì´', 'ì €ê²ƒ', 'ìœ„ì˜', 'ì•ì˜', 'í•´ë‹¹']
        has_pronoun = any(pronoun in query for pronoun in pronouns)
        
        if not has_pronoun:
            return query
        
        try:
            # ì´ì „ ëŒ€í™”ì—ì„œ í•µì‹¬ ì—”í‹°í‹° ì¶”ì¶œ
            previous_entities = context.entities[-10:] if context.entities else []
            
            # ìµœê·¼ ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µì—ì„œ ì£¼ìš” ë‚´ìš© ì¶”ì¶œ
            recent_assistant_msgs = [
                msg.content for msg in context.recent_messages[-3:] 
                if msg.role == "assistant"
            ]
            
            context_info = f"""
ì£¼ìš” ì—”í‹°í‹°: {', '.join(previous_entities)}
ìµœê·¼ ë‹µë³€: {' '.join(recent_assistant_msgs)[:300]}
ìš”ì•½: {context.summary}
"""

            prompt = f"""ë‹¤ìŒ ëŒ€í™” ë§¥ë½ì—ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ìˆëŠ” ì§€ì‹œì–´ë‚˜ ëŒ€ëª…ì‚¬ë¥¼ êµ¬ì²´ì ì¸ ë‚´ìš©ìœ¼ë¡œ ë°”ê¿”ì£¼ì„¸ìš”.

ëŒ€í™” ë§¥ë½:
{context_info}

ì‚¬ìš©ì ì§ˆë¬¸: {query}

ì§€ì‹œì–´ í•´ì†Œ ì§€ì¹¨:
- "ê·¸ê²ƒ", "ì´ê²ƒ" â†’ êµ¬ì²´ì ì¸ êµìœ¡ê³¼ì •ëª…ì´ë‚˜ ì •ì±…ëª…
- "ê·¸", "ì´" â†’ ì•ì„œ ì–¸ê¸‰ëœ êµ¬ì²´ì  ëŒ€ìƒ
- "ìœ„ì˜", "ì•ì˜" â†’ ì´ì „ì— ì–¸ê¸‰ëœ íŠ¹ì • í•­ëª©

í™•ì¥ëœ ì§ˆë¬¸:"""

            response = self.openai_client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ëŒ€í™” ë§¥ë½ì„ ì´í•´í•˜ì—¬ ì§€ì‹œì–´ë¥¼ êµ¬ì²´ì  ë‚´ìš©ìœ¼ë¡œ ë°”ê¾¸ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=150,
                temperature=0.1,
                timeout=4.0
            )
            
            expanded_query = response.choices[0].message.content.strip()
            
            # í™•ì¥ëœ ì¿¼ë¦¬ê°€ ë„ˆë¬´ ê¸¸ê±°ë‚˜ ì´ìƒí•˜ë©´ ì›ë³¸ ì‚¬ìš©
            if len(expanded_query) > len(query) * 3 or len(expanded_query) < 5:
                logger.warning("ì¿¼ë¦¬ í™•ì¥ ê²°ê³¼ ì´ìƒ, ì›ë³¸ ì‚¬ìš©")
                return query
            
            logger.debug(f"ì¿¼ë¦¬ í™•ì¥: '{query}' â†’ '{expanded_query}'")
            return expanded_query
            
        except Exception as e:
            logger.warning(f"ì¿¼ë¦¬ í™•ì¥ ì‹¤íŒ¨: {e}")
            return query


# ================================================================
# 5. ContextManager ë©”ì¸ í´ë˜ìŠ¤
# ================================================================

class ContextManager:
    """ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ ì‹±ê¸€í†¤"""
    
    _instance = None
    _initialized = False
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        if self._initialized:
            return
            
        # Streamlit secrets ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
        try:
            import streamlit as st
            api_key = st.secrets.get("OPENAI_API_KEY")
        except:
            api_key = os.getenv("OPENAI_API_KEY")
        
        if not api_key:
            raise ValueError("OPENAI_API_KEY not found in Streamlit secrets or environment")
        
        # proxies ë§¤ê°œë³€ìˆ˜ ì œê±°!
        self.openai_client = openai.OpenAI(
            api_key=api_key
            # proxies ì œê±°ë¨
        )
        
        # ë©”ëª¨ë¦¬ ê¸°ë°˜ ì„¸ì…˜ ì €ì¥ì†Œ (st.session_stateì™€ ì—°ë™)
        self.conversations: Dict[str, ConversationContext] = {}
        
        # ì„¤ì •ê°’
        self.recent_messages_window = config.CONVERSATION_RECENT_MESSAGES_WINDOW  # 6í„´
        self.summary_update_interval = config.CONVERSATION_SUMMARY_UPDATE_INTERVAL  # 4í„´
        self.summary_token_threshold = config.CONVERSATION_SUMMARY_TOKEN_THRESHOLD  # 1000í† í°
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        self.entity_extractor = EntityExtractor()
        self.context_summarizer = ContextSummarizer(self.openai_client)
        self.followup_detector = FollowUpDetector(self.openai_client)
        self.query_expander = QueryExpander(self.openai_client)
        
        self._initialized = True
        logger.info("ğŸ¯ ContextManager ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _estimate_tokens(self, text: str) -> int:
        """í…ìŠ¤íŠ¸ í† í° ìˆ˜ ì¶”ì • (1í† í° â‰ˆ 3~4ê¸€ì)"""
        return len(text) // 3
    
    def _create_context_hash(self, summary: str, entities: List[str]) -> str:
        """ì»¨í…ìŠ¤íŠ¸ í•´ì‹œ ìƒì„± (ìºì‹œ í‚¤ìš©)"""
        context_data = {
            "summary": summary,
            "entities": sorted(entities)  # ìˆœì„œ ë¬´ê´€í•˜ê²Œ ì •ë ¬
        }
        context_str = json.dumps(context_data, sort_keys=True, ensure_ascii=False)
        return hashlib.md5(context_str.encode('utf-8')).hexdigest()[:16]
    
    def get_or_create_context(self, conversation_id: str) -> ConversationContext:
        """ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±"""
        if conversation_id not in self.conversations:
            # âœ… ìˆ˜ì •: ConversationContext ìŠ¤í‚¤ë§ˆì— ë§ì¶° ìˆ˜ì •
            self.conversations[conversation_id] = ConversationContext(
                session_id=conversation_id,  
                turns=[],                    
                entities={},                 
                summary="",
                updated_at=datetime.now()
            )
            logger.debug(f"ìƒˆ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìƒì„±: {conversation_id}")
        
        return self.conversations[conversation_id]
    
    def add_message(self, conversation_id: str, role: str, text: str) -> ConversationContext:
        """ë©”ì‹œì§€ ì¶”ê°€ ë° ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸"""
        context = self.get_or_create_context(conversation_id)
        
        # âœ… ìˆ˜ì •: ChatTurn êµ¬ì¡°ì— ë§ì¶° ìˆ˜ì •
        new_message = ChatTurn(
            role=MessageRole(role) if isinstance(role, str) else role,
            content=text,  
            timestamp=datetime.now() 
        )
        
        # âœ… ìˆ˜ì •: recent_messages ì†ì„±ì„ í†µí•´ turnsì— ì¶”ê°€
        context.recent_messages.append(new_message)
        
        # ìœˆë„ìš° í¬ê¸° ìœ ì§€ (ìµœê·¼ Ní„´ë§Œ ë³´ê´€)
        if len(context.recent_messages) > self.recent_messages_window:
            context.recent_messages = context.recent_messages[-self.recent_messages_window:]
        
        # ì—”í‹°í‹° ì—…ë°ì´íŠ¸ (ì‚¬ìš©ì ë©”ì‹œì§€ë§Œ)
        if role == "user":
            new_entities = self.entity_extractor.extract_entities(text)
            # âœ… ìˆ˜ì •: entitiesëŠ” Dict[str, List[str]] êµ¬ì¡°
            if "extracted" not in context.entities:
                context.entities["extracted"] = []
            context.entities["extracted"].extend(new_entities)
            context.entities["extracted"] = list(set(context.entities["extracted"]))[:30]
        
        # ìš”ì•½ ì—…ë°ì´íŠ¸ ì¡°ê±´ í™•ì¸
        should_update_summary = (
            len(context.recent_messages) % self.summary_update_interval == 0 or
            self._estimate_tokens(" ".join([msg.content for msg in context.recent_messages])) > self.summary_token_threshold
        )
        
        if should_update_summary and len(context.recent_messages) >= 2:
            context.summary = self.context_summarizer.generate_summary(context.recent_messages)
            logger.debug(f"ëŒ€í™” ìš”ì•½ ì—…ë°ì´íŠ¸: {conversation_id}")
        
        context.updated_at = datetime.now()
        
        return context
    
    def create_query_request(self, 
                           conversation_id: str, 
                           query_text: str, 
                           trace_id: Optional[str] = None) -> QueryRequest:
        """QueryRequest ê°ì²´ ìƒì„± (ì»¨í…ìŠ¤íŠ¸ í¬í•¨)"""
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        context = self.add_message(conversation_id, "user", query_text)
        
        # í›„ì†ì§ˆë¬¸ ê°ì§€
        is_followup = self.followup_detector.detect_followup(query_text, context.recent_messages)
        
        # ì¿¼ë¦¬ í™•ì¥ (í›„ì†ì§ˆë¬¸ì¸ ê²½ìš°)
        expanded_query = query_text
        if is_followup:
            expanded_query = self.query_expander.expand_query(query_text, context)
        
        # trace_id ìƒì„± (ì œê³µë˜ì§€ ì•Šì€ ê²½ìš°)
        if not trace_id:
            trace_id = f"{conversation_id}-{int(time.time())}"
        
        request = QueryRequest(
            text=expanded_query,  # í™•ì¥ëœ ì¿¼ë¦¬ ì‚¬ìš©
            context=context,
            follow_up=is_followup,
            trace_id=trace_id,
            routing_hints={}
        )
        
        logger.info(f"QueryRequest ìƒì„±: {conversation_id}, follow_up={is_followup}, expanded={expanded_query != query_text}")
        return request
    
    def add_response(self, conversation_id: str, response_text: str) -> ConversationContext:
        """ì‹œìŠ¤í…œ ì‘ë‹µ ì¶”ê°€"""
        return self.add_message(conversation_id, "assistant", response_text)
    
    def get_context_hash(self, conversation_id: str) -> str:
        """ì»¨í…ìŠ¤íŠ¸ í•´ì‹œ ë°˜í™˜ (ìºì‹œ í‚¤ìš©)"""
        if conversation_id not in self.conversations:
            return "empty"
        
        context = self.conversations[conversation_id]
        return self._create_context_hash(context.summary, context.entities)
    
    def clear_context(self, conversation_id: str):
        """íŠ¹ì • ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ì‚­ì œ"""
        if conversation_id in self.conversations:
            del self.conversations[conversation_id]
            logger.info(f"ì»¨í…ìŠ¤íŠ¸ ì‚­ì œ: {conversation_id}")
    
    def cleanup_old_contexts(self, max_age_hours: int = 24):
        """ì˜¤ë˜ëœ ì»¨í…ìŠ¤íŠ¸ ì •ë¦¬"""
        cutoff_time = datetime.now(timezone.utc).timestamp() - (max_age_hours * 3600)
        
        old_conversations = [
            conv_id for conv_id, context in self.conversations.items()
            if context.updated_at and context.updated_at.timestamp() < cutoff_time
        ]
        
        for conv_id in old_conversations:
            del self.conversations[conv_id]
        
        if old_conversations:
            logger.info(f"ì˜¤ë˜ëœ ì»¨í…ìŠ¤íŠ¸ {len(old_conversations)}ê°œ ì •ë¦¬ ì™„ë£Œ")
    
    def get_conversation_stats(self) -> Dict[str, Any]:
        """ëŒ€í™” í†µê³„ ë°˜í™˜"""
        total_conversations = len(self.conversations)
        total_messages = sum(len(ctx.recent_messages) for ctx in self.conversations.values())
        
        active_conversations = sum(
            1 for ctx in self.conversations.values()
            if ctx.updated_at and (datetime.now(timezone.utc) - ctx.updated_at).seconds < 3600
        )
        
        return {
            "total_conversations": total_conversations,
            "active_conversations": active_conversations,
            "total_messages": total_messages,
            "avg_messages_per_conversation": total_messages / max(total_conversations, 1),
            "unique_entities": len(set(
                entity for ctx in self.conversations.values() 
                for entity in ctx.entities
            ))
        }
    
    def export_conversation(self, conversation_id: str) -> Optional[Dict]:
        """ëŒ€í™” ë‚´ìš© ë‚´ë³´ë‚´ê¸° (ë””ë²„ê·¸ìš©)"""
        if conversation_id not in self.conversations:
            return None
        
        context = self.conversations[conversation_id]
        return {
            "conversation_id": conversation_id,
            "summary": context.summary,
            "entities": context.entities,
            "messages": [asdict(msg) for msg in context.recent_messages],
            "updated_at": context.updated_at.isoformat() if context.updated_at else None
        }
        

    def update_context(self, conversation_id: str, role, content: str) -> ConversationContext:
        """ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸ ë©”ì†Œë“œ (app.py í˜¸í™˜ì„±)"""
        try:
            role_value = role.value if hasattr(role, 'value') else str(role)
            return self.add_message(conversation_id, role_value, content)
        except Exception as e:
            logger.warning(f"update_context ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ ì»¨í…ìŠ¤íŠ¸ ë°˜í™˜
            return self.get_or_create_context(conversation_id)




# ================================================================
# 6. ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë° í¸ì˜ í•¨ìˆ˜ë“¤
# ================================================================

_context_manager = None


def get_context_manager() -> ContextManager:
    """ContextManager ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _context_manager
    if _context_manager is None:
        _context_manager = ContextManager()
    return _context_manager


# í¸ì˜ í•¨ìˆ˜ë“¤
def create_query_request(conversation_id: str, query_text: str, trace_id: Optional[str] = None) -> QueryRequest:
    """QueryRequest ìƒì„± í¸ì˜ í•¨ìˆ˜"""
    manager = get_context_manager()
    return manager.create_query_request(conversation_id, query_text, trace_id)


def add_response(conversation_id: str, response_text: str) -> ConversationContext:
    """ì‘ë‹µ ì¶”ê°€ í¸ì˜ í•¨ìˆ˜"""
    manager = get_context_manager()
    return manager.add_response(conversation_id, response_text)


def get_context_hash(conversation_id: str) -> str:
    """ì»¨í…ìŠ¤íŠ¸ í•´ì‹œ í¸ì˜ í•¨ìˆ˜"""
    manager = get_context_manager()
    return manager.get_context_hash(conversation_id)


def cleanup_old_contexts():
    """ì˜¤ë˜ëœ ì»¨í…ìŠ¤íŠ¸ ì •ë¦¬ í¸ì˜ í•¨ìˆ˜"""
    manager = get_context_manager()
    manager.cleanup_old_contexts()


# ================================================================
# 7. í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
# ================================================================

def test_context_manager():
    """ContextManager í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    manager = get_context_manager()
    
    print("ğŸ§ª ContextManager í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # í…ŒìŠ¤íŠ¸ ëŒ€í™” ì‹œë®¬ë ˆì´ì…˜
    conv_id = "test-conversation-123"
    
    try:
        # ì²« ë²ˆì§¸ ì§ˆë¬¸
        print("\n=== í…ŒìŠ¤íŠ¸ 1: ì²« ë²ˆì§¸ ì§ˆë¬¸ ===")
        req1 = manager.create_query_request(conv_id, "2024ë…„ ì¤‘ê²¬ë¦¬ë” ê³¼ì • ë§Œì¡±ë„ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”")
        print(f"Query 1 - Follow-up: {req1.follow_up}")
        print(f"Entities: {req1.context.entities[:5]}")
        print(f"Original: 2024ë…„ ì¤‘ê²¬ë¦¬ë” ê³¼ì • ë§Œì¡±ë„ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”")
        print(f"Expanded: {req1.content}")
        
        # ì‹œìŠ¤í…œ ì‘ë‹µ ì¶”ê°€
        manager.add_response(conv_id, "2024ë…„ ì¤‘ê²¬ë¦¬ë” ê³¼ì • ë§Œì¡±ë„ëŠ” ì „ì²´ í‰ê·  4.2ì ì…ë‹ˆë‹¤. ê¸°ë³¸ì—­ëŸ‰ 14.33%, ë¦¬ë”ì‹­ì—­ëŸ‰ 14.70%, ì§ë¬´ì—­ëŸ‰ 24.64% í–¥ìƒë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # í›„ì† ì§ˆë¬¸
        print("\n=== í…ŒìŠ¤íŠ¸ 2: í›„ì† ì§ˆë¬¸ ===")
        req2 = manager.create_query_request(conv_id, "ê·¸ ì¤‘ì—ì„œ ê°€ì¥ ë†’ì€ í–¥ìƒë„ë¥¼ ë³´ì¸ ì—­ëŸ‰ì€?")
        print(f"Query 2 - Follow-up: {req2.follow_up}")
        print(f"Original: ê·¸ ì¤‘ì—ì„œ ê°€ì¥ ë†’ì€ í–¥ìƒë„ë¥¼ ë³´ì¸ ì—­ëŸ‰ì€?")
        print(f"Expanded: {req2.content}")
        print(f"Context hash: {manager.get_context_hash(conv_id)}")
        
        # ì‹œìŠ¤í…œ ì‘ë‹µ ì¶”ê°€
        manager.add_response(conv_id, "ì§ë¬´ì—­ëŸ‰ì´ 24.64%ë¡œ ê°€ì¥ ë†’ì€ í–¥ìƒë„ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.")
        
        # ìƒˆë¡œìš´ ë…ë¦½ì  ì§ˆë¬¸
        print("\n=== í…ŒìŠ¤íŠ¸ 3: ë…ë¦½ì  ì§ˆë¬¸ ===")
        req3 = manager.create_query_request(conv_id, "ì‚¬ì´ë²„êµìœ¡ ë‹´ë‹¹ì ì—°ë½ì²˜ ì•Œë ¤ì£¼ì„¸ìš”")
        print(f"Query 3 - Follow-up: {req3.follow_up}")
        print(f"Entities: {req3.context.entities[:5]}")
        
        # ì—”í‹°í‹° ì¶”ì¶œ í…ŒìŠ¤íŠ¸
        print("\n=== í…ŒìŠ¤íŠ¸ 4: ì—”í‹°í‹° ì¶”ì¶œ ===")
        test_texts = [
            "êµìœ¡ê¸°íšë‹´ë‹¹ì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”",
            "055-254-2053ìœ¼ë¡œ ì—°ë½ë°”ëë‹ˆë‹¤",
            "2025ë…„ 3ì›” ë¦¬ë”ì‹­ êµìœ¡ ì¼ì •",
            "ë‚˜ë¼ë°°ì›€í„° ì§ë¬´êµìœ¡ ê³¼ì •"
        ]
        
        for text in test_texts:
            entities = manager.entity_extractor.extract_entities(text)
            print(f"'{text}' â†’ {entities}")
        
        # í†µê³„ ì¶œë ¥
        print("\n=== í…ŒìŠ¤íŠ¸ 5: í†µê³„ ===")
        stats = manager.get_conversation_stats()
        print(f"í†µê³„: {stats}")
        
        # ëŒ€í™” ë‚´ìš© ë‚´ë³´ë‚´ê¸°
        print("\n=== í…ŒìŠ¤íŠ¸ 6: ëŒ€í™” ë‚´ìš© ë‚´ë³´ë‚´ê¸° ===")
        exported = manager.export_conversation(conv_id)
        if exported:
            print(f"ëŒ€í™” ID: {exported['conversation_id']}")
            print(f"ìš”ì•½: {exported['summary']}")
            print(f"ì—”í‹°í‹° ìˆ˜: {len(exported['entities'])}")
            print(f"ë©”ì‹œì§€ ìˆ˜: {len(exported['messages'])}")
        
        print("\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        return True
        
    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False


# ================================================================
# 8. ì„±ëŠ¥ ìµœì í™” ìœ í‹¸ë¦¬í‹°
# ================================================================

class PerformanceMonitor:
    """ContextManager ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§"""
    
    def __init__(self):
        self.metrics = {
            'entity_extraction_times': [],
            'summary_generation_times': [],
            'followup_detection_times': [],
            'query_expansion_times': [],
            'total_request_times': []
        }
    
    def record_time(self, operation: str, duration_ms: float):
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê¸°ë¡"""
        if operation in self.metrics:
            self.metrics[operation].append(duration_ms)
    
    def get_performance_stats(self) -> Dict[str, Dict[str, float]]:
        """ì„±ëŠ¥ í†µê³„ ë°˜í™˜"""
        stats = {}
        for operation, times in self.metrics.items():
            if times:
                stats[operation] = {
                    'avg_ms': sum(times) / len(times),
                    'max_ms': max(times),
                    'min_ms': min(times),
                    'count': len(times)
                }
        return stats


# ì„±ëŠ¥ ëª¨ë‹ˆí„° ì‹±ê¸€í†¤
_performance_monitor = PerformanceMonitor()


def get_performance_monitor() -> PerformanceMonitor:
    """ì„±ëŠ¥ ëª¨ë‹ˆí„° ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    return _performance_monitor


# ================================================================
# 9. ë©”ì¸ ì‹¤í–‰ë¶€
# ================================================================

if __name__ == "__main__":
    """ContextManager ê°œë°œ í…ŒìŠ¤íŠ¸"""
    import sys
    import os
    
    # í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì •
    if not os.getenv("OPENAI_API_KEY"):
        print("âš ï¸ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ .env íŒŒì¼ì— API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        sys.exit(1)
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    success = test_context_manager()
    
    if success:
        print("\nğŸ‰ ContextManager ì™„ì„± ë° í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
        
        # ì„±ëŠ¥ í†µê³„ ì¶œë ¥
        perf_stats = get_performance_monitor().get_performance_stats()
        if perf_stats:
            print("\nğŸ“Š ì„±ëŠ¥ í†µê³„:")
            for operation, stats in perf_stats.items():
                print(f"  {operation}: {stats['avg_ms']:.1f}ms (í‰ê· )")
    else:
        print("\nğŸ’¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        sys.exit(1)
