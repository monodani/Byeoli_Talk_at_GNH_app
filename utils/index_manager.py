#!/usr/bin/env python3
"""
ë²¼ë¦¬í†¡@ê²½ìƒë‚¨ë„ì¸ì¬ê°œë°œì› (ê²½ìƒë‚¨ë„ì¸ì¬ê°œë°œì› RAG ì±—ë´‡) - index_manager.py (OpenAI í˜¸í™˜ì„± ìˆ˜ì • ë²„ì „)

IndexManager ì‹±ê¸€í†¤: ëª¨ë“  ë²¡í„°ìŠ¤í† ì–´ ì¤‘ì•™ ê´€ë¦¬
- ì•± ê¸°ë™ ì‹œ ëª¨ë“  FAISS ì¸ë±ìŠ¤ ì‚¬ì „ ë¡œë“œ
- ì €ì¥ëœ BM25 íŒŒì¼ ë¡œë“œ
- í•´ì‹œ ê¸°ë°˜ íŒŒì¼ ë³€ê²½ ê°ì§€ë¡œ í•«ìŠ¤ì™‘
- ì „ì—­ ê³µìœ ë¡œ í•¸ë“¤ëŸ¬ ê°„ ì¼ê´€ì„± ë³´ì¥
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë‹¨ì¼ ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬

ğŸš¨ ì£¼ìš” ìˆ˜ì •ì‚¬í•­:
âœ… OpenAIEmbeddings ì´ˆê¸°í™” ë°©ì‹ ìˆ˜ì • (í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°)
âœ… API í‚¤ ëª…ì‹œì  ì „ë‹¬
âœ… Graceful Degradation ì ìš©
âœ… ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”
"""

import hashlib
import logging
import threading
import time
import pickle
import traceback
from pathlib import Path
from typing import Dict, Optional, Any, List, Tuple
from datetime import datetime
from dataclasses import dataclass, field

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ
from utils.config import config
from utils.contracts import HandlerType
from utils.textifier import TextChunk

# ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬
from langchain_community.vectorstores import FAISS
from rank_bm25 import BM25Okapi
import numpy as np

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# ================================================================
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
# ================================================================
try:
    ROOT_DIR = Path(__file__).parent.parent.absolute()
except NameError:
    ROOT_DIR = Path(".").absolute()

# ================================================================
# 1. ë²¡í„°ìŠ¤í† ì–´ ë©”íƒ€ë°ì´í„° í´ë˜ìŠ¤
# ================================================================

@dataclass
class VectorStoreMetadata:
    """
    ë²¡í„°ìŠ¤í† ì–´ ë©”íƒ€ë°ì´í„° ë° ìƒíƒœ ê´€ë¦¬ (BM25 íŒŒì¼ ì§€ì›)
    """
    domain: str
    vectorstore_base_dir: Path
    
    # post_initì—ì„œ ì„¤ì •ë˜ë¯€ë¡œ init=Falseë¡œ ì„¤ì •
    vectorstore_path: Path = field(init=False)
    faiss_path: Path = field(init=False)
    pkl_path: Path = field(init=False)
    bm25_path: Path = field(init=False)
    
    # ëŸ°íƒ€ì„ ì†ì„±
    embeddings: Optional[Any] = None  # OpenAIEmbeddings íƒ€ì… íŒíŠ¸ ì œê±°
    vectorstore: Optional[FAISS] = None
    bm25: Optional[BM25Okapi] = None
    documents: List[TextChunk] = field(default_factory=list)
    last_loaded: Optional[datetime] = None
    load_count: int = 0
    error_count: int = 0
    last_hash: Optional[str] = None
    
    def __post_init__(self):
        # data_ingestion.pyì™€ ë™ì¼í•œ ê²½ë¡œ ë§¤í•‘ ì‚¬ìš©
        self.vectorstore_path = self._get_vectorstore_path()
        self.faiss_path = self.vectorstore_path / f"{self.domain}_index.faiss"
        self.pkl_path = self.vectorstore_path / f"{self.domain}_index.pkl"
        self.bm25_path = self.vectorstore_path / f"{self.domain}_index.bm25"
        
        # âœ… OpenAIEmbeddings ì•ˆì „í•œ ì´ˆê¸°í™”
        self.embeddings = self._init_embeddings()
    
    def _init_embeddings(self) -> Optional[Any]:
        """
        OpenAIEmbeddings ì•ˆì „í•œ ì´ˆê¸°í™” (í˜¸í™˜ì„± ìˆ˜ì •)
        """
        try:
            # LangChain OpenAI Embeddings í˜¸í™˜ì„± ìˆ˜ì •
            from langchain_openai import OpenAIEmbeddings
            
            # API í‚¤ í™•ì¸
            api_key = config.OPENAI_API_KEY
            if not api_key:
                logger.warning("âš ï¸ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ì„ë² ë”©ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            # ìµœì†Œí•œì˜ ë§¤ê°œë³€ìˆ˜ë¡œ ì•ˆì „í•œ ì´ˆê¸°í™” (proxies ì˜¤ë¥˜ ë°©ì§€)
            embeddings = OpenAIEmbeddings(
                api_key=api_key,
                model=config.EMBEDDING_MODEL
            )
            
            logger.debug(f"âœ… {self.domain} ë„ë©”ì¸ìš© OpenAIEmbeddings ì´ˆê¸°í™” ì™„ë£Œ")
            return embeddings
            
        except ImportError as e:
            logger.error(f"âŒ LangChain OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
            return None
        except Exception as e:
            logger.error(f"âŒ {self.domain} ë„ë©”ì¸ OpenAIEmbeddings ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return None
    
    def _get_vectorstore_path(self) -> Path:
        """ë„ë©”ì¸ë³„ ë²¡í„°ìŠ¤í† ì–´ ê²½ë¡œ ë§¤í•‘"""
        domain_mapping = {
            "course_satisfaction": "vectorstore_course_satisfaction",
            "subject_satisfaction": "vectorstore_subject_satisfaction", 
            "satisfaction": "vectorstore_unified_satisfaction",
            "publish": "vectorstore_unified_publish",
            "general": "vectorstore_general",
            "cyber": "vectorstore_cyber",
            "notice": "vectorstore_notice",
            "menu": "vectorstore_menu"
        }
        
        vectorstore_dir_name = domain_mapping.get(self.domain, f"vectorstore_{self.domain}")
        return self.vectorstore_base_dir / vectorstore_dir_name
    
    def exists(self) -> bool:
        """í•„ìˆ˜ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
        return (
            self.faiss_path.exists() and 
            self.pkl_path.exists() and
            self.vectorstore_path.exists()
        )
    
    def get_file_hash(self) -> str:
        """íŒŒì¼ ë³€ê²½ ê°ì§€ìš© í•´ì‹œ ê³„ì‚°"""
        try:
            if not self.exists():
                return ""
                
            hash_content = ""
            
            # FAISS íŒŒì¼ í•´ì‹œ
            if self.faiss_path.exists():
                hash_content += str(self.faiss_path.stat().st_mtime)
            
            # PKL íŒŒì¼ í•´ì‹œ
            if self.pkl_path.exists():
                hash_content += str(self.pkl_path.stat().st_mtime)
                
            # BM25 íŒŒì¼ í•´ì‹œ (ì„ íƒì )
            if self.bm25_path.exists():
                hash_content += str(self.bm25_path.stat().st_mtime)
            
            return hashlib.md5(hash_content.encode()).hexdigest()
        except Exception as e:
            logger.warning(f"âš ï¸ {self.domain} í•´ì‹œ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return ""

# ================================================================
# 2. IndexManager ì‹±ê¸€í†¤ í´ë˜ìŠ¤
# ================================================================

class IndexManager:
    """
    ëª¨ë“  ë²¡í„°ìŠ¤í† ì–´ë¥¼ ê´€ë¦¬í•˜ëŠ” ì‹±ê¸€í†¤ í´ë˜ìŠ¤ (OpenAI í˜¸í™˜ì„± ìˆ˜ì •)
    """
    _instance = None
    _instance_lock = threading.Lock()
    
    def __new__(cls):
        if cls._instance is None:
            with cls._instance_lock:
                if cls._instance is None:
                    cls._instance = super(IndexManager, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        if hasattr(self, '_initialized'):
            return
            
        self.metadata: Dict[str, VectorStoreMetadata] = {}
        
        # âœ… ê¸€ë¡œë²Œ OpenAIEmbeddings ì•ˆì „í•œ ì´ˆê¸°í™”
        self.embeddings = self._init_global_embeddings()
        
        for domain in config.HANDLERS:
            self.metadata[domain] = VectorStoreMetadata(
                domain=domain,
                vectorstore_base_dir=Path(config.VECTORSTORE_DIR)
            )
        
        logger.info(f"ğŸš€ IndexManager ì‹±ê¸€í†¤ ì´ˆê¸°í™” ì™„ë£Œ: {len(self.metadata)}ê°œ ë„ë©”ì¸")
        self.load_all_domains()
        self._initialized = True

    def _init_global_embeddings(self) -> Optional[Any]:
        """
        ê¸€ë¡œë²Œ OpenAIEmbeddings ì•ˆì „í•œ ì´ˆê¸°í™”
        """
        try:
            from langchain_openai import OpenAIEmbeddings
            
            api_key = config.OPENAI_API_KEY
            if not api_key:
                logger.warning("âš ï¸ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ì„ë² ë”© ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤.")
                return None
            
            embeddings = OpenAIEmbeddings(
                api_key=api_key,
                model=config.EMBEDDING_MODEL
            )
            
            logger.info(f"âœ… ê¸€ë¡œë²Œ OpenAIEmbeddings ì´ˆê¸°í™” ì™„ë£Œ: {config.EMBEDDING_MODEL}")
            return embeddings
            
        except ImportError as e:
            logger.error(f"âŒ LangChain OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
            logger.info("ğŸ”„ Graceful Degradation: ì„ë² ë”© ì—†ì´ ê¸°ë³¸ ê¸°ëŠ¥ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤.")
            return None
        except Exception as e:
            logger.error(f"âŒ ê¸€ë¡œë²Œ OpenAIEmbeddings ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            logger.info("ğŸ”„ Graceful Degradation: ì„ë² ë”© ì—†ì´ ê¸°ë³¸ ê¸°ëŠ¥ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤.")
            return None

    def _load_domain(self, domain: str):
        """
        ë‹¨ì¼ ë„ë©”ì¸ì˜ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ë¡œë“œ (Pydantic v1/v2 í˜¸í™˜ì„± ìˆ˜ì •)
        """
        meta = self.metadata[domain]
        
        logger.info(f"ğŸ”„ ë„ë©”ì¸ {domain} ë¡œë“œ ì‹œì‘...")
        logger.debug(f"  - FAISS ê²½ë¡œ: {meta.faiss_path}")
        logger.debug(f"  - PKL ê²½ë¡œ: {meta.pkl_path}")
        logger.debug(f"  - BM25 ê²½ë¡œ: {meta.bm25_path}")
        
        try:
            if not meta.exists():
                logger.warning(f"âš ï¸ ë„ë©”ì¸ {domain}ì— í•„ìš”í•œ ì¸ë±ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¡œë“œ ê±´ë„ˆëœë‹ˆë‹¤.")
                meta.vectorstore = None
                meta.bm25 = None
                return
            
            start_time = time.time()
            
            # ì„ë² ë”© ëª¨ë¸ ì‚¬ìš© (ê¸€ë¡œë²Œ ë˜ëŠ” ë„ë©”ì¸ë³„)
            embeddings_to_use = meta.embeddings or self.embeddings
            if not embeddings_to_use:
                logger.warning(f"âš ï¸ {domain} ì„ë² ë”© ëª¨ë¸ì´ ì—†ì–´ FAISS ë¡œë“œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
                meta.vectorstore = None
            else:
                # FAISS ì¸ë±ìŠ¤ ë¡œë“œ
                meta.vectorstore = FAISS.load_local(
                    str(meta.vectorstore_path),
                    embeddings_to_use,
                    index_name=f"{domain}_index",
                    allow_dangerous_deserialization=True
                )
            
            # âœ… ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ë¡œë“œ (Pydantic v1/v2 í˜¸í™˜ì„± ì²˜ë¦¬)
            try:
                with open(meta.pkl_path, "rb") as f:
                    loaded_data = pickle.load(f)
                    
                    # Pydantic v1 â†’ v2 ë³€í™˜ ì²˜ë¦¬
                    if isinstance(loaded_data, list):
                        meta.documents = []
                        for item in loaded_data:
                            try:
                                if hasattr(item, '__fields_set__'):
                                    # Pydantic v1 ê°ì²´ ê°ì§€ â†’ v2ë¡œ ë³€í™˜
                                    logger.debug(f"ğŸ”„ Pydantic v1 ê°ì²´ë¥¼ v2ë¡œ ë³€í™˜: {type(item)}")
                                    
                                    # ê¸°ë³¸ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ í›„ ì¬ìƒì„±
                                    if hasattr(item, 'dict'):
                                        item_dict = item.dict()
                                    elif hasattr(item, 'model_dump'):
                                        item_dict = item.model_dump()
                                    else:
                                        # ì§ì ‘ ì†ì„± ì¶”ì¶œ
                                        item_dict = {
                                            'text': getattr(item, 'text', ''),
                                            'metadata': getattr(item, 'metadata', {}),
                                            'source_id': getattr(item, 'source_id', ''),
                                            'chunk_index': getattr(item, 'chunk_index', 0)
                                        }
                                    
                                    # ìƒˆë¡œìš´ TextChunk ìƒì„±
                                    new_chunk = TextChunk(**item_dict)
                                    meta.documents.append(new_chunk)
                                else:
                                    # ì´ë¯¸ Pydantic v2 ë˜ëŠ” í˜¸í™˜ ê°ì²´
                                    meta.documents.append(item)
                            except Exception as item_error:
                                logger.warning(f"âš ï¸ ê°œë³„ ë¬¸ì„œ ë³€í™˜ ì‹¤íŒ¨: {item_error}, ê±´ë„ˆëœ€")
                                continue
                    else:
                        meta.documents = loaded_data
                        
                logger.info(f"âœ… ë„ë©”ì¸ {domain} ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(meta.documents)}ê°œ")
                
            except Exception as pkl_error:
                logger.error(f"âŒ ë„ë©”ì¸ {domain} PKL ë¡œë“œ ì‹¤íŒ¨: {pkl_error}")
                
                # âœ… Fallback: FAISS docstoreì—ì„œ ì§ì ‘ ë¡œë“œ
                if meta.vectorstore:
                    logger.info(f"ğŸ”„ {domain} FAISS docstoreì—ì„œ ë¬¸ì„œ ë³µêµ¬ ì‹œë„")
                    try:
                        # FAISSì˜ docstoreì—ì„œ ë¬¸ì„œ ëª©ë¡ì„ ì§ì ‘ ê°€ì ¸ì˜µë‹ˆë‹¤.
                        raw_documents = list(meta.vectorstore.docstore._dict.values())
                        meta.documents = []
                        
                        for i, doc in enumerate(raw_documents):
                            # LangChain Document â†’ TextChunk ë³€í™˜
                            chunk = TextChunk(
                                text=doc.page_content,
                                metadata=doc.metadata,
                                source_id=doc.metadata.get('source_id', f'{domain}_{i}'),
                                chunk_index=i
                            )
                            meta.documents.append(chunk)
                        
                        logger.info(f"âœ… {domain} FAISSì—ì„œ {len(meta.documents)}ê°œ ë¬¸ì„œ ë³µêµ¬ ì™„ë£Œ")
                    except Exception as fallback_error:
                        logger.error(f"âŒ {domain} FAISS ë¬¸ì„œ ë³µêµ¬ë„ ì‹¤íŒ¨: {fallback_error}")
                        meta.documents = []
                else:
                    meta.documents = []
            
            # BM25 ì¸ë±ìŠ¤ ë¡œë“œ
            if meta.bm25_path.exists():
                try:
                    with open(meta.bm25_path, 'rb') as f:
                        bm25_data = pickle.load(f)
                        if isinstance(bm25_data, tuple):
                            meta.bm25, _ = bm25_data
                        else:
                            meta.bm25 = bm25_data
                    logger.info(f"âœ… ë„ë©”ì¸ {domain} BM25 ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ.")
                except Exception as bm25_error:
                    logger.warning(f"âš ï¸ ë„ë©”ì¸ {domain} BM25 ë¡œë“œ ì‹¤íŒ¨: {bm25_error}")
                    meta.bm25 = None
            else:
                logger.warning(f"âš ï¸ ë„ë©”ì¸ {domain} BM25 ì¸ë±ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                meta.bm25 = None
            
            meta.last_loaded = datetime.now()
            meta.load_count += 1
            meta.last_hash = meta.get_file_hash()
            elapsed = time.time() - start_time
            
            # ë¡œë“œ ìƒíƒœ ìš”ì•½
            status_parts = []
            if meta.vectorstore:
                status_parts.append("FAISS")
            if meta.bm25:
                status_parts.append("BM25")
            if meta.documents:
                status_parts.append(f"ë¬¸ì„œ {len(meta.documents)}ê°œ")
            
            logger.info(f"âœ… ë„ë©”ì¸ {domain} ë¡œë“œ ì„±ê³µ! ({', '.join(status_parts)}, {elapsed:.2f}ì´ˆ)")
            
        except Exception as e:
            meta.error_count += 1
            logger.error(f"âŒ ë„ë©”ì¸ {domain} ë¡œë“œ ì‹¤íŒ¨: {e}")
            logger.debug(f"ìƒì„¸ ì˜¤ë¥˜:\n{traceback.format_exc()}")
            
            # Graceful Degradation: ë¶€ë¶„ ë¡œë“œë¼ë„ ì‹œë„
            meta.vectorstore = None
            meta.bm25 = None


    def load_all_domains(self):
        """ëª¨ë“  ë„ë©”ì¸ ë¡œë“œ"""
        logger.info(f"ğŸ”„ ì „ì²´ ë„ë©”ì¸ ë¡œë“œ ì‹œì‘: {list(self.metadata.keys())}")
        
        start_time = time.time()
        loaded_count = 0
        
        for domain in self.metadata.keys():
            try:
                self._load_domain(domain)
                loaded_count += 1
            except Exception as e:
                logger.error(f"âŒ ë„ë©”ì¸ {domain} ë¡œë“œ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        
        elapsed = time.time() - start_time
        logger.info(f"ğŸ‰ ë„ë©”ì¸ ë¡œë“œ ì™„ë£Œ: {loaded_count}/{len(self.metadata)}ê°œ ì„±ê³µ ({elapsed:.2f}ì´ˆ)")

    def get_vectorstore(self, domain: str) -> Optional[FAISS]:
        """ë„ë©”ì¸ë³„ ë²¡í„°ìŠ¤í† ì–´ íšë“"""
        if domain not in self.metadata:
            logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ë„ë©”ì¸: {domain}")
            return None
        
        return self.metadata[domain].vectorstore

    def get_bm25(self, domain: str) -> Optional[BM25Okapi]:
        """ë„ë©”ì¸ë³„ BM25 ì¸ë±ìŠ¤ íšë“"""
        if domain not in self.metadata:
            logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ë„ë©”ì¸: {domain}")
            return None
        
        return self.metadata[domain].bm25

    def get_documents(self, domain: str) -> List[TextChunk]:
        """ë„ë©”ì¸ë³„ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ íšë“"""
        if domain not in self.metadata:
            logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ë„ë©”ì¸: {domain}")
            return []
        
        return self.metadata[domain].documents

    def health_check(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ìƒíƒœ ì²´í¬"""
        status = {
            "total_domains": len(self.metadata),
            "loaded_domains": 0,
            "failed_domains": 0,
            "domains_detail": {},
            "global_embeddings": self.embeddings is not None
        }
        
        for domain, meta in self.metadata.items():
            domain_status = {
                "loaded": meta.vectorstore is not None,
                "bm25_available": meta.bm25 is not None,
                "documents_count": len(meta.documents),
                "load_count": meta.load_count,
                "error_count": meta.error_count,
                "last_loaded": meta.last_loaded.isoformat() if meta.last_loaded else None
            }
            
            if domain_status["loaded"]:
                status["loaded_domains"] += 1
            else:
                status["failed_domains"] += 1
            
            status["domains_detail"][domain] = domain_status
        
        return status

# ================================================================
# 3. ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ íŒ©í„°ë¦¬ ë° í˜¸í™˜ì„± í•¨ìˆ˜
# ================================================================

_index_manager_instance = None

def get_index_manager() -> IndexManager:
    """IndexManager ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ íšë“"""
    global _index_manager_instance
    if _index_manager_instance is None:
        _index_manager_instance = IndexManager()
    return _index_manager_instance

def preload_all_indexes() -> Dict[str, Any]:
    """
    ëª¨ë“  ì¸ë±ìŠ¤ ì‚¬ì „ ë¡œë“œ (app.py í˜¸í™˜ì„± ê°œì„ )
    
    Returns:
        Dict[str, Any]: ë¡œë“œ ê²°ê³¼ ì •ë³´
    """
    logger.info("ğŸš€ ì¸ë±ìŠ¤ ì‚¬ì „ ë¡œë“œ ì‹œì‘")
    start_time = time.time()
    
    try:
        manager = get_index_manager()
        
        # ì¬ë¡œë“œ ì‹¤í–‰
        manager.load_all_domains()
        
        # ìƒíƒœ ì²´í¬
        status = manager.health_check()
        elapsed_time = time.time() - start_time
        
        logger.info(f"ğŸ“Š ì¸ë±ìŠ¤ ë¡œë“œ ìƒíƒœ: {status['loaded_domains']}/{status['total_domains']}ê°œ ì„±ê³µ")
        
        # app.pyì—ì„œ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
        return {
            "success": status["loaded_domains"] > 0,
            "loaded_indexes": list(status["domains_detail"].keys()),
            "performance": {
                "load_time": elapsed_time,
                "loaded_domains": status["loaded_domains"],
                "total_domains": status["total_domains"]
            },
            "error": None if status["loaded_domains"] > 0 else "No domains loaded"
        }
        
    except Exception as e:
        logger.error(f"âŒ ì¸ë±ìŠ¤ ì‚¬ì „ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {
            "success": False,
            "loaded_indexes": [],
            "performance": {},
            "error": str(e)
        }

def index_health_check() -> Dict[str, Any]:
    """
    IndexManager í—¬ìŠ¤ì²´í¬ (app.py í˜¸í™˜ì„± í•¨ìˆ˜)
    
    Returns:
        Dict[str, Any]: ì‹œìŠ¤í…œ ìƒíƒœ ì •ë³´
    """
    try:
        manager = get_index_manager()
        return manager.health_check()
    except Exception as e:
        logger.error(f"âŒ í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨: {e}")
        return {
            "total_domains": 0,
            "loaded_domains": 0,
            "failed_domains": 0,
            "domains_detail": {},
            "global_embeddings": False,
            "error": str(e)
        }

# ================================================================
# 4. í…ŒìŠ¤íŠ¸ ë° ê²€ì¦ 
# ================================================================

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    print("ğŸ§ª IndexManager í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    try:
        # ì‹±ê¸€í†¤ í…ŒìŠ¤íŠ¸
        manager1 = get_index_manager()
        manager2 = get_index_manager()
        assert manager1 is manager2, "ì‹±ê¸€í†¤ íŒ¨í„´ ì‹¤íŒ¨"
        print("âœ… ì‹±ê¸€í†¤ íŒ¨í„´ í…ŒìŠ¤íŠ¸ í†µê³¼")
        
        # ìƒíƒœ ì²´í¬
        status = manager1.health_check()
        print(f"ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ: {status}")
        
        print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        traceback.print_exc()
