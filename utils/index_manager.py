#!/usr/bin/env python3
"""
ë²¼ë¦¬í†¡@ê²½ìƒë‚¨ë„ì¸ì¬ê°œë°œì› (ê²½ìƒë‚¨ë„ì¸ì¬ê°œë°œì› RAG ì±—ë´‡) - index_manager.py (OpenAI í˜¸í™˜ì„± ìˆ˜ì • ë²„ì „)

IndexManager ì‹±ê¸€í†¤: ëª¨ë“  ë²¡í„°ìŠ¤í† ì–´ ì¤‘ì•™ ê´€ë¦¬
- ì•± ê¸°ë™ ì‹œ ëª¨ë“  FAISS ì¸ë±ìŠ¤ ì‚¬ì „ ë¡œë“œ
- ì €ì¥ëœ BM25 íŒŒì¼ ë¡œë“œ
- í•´ì‹œ ê¸°ë°˜ íŒŒì¼ ë³€ê²½ ê°ì§€ë¡œ í•«ìŠ¤ì™‘
- ì „ì—­ ê³µìœ ë¡œ í•¸ë“¤ëŸ¬ ê°„ ì¼ê´€ì„± ë³´ì¥
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë‹¨ì¼ ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬

ğŸš¨ ì£¼ìš” ìˆ˜ì •ì‚¬í•­:
âœ… OpenAIEmbeddings ì´ˆê¸°í™” ë°©ì‹ ìˆ˜ì • (í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°)
âœ… API í‚¤ ëª…ì‹œì  ì „ë‹¬
âœ… Graceful Degradation ì ìš©
âœ… ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”
"""

import hashlib
import logging
import threading
import time
import pickle
import traceback
from pathlib import Path
from typing import Dict, Optional, Any, List, Tuple
from datetime import datetime
from dataclasses import dataclass, field

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ
from utils.config import config
from utils.contracts import HandlerType
from utils.textifier import TextChunk

# ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬
from langchain_community.vectorstores import FAISS
from rank_bm25 import BM25Okapi
import numpy as np

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)

# ================================================================
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
# ================================================================
try:
    ROOT_DIR = Path(__file__).parent.parent.absolute()
except NameError:
    ROOT_DIR = Path(".").absolute()

# ================================================================
# 1. ë²¡í„°ìŠ¤í† ì–´ ë©”íƒ€ë°ì´í„° í´ë˜ìŠ¤
# ================================================================

@dataclass
class VectorStoreMetadata:
    """
    ë²¡í„°ìŠ¤í† ì–´ ë©”íƒ€ë°ì´í„° ë° ìƒíƒœ ê´€ë¦¬ (BM25 íŒŒì¼ ì§€ì›)
    """
    domain: str
    vectorstore_base_dir: Path
    
    # post_initì—ì„œ ì„¤ì •ë˜ë¯€ë¡œ init=Falseë¡œ ì„¤ì •
    vectorstore_path: Path = field(init=False)
    faiss_path: Path = field(init=False)
    pkl_path: Path = field(init=False)
    bm25_path: Path = field(init=False)
    
    # ëŸ°íƒ€ì„ ì†ì„±
    embeddings: Optional[Any] = None  # OpenAIEmbeddings íƒ€ì… íŒíŠ¸ ì œê±°
    vectorstore: Optional[FAISS] = None
    bm25: Optional[BM25Okapi] = None
    documents: List[TextChunk] = field(default_factory=list)
    last_loaded: Optional[datetime] = None
    load_count: int = 0
    error_count: int = 0
    last_hash: Optional[str] = None
    
    def __post_init__(self):
        # data_ingestion.pyì™€ ë™ì¼í•œ ê²½ë¡œ ë§¤í•‘ ì‚¬ìš©
        self.vectorstore_path = self._get_vectorstore_path()
        self.faiss_path = self.vectorstore_path / f"{self.domain}_index.faiss"
        self.pkl_path = self.vectorstore_path / f"{self.domain}_index.pkl"
        self.bm25_path = self.vectorstore_path / f"{self.domain}_index.bm25"
        
        # âœ… OpenAIEmbeddings ì•ˆì „í•œ ì´ˆê¸°í™”
        self.embeddings = self._init_embeddings()
    
    def _init_embeddings(self) -> Optional[Any]:
        """
        OpenAIEmbeddings ì•ˆì „í•œ ì´ˆê¸°í™” (Streamlit Secrets ì§€ì›)
        """
        try:
            from langchain_openai import OpenAIEmbeddings
            
            # ğŸš¨ í•µì‹¬ ìˆ˜ì •: ë™ì ìœ¼ë¡œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
            api_key = config.get('OPENAI_API_KEY') or config.OPENAI_API_KEY
            
            if not api_key:
                logger.warning(f"âš ï¸ {self.domain} ë„ë©”ì¸: OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ì„ë² ë”©ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            # ìµœì†Œí•œì˜ ë§¤ê°œë³€ìˆ˜ë¡œ ì•ˆì „í•œ ì´ˆê¸°í™”
            embeddings = OpenAIEmbeddings(
                api_key=api_key,
                model=config.EMBEDDING_MODEL
            )
            
            logger.debug(f"âœ… {self.domain} ë„ë©”ì¸ìš© OpenAIEmbeddings ì´ˆê¸°í™” ì™„ë£Œ")
            return embeddings
            
        except ImportError as e:
            logger.error(f"âŒ LangChain OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
            return None
        except Exception as e:
            logger.error(f"âŒ {self.domain} ë„ë©”ì¸ OpenAIEmbeddings ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return None

    
    def _get_vectorstore_path(self) -> Path:
        """ë„ë©”ì¸ë³„ ë²¡í„°ìŠ¤í† ì–´ ê²½ë¡œ ë§¤í•‘"""
        domain_mapping = {
            "course_satisfaction": "vectorstore_course_satisfaction",
            "subject_satisfaction": "vectorstore_subject_satisfaction", 
            "satisfaction": "vectorstore_unified_satisfaction",
            "publish": "vectorstore_unified_publish",
            "general": "vectorstore_general",
            "cyber": "vectorstore_cyber",
            "notice": "vectorstore_notice",
            "menu": "vectorstore_menu"
        }
        
        vectorstore_dir_name = domain_mapping.get(self.domain, f"vectorstore_{self.domain}")
        return self.vectorstore_base_dir / vectorstore_dir_name
    
    def exists(self) -> bool:
        """í•„ìˆ˜ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
        return (
            self.faiss_path.exists() and 
            self.pkl_path.exists() and
            self.vectorstore_path.exists()
        )
    
    def get_file_hash(self) -> str:
        """íŒŒì¼ ë³€ê²½ ê°ì§€ìš© í•´ì‹œ ê³„ì‚°"""
        try:
            if not self.exists():
                return ""
                
            hash_content = ""
            
            # FAISS íŒŒì¼ í•´ì‹œ
            if self.faiss_path.exists():
                hash_content += str(self.faiss_path.stat().st_mtime)
            
            # PKL íŒŒì¼ í•´ì‹œ
            if self.pkl_path.exists():
                hash_content += str(self.pkl_path.stat().st_mtime)
                
            # BM25 íŒŒì¼ í•´ì‹œ (ì„ íƒì )
            if self.bm25_path.exists():
                hash_content += str(self.bm25_path.stat().st_mtime)
            
            return hashlib.md5(hash_content.encode()).hexdigest()
        except Exception as e:
            logger.warning(f"âš ï¸ {self.domain} í•´ì‹œ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return ""

# ================================================================
# 2. IndexManager ì‹±ê¸€í†¤ í´ë˜ìŠ¤
# ================================================================

class IndexManager:
    """
    ëª¨ë“  ë²¡í„°ìŠ¤í† ì–´ë¥¼ ê´€ë¦¬í•˜ëŠ” ì‹±ê¸€í†¤ í´ë˜ìŠ¤ (OpenAI í˜¸í™˜ì„± ìˆ˜ì •)
    """
    _instance = None
    _instance_lock = threading.Lock()
    
    def __new__(cls):
        if cls._instance is None:
            with cls._instance_lock:
                if cls._instance is None:
                    cls._instance = super(IndexManager, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        if hasattr(self, '_initialized'):
            return
            
        self.metadata: Dict[str, VectorStoreMetadata] = {}
        
        # âœ… ê¸€ë¡œë²Œ OpenAIEmbeddings ì•ˆì „í•œ ì´ˆê¸°í™”
        self.embeddings = self._init_global_embeddings()
        
        for domain in config.HANDLERS:
            self.metadata[domain] = VectorStoreMetadata(
                domain=domain,
                vectorstore_base_dir=Path(config.VECTORSTORE_DIR)
            )
        
        logger.info(f"ğŸš€ IndexManager ì‹±ê¸€í†¤ ì´ˆê¸°í™” ì™„ë£Œ: {len(self.metadata)}ê°œ ë„ë©”ì¸")
        self.load_all_domains()
        self._initialized = True

    def _init_global_embeddings(self) -> Optional[Any]:
        """
        ê¸€ë¡œë²Œ OpenAIEmbeddings ì•ˆì „í•œ ì´ˆê¸°í™” (Streamlit Secrets ì§€ì›)
        """
        try:
            from langchain_openai import OpenAIEmbeddings
            
            # ğŸš¨ í•µì‹¬ ìˆ˜ì •: ë™ì ìœ¼ë¡œ API í‚¤ ê°€ì ¸ì˜¤ê¸°  
            api_key = config.get('OPENAI_API_KEY') or config.OPENAI_API_KEY
            
            if not api_key:
                logger.warning("âš ï¸ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ì„ë² ë”© ê¸°ëŠ¥ì´ ì œí•œë©ë‹ˆë‹¤.")
                return None
            
            embeddings = OpenAIEmbeddings(
                api_key=api_key,
                model=config.EMBEDDING_MODEL
            )
            
            logger.info(f"âœ… ê¸€ë¡œë²Œ OpenAIEmbeddings ì´ˆê¸°í™” ì™„ë£Œ: {config.EMBEDDING_MODEL}")
            return embeddings
            
        except ImportError as e:
            logger.error(f"âŒ LangChain OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}")
            logger.info("ğŸ”„ Graceful Degradation: ì„ë² ë”© ì—†ì´ ê¸°ë³¸ ê¸°ëŠ¥ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤.")
            return None
        except Exception as e:
            logger.error(f"âŒ ê¸€ë¡œë²Œ OpenAIEmbeddings ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            logger.info("ğŸ”„ Graceful Degradation: ì„ë² ë”© ì—†ì´ ê¸°ë³¸ ê¸°ëŠ¥ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤.")
            return None


    def _load_domain(self, domain: str):
        
        """
        ì—¬ê¸°ì„œ failì´ë©´ vectorstoreì— ë°•íŒ embed_fnì´ í‚¤/ëª¨ë¸ ë¶ˆëŸ‰ í™•ì •
        """
        logger.info(f"[{domain}] embed_fn type: {type(meta.vectorstore.embedding_function).__name__}")
        try:
            v = meta.vectorstore.embedding_function.embed_query("ping")
            logger.info(f"[{domain}] embed_fn ping OK, dim={len(v)} vs index.d={meta.vectorstore.index.d}")
        except Exception as e:
            logger.exception(f"[{domain}] embed_fn ping FAIL â†’ ì´ embed_fnë¡œëŠ” ì¿¼ë¦¬ ë¶ˆê°€")
    
        """
        ë‹¨ì¼ ë„ë©”ì¸ì˜ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ë¡œë“œ (ê²½ë¡œ ë¬¸ì œ ìˆ˜ì •)
        """
        meta = self.metadata[domain]
        
        logger.info(f"ğŸ”„ ë„ë©”ì¸ {domain} ë¡œë“œ ì‹œì‘...")
        logger.debug(f"  - FAISS ê²½ë¡œ: {meta.faiss_path}")
        logger.debug(f"  - PKL ê²½ë¡œ: {meta.pkl_path}")
        logger.debug(f"  - BM25 ê²½ë¡œ: {meta.bm25_path}")
        
        try:
            if not meta.exists():
                logger.warning(f"âš ï¸ ë„ë©”ì¸ {domain}ì— í•„ìš”í•œ ì¸ë±ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                meta.vectorstore = None
                meta.bm25 = None
                return
            
            start_time = time.time()
            
            # ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©
            embeddings_to_use = meta.embeddings or self.embeddings
            if not embeddings_to_use:
                logger.warning(f"âš ï¸ {domain} ì„ë² ë”© ëª¨ë¸ì´ ì—†ì–´ FAISS ë¡œë“œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
                meta.vectorstore = None
            else:
                try:
                    # ğŸ”§ í•µì‹¬ ìˆ˜ì •: ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš© ë° allow_dangerous_deserialization ì¶”ê°€
                    vectorstore_path = meta.vectorstore_path.absolute()
                    
                    logger.info(f"ğŸ“ FAISS ë¡œë“œ ì‹œë„:")
                    logger.info(f"   ê²½ë¡œ: {vectorstore_path}")
                    logger.info(f"   ì¸ë±ìŠ¤ëª…: {domain}_index")
                    
                    # FAISS ì¸ë±ìŠ¤ ë¡œë“œ
                    meta.vectorstore = FAISS.load_local(
                        str(vectorstore_path),  # ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
                        embeddings_to_use,
                        index_name=f"{domain}_index",
                        allow_dangerous_deserialization=True  # ğŸ”§ ì¤‘ìš”!
                    )
                    
                    # ë¡œë“œ ì„±ê³µ í™•ì¸
                    if hasattr(meta.vectorstore, 'index') and hasattr(meta.vectorstore.index, 'ntotal'):
                        doc_count = meta.vectorstore.index.ntotal
                        logger.info(f"âœ… {domain} FAISS ë¡œë“œ ì„±ê³µ: {doc_count}ê°œ ë²¡í„°")
                    else:
                        logger.info(f"âœ… {domain} FAISS ë¡œë“œ ì™„ë£Œ")
                        
                except Exception as faiss_error:
                    logger.error(f"âŒ {domain} FAISS ë¡œë“œ ì‹¤íŒ¨: {faiss_error}")
                    logger.debug(f"ìƒì„¸ ì˜¤ë¥˜:\n{traceback.format_exc()}")
                    meta.vectorstore = None
            
            # ë¬¸ì„œ ë¡œë“œ (FAISS docstoreì—ì„œ)
            meta.documents = []
            if meta.vectorstore:
                try:
                    # docstore._dict ëŒ€ì‹  ì§ì ‘ ê²€ìƒ‰ìœ¼ë¡œ ë¬¸ì„œ í™•ì¸
                    test_results = meta.vectorstore.similarity_search("test", k=1)
                    logger.info(f"ğŸ“„ {domain} FAISS ê²€ìƒ‰ í…ŒìŠ¤íŠ¸: {len(test_results)}ê°œ ê²°ê³¼")
                    
                    # docstoreì—ì„œ ë¬¸ì„œ ì¶”ì¶œ
                    if hasattr(meta.vectorstore, 'docstore') and hasattr(meta.vectorstore.docstore, '_dict'):
                        raw_documents = list(meta.vectorstore.docstore._dict.values())
                        logger.info(f"ğŸ“„ {domain} docstoreì—ì„œ {len(raw_documents)}ê°œ ë¬¸ì„œ ë°œê²¬")
                        
                        for i, doc in enumerate(raw_documents[:100]):  # ìµœëŒ€ 100ê°œë§Œ ì²˜ë¦¬ (ì„±ëŠ¥)
                            try:
                                chunk = TextChunk(
                                    text=doc.page_content,
                                    metadata=doc.metadata if hasattr(doc, 'metadata') else {},
                                    source_id=doc.metadata.get('source_id', f'{domain}_{i}') if hasattr(doc, 'metadata') else f'{domain}_{i}',
                                    chunk_index=i
                                )
                                meta.documents.append(chunk)
                            except Exception as e:
                                if i < 5:  # ì²˜ìŒ 5ê°œë§Œ ì—ëŸ¬ ë¡œê¹…
                                    logger.debug(f"ì²­í¬ {i} ë³€í™˜ ì‹¤íŒ¨: {e}")
                        
                        logger.info(f"âœ… {domain} ë¬¸ì„œ ë¡œë“œ: {len(meta.documents)}ê°œ")
                        
                except Exception as doc_error:
                    logger.warning(f"âš ï¸ {domain} ë¬¸ì„œ ì¶”ì¶œ ì‹¤íŒ¨: {doc_error}")
                    # í´ë°±: ë”ë¯¸ ë¬¸ì„œ ìƒì„±
                    meta.documents = [TextChunk(
                        text=f"{domain} ë„ë©”ì¸ ì •ë³´",
                        metadata={'domain': domain},
                        source_id=f'{domain}_dummy',
                        chunk_index=0
                    )]
            
            # BM25 ë¡œë“œ (ì„ íƒì )
            if meta.bm25_path.exists():
                try:
                    with open(meta.bm25_path, 'rb') as f:
                        bm25_data = pickle.load(f)
                        if isinstance(bm25_data, tuple):
                            meta.bm25, _ = bm25_data
                        else:
                            meta.bm25 = bm25_data
                    logger.info(f"âœ… {domain} BM25 ë¡œë“œ ì™„ë£Œ")
                except Exception as e:
                    logger.warning(f"âš ï¸ {domain} BM25 ë¡œë“œ ì‹¤íŒ¨: {e}")
                    meta.bm25 = None
            
            # ìƒíƒœ ì—…ë°ì´íŠ¸
            meta.last_loaded = datetime.now()
            meta.load_count += 1
            meta.last_hash = meta.get_file_hash()
            
            elapsed = time.time() - start_time
            logger.info(f"âœ… {domain} ì „ì²´ ë¡œë“œ ì™„ë£Œ ({elapsed:.2f}ì´ˆ)")
            
        except Exception as e:
            meta.error_count += 1
            logger.error(f"âŒ {domain} ë¡œë“œ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
            logger.debug(traceback.format_exc())
            
            # í´ë°± ì„¤ì •
            meta.vectorstore = None
            meta.bm25 = None
            meta.documents = [TextChunk(
                text=f"{domain} ë¡œë“œ ì˜¤ë¥˜",
                metadata={'error': str(e)},
                source_id=f'{domain}_error',
                chunk_index=0
            )]




    def load_all_domains(self):
        """ëª¨ë“  ë„ë©”ì¸ ë¡œë“œ"""
        logger.info(f"ğŸ”„ ì „ì²´ ë„ë©”ì¸ ë¡œë“œ ì‹œì‘: {list(self.metadata.keys())}")
        
        start_time = time.time()
        loaded_count = 0
        
        for domain in self.metadata.keys():
            try:
                self._load_domain(domain)
                loaded_count += 1
            except Exception as e:
                logger.error(f"âŒ ë„ë©”ì¸ {domain} ë¡œë“œ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        
        elapsed = time.time() - start_time
        logger.info(f"ğŸ‰ ë„ë©”ì¸ ë¡œë“œ ì™„ë£Œ: {loaded_count}/{len(self.metadata)}ê°œ ì„±ê³µ ({elapsed:.2f}ì´ˆ)")

    def get_vectorstore(self, domain: str) -> Optional[FAISS]:
        """ë„ë©”ì¸ë³„ ë²¡í„°ìŠ¤í† ì–´ íšë“"""
        if domain not in self.metadata:
            logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ë„ë©”ì¸: {domain}")
            return None
        
        return self.metadata[domain].vectorstore

    def get_bm25(self, domain: str) -> Optional[BM25Okapi]:
        """ë„ë©”ì¸ë³„ BM25 ì¸ë±ìŠ¤ íšë“"""
        if domain not in self.metadata:
            logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ë„ë©”ì¸: {domain}")
            return None
        
        return self.metadata[domain].bm25

    def get_documents(self, domain: str) -> List[TextChunk]:
        """ë„ë©”ì¸ë³„ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ íšë“"""
        if domain not in self.metadata:
            logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ë„ë©”ì¸: {domain}")
            return []
        
        return self.metadata[domain].documents

    def health_check(self) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ìƒíƒœ ì²´í¬"""
        status = {
            "total_domains": len(self.metadata),
            "loaded_domains": 0,
            "failed_domains": 0,
            "domains_detail": {},
            "global_embeddings": self.embeddings is not None
        }
        
        for domain, meta in self.metadata.items():
            domain_status = {
                "loaded": meta.vectorstore is not None,
                "bm25_available": meta.bm25 is not None,
                "documents_count": len(meta.documents),
                "load_count": meta.load_count,
                "error_count": meta.error_count,
                "last_loaded": meta.last_loaded.isoformat() if meta.last_loaded else None
            }
            
            if domain_status["loaded"]:
                status["loaded_domains"] += 1
            else:
                status["failed_domains"] += 1
            
            status["domains_detail"][domain] = domain_status
        
        return status

# ================================================================
# 3. ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ íŒ©í„°ë¦¬ ë° í˜¸í™˜ì„± í•¨ìˆ˜
# ================================================================

_index_manager_instance = None

def get_index_manager() -> IndexManager:
    """IndexManager ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ íšë“"""
    global _index_manager_instance
    if _index_manager_instance is None:
        _index_manager_instance = IndexManager()
    return _index_manager_instance

def preload_all_indexes() -> Dict[str, Any]:
    """
    ëª¨ë“  ì¸ë±ìŠ¤ ì‚¬ì „ ë¡œë“œ (app.py í˜¸í™˜ì„± ê°œì„ )
    
    Returns:
        Dict[str, Any]: ë¡œë“œ ê²°ê³¼ ì •ë³´
    """
    logger.info("ğŸš€ ì¸ë±ìŠ¤ ì‚¬ì „ ë¡œë“œ ì‹œì‘")
    start_time = time.time()
    
    try:
        manager = get_index_manager()
        
        # ì¬ë¡œë“œ ì‹¤í–‰
        manager.load_all_domains()
        
        # ìƒíƒœ ì²´í¬
        status = manager.health_check()
        elapsed_time = time.time() - start_time
        
        logger.info(f"ğŸ“Š ì¸ë±ìŠ¤ ë¡œë“œ ìƒíƒœ: {status['loaded_domains']}/{status['total_domains']}ê°œ ì„±ê³µ")
        
        # app.pyì—ì„œ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
        return {
            "success": status["loaded_domains"] > 0,
            "loaded_indexes": list(status["domains_detail"].keys()),
            "performance": {
                "load_time": elapsed_time,
                "loaded_domains": status["loaded_domains"],
                "total_domains": status["total_domains"]
            },
            "error": None if status["loaded_domains"] > 0 else "No domains loaded"
        }
        
    except Exception as e:
        logger.error(f"âŒ ì¸ë±ìŠ¤ ì‚¬ì „ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {
            "success": False,
            "loaded_indexes": [],
            "performance": {},
            "error": str(e)
        }

def index_health_check() -> Dict[str, Any]:
    """
    IndexManager í—¬ìŠ¤ì²´í¬ (app.py í˜¸í™˜ì„± í•¨ìˆ˜)
    
    Returns:
        Dict[str, Any]: ì‹œìŠ¤í…œ ìƒíƒœ ì •ë³´
    """
    try:
        manager = get_index_manager()
        return manager.health_check()
    except Exception as e:
        logger.error(f"âŒ í—¬ìŠ¤ì²´í¬ ì‹¤íŒ¨: {e}")
        return {
            "total_domains": 0,
            "loaded_domains": 0,
            "failed_domains": 0,
            "domains_detail": {},
            "global_embeddings": False,
            "error": str(e)
        }

# ================================================================
# 4. í…ŒìŠ¤íŠ¸ ë° ê²€ì¦ 
# ================================================================

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    print("ğŸ§ª IndexManager í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    try:
        # ì‹±ê¸€í†¤ í…ŒìŠ¤íŠ¸
        manager1 = get_index_manager()
        manager2 = get_index_manager()
        assert manager1 is manager2, "ì‹±ê¸€í†¤ íŒ¨í„´ ì‹¤íŒ¨"
        print("âœ… ì‹±ê¸€í†¤ íŒ¨í„´ í…ŒìŠ¤íŠ¸ í†µê³¼")
        
        # ìƒíƒœ ì²´í¬
        status = manager1.health_check()
        print(f"ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ: {status}")
        
        print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        traceback.print_exc()
