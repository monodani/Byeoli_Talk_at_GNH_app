def _load_domain(self, domain: str):
    """
    ë‹¨ì¼ ë„ë©”ì¸ì˜ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ë¡œë“œ (pickle ìš°íšŒ ì „ëµ)
    """
    meta = self.metadata[domain]
    
    logger.info(f"ğŸ”„ ë„ë©”ì¸ {domain} ë¡œë“œ ì‹œì‘...")
    logger.debug(f"  - FAISS ê²½ë¡œ: {meta.faiss_path}")
    logger.debug(f"  - PKL ê²½ë¡œ: {meta.pkl_path}")
    logger.debug(f"  - BM25 ê²½ë¡œ: {meta.bm25_path}")
    
    try:
        if not meta.exists():
            logger.warning(f"âš ï¸ ë„ë©”ì¸ {domain}ì— í•„ìš”í•œ ì¸ë±ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¡œë“œ ê±´ë„ˆëœë‹ˆë‹¤.")
            meta.vectorstore = None
            meta.bm25 = None
            return
        
        start_time = time.time()
        
        # ì„ë² ë”© ëª¨ë¸ ì‚¬ìš© (ê¸€ë¡œë²Œ ë˜ëŠ” ë„ë©”ì¸ë³„)
        embeddings_to_use = meta.embeddings or self.embeddings
        if not embeddings_to_use:
            logger.warning(f"âš ï¸ {domain} ì„ë² ë”© ëª¨ë¸ì´ ì—†ì–´ FAISS ë¡œë“œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            meta.vectorstore = None
        else:
            # FAISS ì¸ë±ìŠ¤ ë¡œë“œ
            meta.vectorstore = FAISS.load_local(
                str(meta.vectorstore_path),
                embeddings_to_use,
                index_name=f"{domain}_index",
                allow_dangerous_deserialization=True
            )
            logger.info(f"âœ… ë„ë©”ì¸ {domain} FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ")
        
        # âœ… í•µì‹¬ ë³€ê²½: pickle íŒŒì¼ì„ ì™„ì „íˆ ë¬´ì‹œí•˜ê³  FAISSì—ì„œë§Œ ë¡œë“œ
        meta.documents = []
        documents_loaded = False
        
        # ìœ ì¼í•œ ì „ëµ: FAISS docstoreì—ì„œë§Œ ë¡œë“œ (pickle ì™„ì „ ìš°íšŒ)
        if meta.vectorstore:
            logger.info(f"ğŸ”„ {domain} FAISS docstoreì—ì„œ ë¬¸ì„œ ì§ì ‘ ë¡œë“œ (pickle ìš°íšŒ)")
            try:
                # FAISS ë‚´ë¶€ docstore ì§ì ‘ ì ‘ê·¼
                raw_documents = list(meta.vectorstore.docstore._dict.values())
                logger.info(f"ğŸ“„ {domain} FAISS docstoreì—ì„œ {len(raw_documents)}ê°œ ë¬¸ì„œ ë°œê²¬")
                
                for i, doc in enumerate(raw_documents):
                    try:
                        # LangChain Document â†’ TextChunk ì§ì ‘ ë³€í™˜ (pickle ì—†ì´)
                        chunk = TextChunk(
                            text=doc.page_content,
                            metadata=doc.metadata if hasattr(doc, 'metadata') else {},
                            source_id=doc.metadata.get('source_id', f'{domain}_{i}') if hasattr(doc, 'metadata') else f'{domain}_{i}',
                            chunk_index=i
                        )
                        meta.documents.append(chunk)
                        
                        # ì§„í–‰ ìƒí™© ë¡œê¹… (í° ë°ì´í„°ì…‹ì˜ ê²½ìš°)
                        if i > 0 and i % 50 == 0:
                            logger.debug(f"ğŸ“ {domain} ë¬¸ì„œ ë³€í™˜ ì§„í–‰: {i}/{len(raw_documents)}")
                            
                    except Exception as chunk_error:
                        logger.warning(f"âš ï¸ {domain} ì²­í¬ {i} ë³€í™˜ ì‹¤íŒ¨: {chunk_error}")
                        # ë³€í™˜ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì²­í¬ë¼ë„ ìƒì„±
                        try:
                            fallback_chunk = TextChunk(
                                text=str(doc.page_content) if hasattr(doc, 'page_content') else f"ë¬¸ì„œ {i} ë‚´ìš©",
                                metadata={'fallback': True, 'domain': domain},
                                source_id=f'{domain}_fallback_{i}',
                                chunk_index=i
                            )
                            meta.documents.append(fallback_chunk)
                        except:
                            logger.warning(f"âš ï¸ {domain} ì²­í¬ {i} í´ë°±ë„ ì‹¤íŒ¨, ê±´ë„ˆëœ€")
                            continue
                
                if meta.documents:
                    documents_loaded = True
                    logger.info(f"âœ… {domain} FAISSì—ì„œ {len(meta.documents)}ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ")
                else:
                    logger.warning(f"âš ï¸ {domain} FAISSì—ì„œ ë³€í™˜ëœ ë¬¸ì„œê°€ ì—†ìŒ")
                    
            except Exception as faiss_error:
                logger.error(f"âŒ {domain} FAISS docstore ì ‘ê·¼ ì‹¤íŒ¨: {faiss_error}")
                logger.debug(f"FAISS ì˜¤ë¥˜ ìƒì„¸:\n{traceback.format_exc()}")
        else:
            logger.warning(f"âš ï¸ {domain} ë²¡í„°ìŠ¤í† ì–´ê°€ ë¡œë“œë˜ì§€ ì•Šì•„ ë¬¸ì„œ ë¡œë“œ ë¶ˆê°€")
        
        # ë¬¸ì„œê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìœ¼ë©´ ê¸°ë³¸ ë”ë¯¸ ìƒì„±
        if not documents_loaded:
            logger.warning(f"âš ï¸ {domain} ëª¨ë“  ë¬¸ì„œ ë¡œë“œ ì‹¤íŒ¨, ë„ë©”ì¸ë³„ ë”ë¯¸ ë¬¸ì„œ ìƒì„±")
            
            # ë„ë©”ì¸ë³„ ì˜ë¯¸ìˆëŠ” ë”ë¯¸ ë°ì´í„° ìƒì„±
            domain_dummy_data = {
                "satisfaction": "ë§Œì¡±ë„ ì¡°ì‚¬ ê²°ê³¼ì— ëŒ€í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.",
                "general": "ê²½ìƒë‚¨ë„ì¸ì¬ê°œë°œì›ì˜ ì¼ë°˜ ì •ë³´ì™€ í•™ì¹™ì„ ì œê³µí•©ë‹ˆë‹¤.",
                "publish": "êµìœ¡ê³„íšì„œì™€ í‰ê°€ì„œ ë“± ê³µì‹ ë°œí–‰ë¬¼ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.",
                "cyber": "ì‚¬ì´ë²„ êµìœ¡ ì¼ì •ê³¼ ê³¼ì • ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.",
                "menu": "êµ¬ë‚´ì‹ë‹¹ ë©”ë‰´ì™€ ì‹ë‹¨ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.",
                "notice": "ê³µì§€ì‚¬í•­ê³¼ ì•ˆë‚´ì‚¬í•­ì„ ì œê³µí•©ë‹ˆë‹¤."
            }
            
            dummy_text = domain_dummy_data.get(domain, f"{domain} ë„ë©”ì¸ì˜ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.")
            dummy_chunk = TextChunk(
                text=dummy_text,
                metadata={'domain': domain, 'type': 'dummy', 'created_at': datetime.now().isoformat()},
                source_id=f'{domain}_dummy',
                chunk_index=0
            )
            meta.documents = [dummy_chunk]
            logger.info(f"ğŸ”„ {domain} ë”ë¯¸ ë¬¸ì„œ ìƒì„± ì™„ë£Œ: '{dummy_text[:50]}...'")
        
        # BM25 ì¸ë±ìŠ¤ ë¡œë“œ ì‹œë„ (ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰)
        bm25_loaded = False
        if meta.bm25_path.exists():
            try:
                logger.info(f"ğŸ”„ {domain} BM25 ì¸ë±ìŠ¤ ë¡œë“œ ì‹œë„")
                with open(meta.bm25_path, 'rb') as f:
                    bm25_data = pickle.load(f)
                    if isinstance(bm25_data, tuple):
                        meta.bm25, _ = bm25_data
                    else:
                        meta.bm25 = bm25_data
                bm25_loaded = True
                logger.info(f"âœ… ë„ë©”ì¸ {domain} BM25 ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ")
            except Exception as bm25_error:
                logger.warning(f"âš ï¸ ë„ë©”ì¸ {domain} BM25 ë¡œë“œ ì‹¤íŒ¨: {bm25_error}")
                meta.bm25 = None
        else:
            logger.debug(f"âš ï¸ ë„ë©”ì¸ {domain} BM25 ì¸ë±ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            meta.bm25 = None
        
        # ë¡œë“œ ìƒíƒœ ì—…ë°ì´íŠ¸
        meta.last_loaded = datetime.now()
        meta.load_count += 1
        meta.last_hash = meta.get_file_hash()
        elapsed = time.time() - start_time
        
        # ë¡œë“œ ìƒíƒœ ìš”ì•½
        status_parts = []
        if meta.vectorstore:
            status_parts.append("FAISS")
        if bm25_loaded:
            status_parts.append("BM25")
        if meta.documents:
            status_parts.append(f"ë¬¸ì„œ {len(meta.documents)}ê°œ")
        
        logger.info(f"âœ… ë„ë©”ì¸ {domain} ë¡œë“œ ì„±ê³µ! ({', '.join(status_parts)}, {elapsed:.2f}ì´ˆ)")
        
    except Exception as e:
        meta.error_count += 1
        logger.error(f"âŒ ë„ë©”ì¸ {domain} ë¡œë“œ ì‹¤íŒ¨: {e}")
        logger.debug(f"ìƒì„¸ ì˜¤ë¥˜:\n{traceback.format_exc()}")
        
        # ìµœì¢… ì•ˆì „ì¥ì¹˜: ì—ëŸ¬ ì‹œì—ë„ ìµœì†Œ ê¸°ëŠ¥ ì œê³µ
        try:
            meta.vectorstore = None
            meta.bm25 = None
            
            if not meta.documents:
                error_chunk = TextChunk(
                    text=f"{domain} ë„ë©”ì¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ë¡œë“œí•˜ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.",
                    metadata={
                        'domain': domain, 
                        'type': 'error_fallback',
                        'error': str(e),
                        'created_at': datetime.now().isoformat()
                    },
                    source_id=f'{domain}_error',
                    chunk_index=0
                )
                meta.documents = [error_chunk]
                logger.info(f"ğŸ†˜ {domain} ì—ëŸ¬ í´ë°± ë¬¸ì„œ ìƒì„± ì™„ë£Œ")
                
        except Exception as final_error:
            logger.error(f"ğŸ’¥ {domain} ìµœì¢… í´ë°±ë„ ì‹¤íŒ¨: {final_error}")
            # ì´ ê²½ìš° meta.documentsëŠ” ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ë‚¨ìŒ
