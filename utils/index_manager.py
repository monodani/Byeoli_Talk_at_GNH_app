#!/usr/bin/env python3
"""
ê²½ìƒë‚¨ë„ì¸ì¬ê°œë°œì› RAG ì±—ë´‡ - index_manager.py (ì™„ì „ ìˆ˜ì • ë²„ì „)

IndexManager ì‹±ê¸€í†¤: ëª¨ë“  ë²¡í„°ìŠ¤í† ì–´ ì¤‘ì•™ ê´€ë¦¬
- ì•± ê¸°ë™ ì‹œ ëª¨ë“  FAISS ì¸ë±ìŠ¤ ì‚¬ì „ ë¡œë“œ
- ì €ì¥ëœ BM25 íŒŒì¼ ë¡œë“œ
- í•´ì‹œ ê¸°ë°˜ íŒŒì¼ ë³€ê²½ ê°ì§€ë¡œ í•«ìŠ¤ì™‘
- ì „ì—­ ê³µìœ ë¡œ í•¸ë“¤ëŸ¬ ê°„ ì¼ê´€ì„± ë³´ì¥
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë‹¨ì¼ ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬

í•µì‹¬ ìˆ˜ì •ì‚¬í•­:
âœ… TextChunk import ëˆ„ë½ ì˜¤ë¥˜ ìˆ˜ì •
âœ… ê²½ë¡œ ì˜¤ë¥˜ ìˆ˜ì •: data_ingestion.pyì™€ ë™ì¼í•œ ê²½ë¡œ ë§¤í•‘ ì‚¬ìš©
âœ… preload_all_indexes í•¨ìˆ˜ ì¶”ê°€ (test_integration.py í˜¸í™˜)
âœ… health_check() ë©”ì„œë“œ ì¶”ê°€
âœ… íŒŒì¼ëª… íŒ¨í„´ í†µì¼ (domain_index.faiss)
"""

import hashlib
import logging
import threading
import time
import pickle
import traceback
from pathlib import Path
from typing import Dict, Optional, Any, List, Tuple
from datetime import datetime
from dataclasses import dataclass, field

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ
from utils.config import config
from utils.contracts import HandlerType
from utils.textifier import TextChunk

# ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import OpenAIEmbeddings
from rank_bm25 import BM25Okapi
import numpy as np

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)


# ================================================================
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
# ================================================================
try:
    ROOT_DIR = Path(__file__).parent.parent.absolute()
except NameError:
    ROOT_DIR = Path(".").absolute()

# ================================================================
# 1. ë²¡í„°ìŠ¤í† ì–´ ë©”íƒ€ë°ì´í„° í´ë˜ìŠ¤
# ================================================================

@dataclass
class VectorStoreMetadata:
    """
    ë²¡í„°ìŠ¤í† ì–´ ë©”íƒ€ë°ì´í„° ë° ìƒíƒœ ê´€ë¦¬ (BM25 íŒŒì¼ ì§€ì›)
    """
    domain: str
    vectorstore_base_dir: Path
    
    # post_initì—ì„œ ì„¤ì •ë˜ë¯€ë¡œ init=Falseë¡œ ì„¤ì •
    vectorstore_path: Path = field(init=False)
    faiss_path: Path = field(init=False)
    pkl_path: Path = field(init=False)
    bm25_path: Path = field(init=False)
    
    # ëŸ°íƒ€ì„ ì†ì„±
    embeddings: Optional[OpenAIEmbeddings] = None
    vectorstore: Optional[FAISS] = None
    bm25: Optional[BM25Okapi] = None
    documents: List[TextChunk] = field(default_factory=list)
    last_loaded: Optional[datetime] = None
    load_count: int = 0
    error_count: int = 0
    last_hash: Optional[str] = None
    
    def __post_init__(self):
        # data_ingestion.pyì™€ ë™ì¼í•œ ê²½ë¡œ ë§¤í•‘ ì‚¬ìš©
        self.vectorstore_path = self._get_vectorstore_path()
        self.faiss_path = self.vectorstore_path / f"{self.domain}_index.faiss"
        self.pkl_path = self.vectorstore_path / f"{self.domain}_index.pkl"
        self.bm25_path = self.vectorstore_path / f"{self.domain}_index.bm25"
        self.embeddings = OpenAIEmbeddings()
    
    def _get_vectorstore_path(self) -> Path:
        """data_ingestion.pyì™€ ì™„ì „íˆ ë™ì¼í•œ ê²½ë¡œ ë°˜í™˜"""
        vectorstore_base = ROOT_DIR / "vectorstores"
        
        path_mapping = {
            "satisfaction": vectorstore_base / "vectorstore_unified_satisfaction",
            "general": vectorstore_base / "vectorstore_general",
            "menu": vectorstore_base / "vectorstore_menu", 
            "cyber": vectorstore_base / "vectorstore_cyber",
            "publish": vectorstore_base / "vectorstore_unified_publish",
            "notice": vectorstore_base / "vectorstore_notice"
        }
        
        return path_mapping.get(self.domain, vectorstore_base / f"vectorstore_{self.domain}")

    def exists(self) -> bool:
        """
        í•„ìš”í•œ ì¸ë±ìŠ¤ íŒŒì¼ë“¤ì´ ëª¨ë‘ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        """
        exists = self.faiss_path.exists() and self.pkl_path.exists() and self.bm25_path.exists()
        if not exists:
            logger.debug(f"íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ - FAISS: {self.faiss_path.exists()}, PKL: {self.pkl_path.exists()}, BM25: {self.bm25_path.exists()}")
        return exists

    @property
    def needs_reload(self) -> bool:
        """
        íŒŒì¼ ë³€ê²½ ì—¬ë¶€ë¥¼ ê°ì§€í•˜ì—¬ ë¦¬ë¡œë“œ í•„ìš”ì„±ì„ íŒë‹¨
        """
        if not self.exists():
            return False
            
        current_hash = self.get_file_hash()
        return current_hash != self.last_hash
        
    def get_file_hash(self) -> str:
        """
        ëª¨ë“  ì¸ë±ìŠ¤ íŒŒì¼ì˜ í•´ì‹œë¥¼ í•©ì³ì„œ ë°˜í™˜
        """
        hasher = hashlib.sha256()
        try:
            for path in [self.faiss_path, self.pkl_path, self.bm25_path]:
                if path.exists():
                    hasher.update(path.read_bytes())
            return hasher.hexdigest()
        except Exception as e:
            logger.error(f"âŒ ë„ë©”ì¸ {self.domain} íŒŒì¼ í•´ì‹œ ê³„ì‚° ì‹¤íŒ¨: {e}")
            self.error_count += 1
            return ""

# ================================================================
# 2. IndexManager ì‹±ê¸€í†¤ í´ë˜ìŠ¤
# ================================================================

class IndexManager:
    """
    ëª¨ë“  ë²¡í„°ìŠ¤í† ì–´ë¥¼ ê´€ë¦¬í•˜ëŠ” ì‹±ê¸€í†¤ í´ë˜ìŠ¤
    """
    _instance = None
    _instance_lock = threading.Lock()
    
    def __new__(cls):
        if cls._instance is None:
            with cls._instance_lock:
                if cls._instance is None:
                    cls._instance = super(IndexManager, cls).__new__(cls)
        return cls._instance

    def __init__(self):
        if hasattr(self, '_initialized'):
            return
            
        self.metadata: Dict[str, VectorStoreMetadata] = {}
        self.embeddings = OpenAIEmbeddings()
        
        for domain in config.HANDLERS:
            self.metadata[domain] = VectorStoreMetadata(
                domain=domain,
                vectorstore_base_dir=Path(config.VECTORSTORE_DIR)
            )
        
        logger.info(f"ğŸš€ IndexManager ì‹±ê¸€í†¤ ì´ˆê¸°í™” ì™„ë£Œ: {len(self.metadata)}ê°œ ë„ë©”ì¸")
        self.load_all_domains()
        self._initialized = True

    def _load_domain(self, domain: str):
        """
        ë‹¨ì¼ ë„ë©”ì¸ì˜ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ë¡œë“œ
        """
        meta = self.metadata[domain]
        
        logger.info(f"ğŸ”„ ë„ë©”ì¸ {domain} ë¡œë“œ ì‹œì‘...")
        logger.debug(f"  - FAISS ê²½ë¡œ: {meta.faiss_path}")
        logger.debug(f"  - PKL ê²½ë¡œ: {meta.pkl_path}")
        logger.debug(f"  - BM25 ê²½ë¡œ: {meta.bm25_path}")
        
        try:
            if not meta.exists():
                logger.warning(f"âš ï¸ ë„ë©”ì¸ {domain}ì— í•„ìš”í•œ ì¸ë±ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¡œë“œ ê±´ë„ˆëœë‹ˆë‹¤.")
                meta.vectorstore = None
                meta.bm25 = None
                return
            
            start_time = time.time()
            
            # FAISS ì¸ë±ìŠ¤ ë¡œë“œ - index_name íŒŒë¼ë¯¸í„° ì¶”ê°€
            meta.vectorstore = FAISS.load_local(
                str(meta.vectorstore_path),
                meta.embeddings,
                index_name=f"{domain}_index",  # íŒŒì¼ëª… íŒ¨í„´ ëª…ì‹œ
                allow_dangerous_deserialization=True
            )
            
            # ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ë¡œë“œ
            with open(meta.pkl_path, "rb") as f:
                meta.documents = pickle.load(f)
            
            # BM25 ì¸ë±ìŠ¤ ë¡œë“œ
            if meta.bm25_path.exists():
                with open(meta.bm25_path, 'rb') as f:
                    bm25_data = pickle.load(f)
                    if isinstance(bm25_data, tuple):
                        meta.bm25, _ = bm25_data  # (bm25_index, metadata) íŠœí”Œì¸ ê²½ìš°
                    else:
                        meta.bm25 = bm25_data
                logger.info(f"âœ… ë„ë©”ì¸ {domain} BM25 ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ.")
            else:
                logger.warning(f"âš ï¸ ë„ë©”ì¸ {domain} BM25 ì¸ë±ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                meta.bm25 = None
            
            meta.last_loaded = datetime.now()
            meta.load_count += 1
            meta.last_hash = meta.get_file_hash()
            elapsed = time.time() - start_time
            logger.info(f"âœ… ë„ë©”ì¸ {domain} ë¡œë“œ ì„±ê³µ! ({len(meta.documents):,}ê°œ ë¬¸ì„œ, {elapsed:.2f}ì´ˆ)")

        except Exception as e:
            meta.error_count += 1
            logger.error(f"âŒ ë„ë©”ì¸ {domain} ë¡œë“œ ì‹¤íŒ¨: {e}")
            logger.debug(traceback.format_exc())
            meta.vectorstore = None
            meta.bm25 = None
            
    def load_all_domains(self):
        """ë³‘ë ¬ë¡œ ëª¨ë“  ë„ë©”ì¸ì„ ë¡œë“œ"""
        threads = []
        for domain in self.metadata:
            thread = threading.Thread(target=self._load_domain, args=(domain,))
            threads.append(thread)
            thread.start()
        
        for thread in threads:
            thread.join()
            
    def check_for_updates_and_reload(self):
        """
        íŒŒì¼ ë³€ê²½ì„ ê°ì§€í•˜ê³ , ë³€ê²½ëœ ë„ë©”ì¸ë§Œ í•«ìŠ¤ì™‘ ì‹¤í–‰
        """
        for domain, meta in self.metadata.items():
            if meta.needs_reload:
                logger.info(f"ğŸ”„ ë„ë©”ì¸ {domain} íŒŒì¼ ë³€ê²½ ê°ì§€, í•«ìŠ¤ì™‘ ì‹¤í–‰...")
                self._load_domain(domain)
    
    def get_vectorstore(self, domain: str) -> Optional[FAISS]:
        """ë„ë©”ì¸ì— í•´ë‹¹í•˜ëŠ” FAISS ë²¡í„°ìŠ¤í† ì–´ ë°˜í™˜ (base_handler í˜¸í™˜)"""
        meta = self.metadata.get(domain)
        return meta.vectorstore if meta else None
    
    def get_index(self, domain: str) -> Optional[FAISS]:
        """ë„ë©”ì¸ì— í•´ë‹¹í•˜ëŠ” FAISS ì¸ë±ìŠ¤ ë°˜í™˜ (ê¸°ì¡´ í˜¸í™˜ì„±)"""
        return self.get_vectorstore(domain)
    
    def get_documents(self, domain: str) -> List[TextChunk]:
        """ë„ë©”ì¸ì— í•´ë‹¹í•˜ëŠ” ì›ë³¸ ë¬¸ì„œ ì²­í¬ ë°˜í™˜"""
        meta = self.metadata.get(domain)
        return meta.documents if meta else []
        
    def get_bm25(self, domain: str) -> Optional[BM25Okapi]:
        """ë„ë©”ì¸ì— í•´ë‹¹í•˜ëŠ” BM25 ì¸ë±ìŠ¤ ë°˜í™˜"""
        meta = self.metadata.get(domain)
        return meta.bm25 if meta else None
        
    def get_status(self) -> Dict[str, Dict]:
        """
        ì „ì²´ ì¸ë±ìŠ¤ ìƒíƒœ ì •ë³´ ë°˜í™˜
        """
        status = {}
        
        for domain, meta in self.metadata.items():
            status[domain] = {
                'loaded': meta.vectorstore is not None,
                'documents_count': len(meta.documents),
                'has_bm25': meta.bm25 is not None,
                'last_loaded': meta.last_loaded.isoformat() if meta.last_loaded else None,
                'load_count': meta.load_count,
                'error_count': meta.error_count,
                'files_exist': meta.exists()
            }
        
        return status

    def health_check(self) -> Dict[str, Any]:
        """
        test_integration.py í˜¸í™˜ì„±ì„ ìœ„í•œ health_check ë©”ì„œë“œ
        ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœë¥¼ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€
        """
        status = self.get_status()
        
        # ìƒíƒœ í†µê³„ ê³„ì‚°
        total_domains = len(status)
        loaded_domains = sum(1 for s in status.values() if s['loaded'])
        total_documents = sum(s['documents_count'] for s in status.values())
        domains_with_bm25 = sum(1 for s in status.values() if s['has_bm25'])
        
        # ì „ì²´ ê±´ê°•ë„ í‰ê°€
        health_score = 0
        if total_domains > 0:
            health_score += (loaded_domains / total_domains) * 50  # 50ì : ë¡œë“œ ìƒíƒœ
            health_score += (domains_with_bm25 / total_domains) * 30  # 30ì : BM25 ì¸ë±ìŠ¤
            health_score += min(total_documents / 1000, 1) * 20  # 20ì : ë¬¸ì„œ ìˆ˜ (1000ê°œ ì´ìƒì´ë©´ ë§Œì )
        
        overall_health = "healthy" if health_score >= 70 else "degraded" if health_score >= 40 else "critical"
        
        return {
            "overall_health": overall_health,
            "health_score": round(health_score, 1),
            "loaded_domains": f"{loaded_domains}/{total_domains}",
            "total_documents": total_documents,
            "domains_with_bm25": f"{domains_with_bm25}/{total_domains}",
            "domain_status": status
        }

# ================================================================
# 3. ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬
# ================================================================

_index_manager_instance: Optional[IndexManager] = None
_instance_lock = threading.Lock()


def get_index_manager() -> IndexManager:
    """
    IndexManager ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜
    """
    global _index_manager_instance
    
    if _index_manager_instance is None:
        with _instance_lock:
            if _index_manager_instance is None:
                _index_manager_instance = IndexManager()
    
    return _index_manager_instance


# ================================================================
# 4. test_integration.py í˜¸í™˜ì„±ì„ ìœ„í•œ ì¶”ê°€ í•¨ìˆ˜ë“¤
# ================================================================

def preload_all_indexes() -> Dict[str, bool]:
    """
    ëª¨ë“  ì¸ë±ìŠ¤ë¥¼ ì‚¬ì „ ë¡œë“œí•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜
    test_integration.pyì—ì„œ ìš”êµ¬í•˜ëŠ” í•¨ìˆ˜
    
    Returns:
        Dict[str, bool]: ë„ë©”ì¸ë³„ ë¡œë“œ ì„±ê³µ ì—¬ë¶€
    """
    logger.info("ğŸš€ ëª¨ë“  ì¸ë±ìŠ¤ ì‚¬ì „ ë¡œë“œ ì‹œì‘...")
    
    try:
        index_manager = get_index_manager()
        
        results = {}
        status = index_manager.get_status()
        
        for domain, domain_status in status.items():
            is_loaded = domain_status['loaded'] and domain_status['documents_count'] > 0
            results[domain] = is_loaded
            
            if is_loaded:
                logger.info(f"âœ… {domain}: {domain_status['documents_count']}ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ")
            else:
                logger.warning(f"âš ï¸ {domain}: ë¡œë“œ ì‹¤íŒ¨ ë˜ëŠ” ë¬¸ì„œ ì—†ìŒ")
        
        success_count = sum(1 for success in results.values() if success)
        total_count = len(results)
        
        logger.info(f"ğŸ“Š ì¸ë±ìŠ¤ ì‚¬ì „ ë¡œë“œ ì™„ë£Œ: {success_count}/{total_count}ê°œ ë„ë©”ì¸ ì„±ê³µ")
        
        return results
        
    except Exception as e:
        logger.error(f"âŒ ì¸ë±ìŠ¤ ì‚¬ì „ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {domain: False for domain in config.HANDLERS}


def index_health_check() -> Dict[str, Any]:
    """
    ì¸ë±ìŠ¤ ìƒíƒœ ê±´ê°• ê²€ì§„ (ë…ë¦½ í•¨ìˆ˜ ë²„ì „)
    
    Returns:
        Dict[str, Any]: ìƒíƒœ ì •ë³´ ë° ê±´ê°•ë„ ì§€í‘œ
    """
    try:
        index_manager = get_index_manager()
        return index_manager.health_check()
        
    except Exception as e:
        logger.error(f"âŒ ê±´ê°• ê²€ì§„ ì‹¤íŒ¨: {e}")
        return {
            "overall_health": "error",
            "health_score": 0,
            "error": str(e)
        }


# ================================================================
# 5. ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ ë¡œê·¸
# ================================================================

logger.info("âœ… index_manager.py ëª¨ë“ˆ ë¡œë“œ ì™„ë£Œ (ì™„ì „ ìˆ˜ì • ë²„ì „)")