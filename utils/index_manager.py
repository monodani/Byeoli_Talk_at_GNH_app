#!/usr/bin/env python3
"""
ê²½ìƒë‚¨ë„ì¸ì¬ê°œë°œì› RAG ì±—ë´‡ - index_manager.py

IndexManager ì‹±ê¸€í†¤: ëª¨ë“  ë²¡í„°ìŠ¤í† ì–´ ì¤‘ì•™ ê´€ë¦¬
- ì•± ê¸°ë™ ì‹œ ëª¨ë“  FAISS ì¸ë±ìŠ¤ ì‚¬ì „ ë¡œë“œ
- í•´ì‹œ ê¸°ë°˜ íŒŒì¼ ë³€ê²½ ê°ì§€ë¡œ í•«ìŠ¤ì™‘
- ì „ì—­ ê³µìœ ë¡œ í•¸ë“¤ëŸ¬ ê°„ ì¼ê´€ì„± ë³´ì¥
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ë‹¨ì¼ ì¸ìŠ¤í„´ìŠ¤ ê´€ë¦¬

í•µì‹¬ íŠ¹ì§•:
- ì‹±ê¸€í†¤ íŒ¨í„´ìœ¼ë¡œ ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ë³´ì¥
- ì§€ì—° ë¡œë”© ë° ìºì‹œ ê¸°ë°˜ ì„±ëŠ¥ ìµœì í™”
- íŒŒì¼ í•´ì‹œ ê°ì‹œë¡œ ìë™ í•«ìŠ¤ì™‘
- ì—ëŸ¬ ë³µêµ¬ ë° ì•ˆì „ë§ ì œê³µ
"""

import hashlib
import logging
import threading
import time
from pathlib import Path
from typing import Dict, Optional, Any, List, Tuple
from datetime import datetime

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ
from utils.config import config
from utils.contracts import HandlerType

# ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import OpenAIEmbeddings
from rank_bm25 import BM25Okapi
import numpy as np

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)


# ================================================================
# 1. ë²¡í„°ìŠ¤í† ì–´ ë©”íƒ€ë°ì´í„° í´ë˜ìŠ¤
# ================================================================

class VectorStoreMetadata:
    """ë²¡í„°ìŠ¤í† ì–´ ë©”íƒ€ë°ì´í„° ë° ìƒíƒœ ê´€ë¦¬"""
    
    def __init__(self, domain: str, vectorstore_dir: Path):
        self.domain = domain
        self.vectorstore_dir = vectorstore_dir
        self.faiss_file = vectorstore_dir / f"{domain}_index.faiss"
        self.pkl_file = vectorstore_dir / f"{domain}_index.pkl"
        
        # ìƒíƒœ ì •ë³´
        self.vectorstore: Optional[FAISS] = None
        self.bm25: Optional[BM25Okapi] = None
        self.documents: List[str] = []
        self.last_loaded: Optional[datetime] = None
        self.file_hash: Optional[str] = None
        self.load_count: int = 0
        self.error_count: int = 0
        
    def exists(self) -> bool:
        """ë²¡í„°ìŠ¤í† ì–´ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€"""
        return self.faiss_file.exists() and self.pkl_file.exists()
    
    def calculate_hash(self) -> str:
        """ë²¡í„°ìŠ¤í† ì–´ íŒŒì¼ë“¤ì˜ í•´ì‹œ ê³„ì‚°"""
        if not self.exists():
            return ""
        
        try:
            hash_md5 = hashlib.md5()
            
            # FAISS íŒŒì¼ í•´ì‹œ
            with open(self.faiss_file, 'rb') as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_md5.update(chunk)
            
            # PKL íŒŒì¼ í•´ì‹œ
            with open(self.pkl_file, 'rb') as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_md5.update(chunk)
            
            return hash_md5.hexdigest()
            
        except Exception as e:
            logger.error(f"âŒ {self.domain} í•´ì‹œ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return ""
    
    def needs_reload(self) -> bool:
        """ì¬ë¡œë“œ í•„ìš” ì—¬ë¶€ í™•ì¸"""
        if not self.vectorstore:
            return True
        
        current_hash = self.calculate_hash()
        return current_hash != self.file_hash
    
    def mark_loaded(self, success: bool = True):
        """ë¡œë“œ ì™„ë£Œ ë§ˆí‚¹"""
        self.last_loaded = datetime.now()
        self.load_count += 1
        if not success:
            self.error_count += 1
        self.file_hash = self.calculate_hash()


# ================================================================
# 2. IndexManager ì‹±ê¸€í†¤ í´ë˜ìŠ¤
# ================================================================

class IndexManager:
    """
    ë²¡í„°ìŠ¤í† ì–´ ì¸ë±ìŠ¤ ì¤‘ì•™ ê´€ë¦¬ì (ì‹±ê¸€í†¤)
    
    ì£¼ìš” ê¸°ëŠ¥:
    - ëª¨ë“  ë„ë©”ì¸ì˜ ë²¡í„°ìŠ¤í† ì–´ ì‚¬ì „ ë¡œë“œ
    - íŒŒì¼ ë³€ê²½ ê°ì§€ ë° ìë™ í•«ìŠ¤ì™‘
    - ìŠ¤ë ˆë“œ ì•ˆì „í•œ ì•¡ì„¸ìŠ¤ ì œê³µ
    - ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ì—ëŸ¬ ì²˜ë¦¬
    """
    
    _instance = None
    _lock = threading.Lock()
    
    def __new__(cls):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
                    cls._instance._initialized = False
        return cls._instance
    
    def __init__(self):
        if hasattr(self, '_initialized') and self._initialized:
            return
            
        # ì´ˆê¸°í™”
        self.embeddings = OpenAIEmbeddings()
        self.domains = self._get_domain_configs()
        self.metadata: Dict[str, VectorStoreMetadata] = {}
        self._access_lock = threading.RLock()
        
        # ë„ë©”ì¸ë³„ ë©”íƒ€ë°ì´í„° ì´ˆê¸°í™”
        for domain, config_info in self.domains.items():
            self.metadata[domain] = VectorStoreMetadata(
                domain=domain,
                vectorstore_dir=config_info["path"]
            )
        
        self._initialized = True
        logger.info(f"ğŸš€ IndexManager ì‹±ê¸€í†¤ ì´ˆê¸°í™” ì™„ë£Œ: {len(self.domains)}ê°œ ë„ë©”ì¸")
    
    def _get_domain_configs(self) -> Dict[str, Dict[str, Any]]:
        """ë„ë©”ì¸ë³„ ì„¤ì • ì •ë³´ ë°˜í™˜"""
        vectorstore_base = config.ROOT_DIR / "vectorstores"
        
        return {
            "satisfaction": {
                "path": vectorstore_base / "vectorstore_unified_satisfaction",
                "handler_type": HandlerType.SATISFACTION
            },
            "general": {
                "path": vectorstore_base / "vectorstore_general",
                "handler_type": HandlerType.GENERAL
            },
            "menu": {
                "path": vectorstore_base / "vectorstore_menu",
                "handler_type": HandlerType.MENU
            },
            "cyber": {
                "path": vectorstore_base / "vectorstore_cyber",
                "handler_type": HandlerType.CYBER
            },
            "publish": {
                "path": vectorstore_base / "vectorstore_unified_publish",
                "handler_type": HandlerType.PUBLISH
            },
            "notice": {
                "path": vectorstore_base / "vectorstore_notice",
                "handler_type": HandlerType.NOTICE
            }
        }
    
    def preload_all(self) -> Dict[str, bool]:
        """
        ëª¨ë“  ë²¡í„°ìŠ¤í† ì–´ ì‚¬ì „ ë¡œë“œ
        
        Returns:
            Dict[str, bool]: ë„ë©”ì¸ë³„ ë¡œë“œ ì„±ê³µ ì—¬ë¶€
        """
        logger.info("ğŸ“š ì „ì²´ ë²¡í„°ìŠ¤í† ì–´ ì‚¬ì „ ë¡œë“œ ì‹œì‘...")
        start_time = time.time()
        
        results = {}
        for domain in self.domains.keys():
            try:
                success = self._load_domain(domain)
                results[domain] = success
                
                if success:
                    logger.info(f"âœ… {domain} ë¡œë“œ ì„±ê³µ")
                else:
                    logger.warning(f"âš ï¸ {domain} ë¡œë“œ ì‹¤íŒ¨")
                    
            except Exception as e:
                logger.error(f"âŒ {domain} ë¡œë“œ ì¤‘ ì˜ˆì™¸: {e}")
                results[domain] = False
        
        elapsed_time = time.time() - start_time
        success_count = sum(1 for success in results.values() if success)
        
        logger.info(f"ğŸ“Š ì‚¬ì „ ë¡œë“œ ì™„ë£Œ: {success_count}/{len(results)} ì„±ê³µ ({elapsed_time:.2f}s)")
        return results
    
    def _load_domain(self, domain: str) -> bool:
        """
        íŠ¹ì • ë„ë©”ì¸ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ
        
        Args:
            domain: ë„ë©”ì¸ ì´ë¦„
            
        Returns:
            bool: ë¡œë“œ ì„±ê³µ ì—¬ë¶€
        """
        if domain not in self.metadata:
            logger.error(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ë„ë©”ì¸: {domain}")
            return False
        
        meta = self.metadata[domain]
        
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not meta.exists():
            logger.warning(f"âš ï¸ {domain} ë²¡í„°ìŠ¤í† ì–´ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {meta.vectorstore_dir}")
            return False
        
        try:
            with self._access_lock:
                # FAISS ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ
                vectorstore = FAISS.load_local(
                    folder_path=str(meta.vectorstore_dir),
                    embeddings=self.embeddings,
                    allow_dangerous_deserialization=True,
                    index_name=f"{domain}_index"
                )
                
                # ë¬¸ì„œ ë‚´ìš© ì¶”ì¶œ (BM25ìš©)
                documents = []
                docstore = vectorstore.docstore._dict
                
                for doc_id in range(len(docstore)):
                    doc = docstore.get(str(doc_id))
                    if doc and hasattr(doc, 'page_content'):
                        documents.append(doc.page_content)
                
                # BM25 ì¸ë±ìŠ¤ êµ¬ì¶•
                bm25 = None
                if documents:
                    tokenized_docs = [doc.split() for doc in documents]
                    bm25 = BM25Okapi(tokenized_docs)
                
                # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
                meta.vectorstore = vectorstore
                meta.bm25 = bm25
                meta.documents = documents
                meta.mark_loaded(success=True)
                
                logger.debug(f"ğŸ“„ {domain}: {len(documents)}ê°œ ë¬¸ì„œ, BM25 {'âœ“' if bm25 else 'âœ—'}")
                return True
                
        except Exception as e:
            logger.error(f"âŒ {domain} ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì‹¤íŒ¨: {e}")
            meta.mark_loaded(success=False)
            return False
    
    def get_vectorstore(self, domain: str) -> Optional[FAISS]:
        """
        ë„ë©”ì¸ë³„ FAISS ë²¡í„°ìŠ¤í† ì–´ ë°˜í™˜
        
        Args:
            domain: ë„ë©”ì¸ ì´ë¦„
            
        Returns:
            Optional[FAISS]: ë¡œë“œëœ ë²¡í„°ìŠ¤í† ì–´ ë˜ëŠ” None
        """
        if domain not in self.metadata:
            logger.error(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ë„ë©”ì¸: {domain}")
            return None
        
        meta = self.metadata[domain]
        
        # í•«ìŠ¤ì™‘ ì²´í¬
        if meta.needs_reload():
            logger.info(f"ğŸ”„ {domain} íŒŒì¼ ë³€ê²½ ê°ì§€, í•«ìŠ¤ì™‘ ì‹¤í–‰...")
            self._load_domain(domain)
        
        return meta.vectorstore
    
    def get_bm25(self, domain: str) -> Optional[BM25Okapi]:
        """
        ë„ë©”ì¸ë³„ BM25 ì¸ë±ìŠ¤ ë°˜í™˜
        
        Args:
            domain: ë„ë©”ì¸ ì´ë¦„
            
        Returns:
            Optional[BM25Okapi]: BM25 ì¸ë±ìŠ¤ ë˜ëŠ” None
        """
        if domain not in self.metadata:
            return None
        
        meta = self.metadata[domain]
        
        # í•«ìŠ¤ì™‘ ì²´í¬
        if meta.needs_reload():
            self._load_domain(domain)
        
        return meta.bm25
    
    def get_documents(self, domain: str) -> List[str]:
        """
        ë„ë©”ì¸ë³„ ë¬¸ì„œ ëª©ë¡ ë°˜í™˜
        
        Args:
            domain: ë„ë©”ì¸ ì´ë¦„
            
        Returns:
            List[str]: ë¬¸ì„œ í…ìŠ¤íŠ¸ ëª©ë¡
        """
        if domain not in self.metadata:
            return []
        
        meta = self.metadata[domain]
        
        # í•«ìŠ¤ì™‘ ì²´í¬
        if meta.needs_reload():
            self._load_domain(domain)
        
        return meta.documents.copy()
    
    def hybrid_search(
        self, 
        domain: str, 
        query: str, 
        k: int = 10,
        rrf_k: int = 60
    ) -> List[Tuple[str, float, Dict[str, Any]]]:
        """
        ë„ë©”ì¸ë³„ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (FAISS + BM25 + RRF)
        
        Args:
            domain: ê²€ìƒ‰ ëŒ€ìƒ ë„ë©”ì¸
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
            rrf_k: RRF íŒŒë¼ë¯¸í„°
            
        Returns:
            List[Tuple[str, float, dict]]: (í…ìŠ¤íŠ¸, ì ìˆ˜, ë©”íƒ€ë°ì´í„°) íŠœí”Œ ëª©ë¡
        """
        vectorstore = self.get_vectorstore(domain)
        bm25 = self.get_bm25(domain)
        documents = self.get_documents(domain)
        
        if not vectorstore:
            logger.warning(f"âš ï¸ {domain} ë²¡í„°ìŠ¤í† ì–´ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return []
        
        try:
            # 1. FAISS ê²€ìƒ‰
            faiss_results = vectorstore.similarity_search_with_score(query, k=k)
            faiss_docs = [(doc.page_content, score, doc.metadata) for doc, score in faiss_results]
            
            # 2. BM25 ê²€ìƒ‰
            bm25_docs = []
            if bm25 and documents:
                tokenized_query = query.split()
                bm25_scores = bm25.get_scores(tokenized_query)
                
                # ìƒìœ„ kê°œ ì„ íƒ
                top_indices = np.argsort(bm25_scores)[-k:][::-1]
                for idx in top_indices:
                    if idx < len(documents):
                        # ë©”íƒ€ë°ì´í„° ì°¾ê¸°
                        doc_id = str(idx)
                        metadata = {}
                        if hasattr(vectorstore, 'docstore') and doc_id in vectorstore.docstore._dict:
                            metadata = vectorstore.docstore._dict[doc_id].metadata
                        
                        bm25_docs.append((documents[idx], bm25_scores[idx], metadata))
            
            # 3. RRF ìœµí•©
            combined_results = self._rrf_fusion(faiss_docs, bm25_docs, k, rrf_k)
            
            logger.debug(f"ğŸ” {domain} í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: FAISS {len(faiss_docs)}, BM25 {len(bm25_docs)}, ìœµí•© {len(combined_results)}")
            return combined_results
            
        except Exception as e:
            logger.error(f"âŒ {domain} í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _rrf_fusion(
        self, 
        faiss_results: List[Tuple[str, float, Dict]], 
        bm25_results: List[Tuple[str, float, Dict]], 
        k: int, 
        rrf_k: int = 60
    ) -> List[Tuple[str, float, Dict[str, Any]]]:
        """
        Reciprocal Rank Fusion (RRF) ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ê²°ê³¼ ìœµí•©
        
        Args:
            faiss_results: FAISS ê²€ìƒ‰ ê²°ê³¼
            bm25_results: BM25 ê²€ìƒ‰ ê²°ê³¼
            k: ìµœì¢… ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
            rrf_k: RRF íŒŒë¼ë¯¸í„°
            
        Returns:
            List[Tuple]: ìœµí•©ëœ ê²€ìƒ‰ ê²°ê³¼
        """
        try:
            # ë¬¸ì„œë³„ ì ìˆ˜ ì§‘ê³„
            doc_scores = {}
            
            # FAISS ê²°ê³¼ ì²˜ë¦¬ (ì •ê·œí™”ëœ ìˆœìœ„ ì ìˆ˜)
            for rank, (text, score, metadata) in enumerate(faiss_results, 1):
                doc_key = text[:100]  # ë¬¸ì„œ ì‹ë³„ìš© í‚¤
                if doc_key not in doc_scores:
                    doc_scores[doc_key] = {
                        'text': text,
                        'metadata': metadata,
                        'faiss_score': score,
                        'bm25_score': 0.0,
                        'rrf_score': 0.0
                    }
                
                # RRF ì ìˆ˜ ê³„ì‚°: 1 / (rank + k)
                doc_scores[doc_key]['rrf_score'] += 1.0 / (rank + rrf_k)
                doc_scores[doc_key]['faiss_score'] = max(doc_scores[doc_key]['faiss_score'], score)
            
            # BM25 ê²°ê³¼ ì²˜ë¦¬
            for rank, (text, score, metadata) in enumerate(bm25_results, 1):
                doc_key = text[:100]
                if doc_key not in doc_scores:
                    doc_scores[doc_key] = {
                        'text': text,
                        'metadata': metadata,
                        'faiss_score': 0.0,
                        'bm25_score': score,
                        'rrf_score': 0.0
                    }
                
                doc_scores[doc_key]['rrf_score'] += 1.0 / (rank + rrf_k)
                doc_scores[doc_key]['bm25_score'] = max(doc_scores[doc_key]['bm25_score'], score)
            
            # RRF ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
            sorted_docs = sorted(
                doc_scores.values(),
                key=lambda x: x['rrf_score'],
                reverse=True
            )
            
            # ìƒìœ„ kê°œ ë°˜í™˜
            return [
                (doc['text'], doc['rrf_score'], doc['metadata'])
                for doc in sorted_docs[:k]
            ]
            
        except Exception as e:
            logger.error(f"âŒ RRF ìœµí•© ì‹¤íŒ¨: {e}")
            # ìœµí•© ì‹¤íŒ¨ ì‹œ FAISS ê²°ê³¼ë§Œ ë°˜í™˜
            return faiss_results[:k]
    
    def force_reload(self, domain: str) -> bool:
        """
        íŠ¹ì • ë„ë©”ì¸ ê°•ì œ ì¬ë¡œë“œ
        
        Args:
            domain: ì¬ë¡œë“œí•  ë„ë©”ì¸
            
        Returns:
            bool: ì¬ë¡œë“œ ì„±ê³µ ì—¬ë¶€
        """
        if domain not in self.metadata:
            logger.error(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ë„ë©”ì¸: {domain}")
            return False
        
        logger.info(f"ğŸ”„ {domain} ê°•ì œ ì¬ë¡œë“œ ì‹¤í–‰...")
        
        # ê¸°ì¡´ ë°ì´í„° í´ë¦¬ì–´
        meta = self.metadata[domain]
        meta.vectorstore = None
        meta.bm25 = None
        meta.documents = []
        meta.file_hash = None
        
        # ì¬ë¡œë“œ
        return self._load_domain(domain)
    
    def force_reload_all(self) -> Dict[str, bool]:
        """
        ëª¨ë“  ë„ë©”ì¸ ê°•ì œ ì¬ë¡œë“œ
        
        Returns:
            Dict[str, bool]: ë„ë©”ì¸ë³„ ì¬ë¡œë“œ ê²°ê³¼
        """
        logger.info("ğŸ”„ ì „ì²´ ë„ë©”ì¸ ê°•ì œ ì¬ë¡œë“œ ì‹œì‘...")
        
        results = {}
        for domain in self.domains.keys():
            results[domain] = self.force_reload(domain)
        
        success_count = sum(1 for success in results.values() if success)
        logger.info(f"ğŸ”„ ì „ì²´ ì¬ë¡œë“œ ì™„ë£Œ: {success_count}/{len(results)} ì„±ê³µ")
        
        return results
    
    def get_status(self) -> Dict[str, Dict[str, Any]]:
        """
        ì „ì²´ ì¸ë±ìŠ¤ ìƒíƒœ ì •ë³´ ë°˜í™˜
        
        Returns:
            Dict[str, Dict]: ë„ë©”ì¸ë³„ ìƒíƒœ ì •ë³´
        """
        status = {}
        
        for domain, meta in self.metadata.items():
            status[domain] = {
                'loaded': meta.vectorstore is not None,
                'documents_count': len(meta.documents),
                'has_bm25': meta.bm25 is not None,
                'last_loaded': meta.last_loaded.isoformat() if meta.last_loaded else None,
                'load_count': meta.load_count,
                'error_count': meta.error_count,
                'file_exists': meta.exists(),
                'file_hash': meta.file_hash[:8] if meta.file_hash else None,
                'needs_reload': meta.needs_reload()
            }
        
        return status
    
    def health_check(self) -> Dict[str, Any]:
        """
        IndexManager í—¬ìŠ¤ì²´í¬
        
        Returns:
            Dict[str, Any]: í—¬ìŠ¤ì²´í¬ ê²°ê³¼
        """
        status = self.get_status()
        
        total_domains = len(status)
        loaded_domains = sum(1 for s in status.values() if s['loaded'])
        total_documents = sum(s['documents_count'] for s in status.values())
        total_errors = sum(s['error_count'] for s in status.values())
        
        health = {
            'overall_health': 'healthy' if loaded_domains == total_domains else 'degraded',
            'loaded_domains': f"{loaded_domains}/{total_domains}",
            'total_documents': total_documents,
            'total_errors': total_errors,
            'domains': status,
            'timestamp': datetime.now().isoformat()
        }
        
        return health
    
    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        logger.info("ğŸ§¹ IndexManager ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹œì‘...")
        
        with self._access_lock:
            for meta in self.metadata.values():
                meta.vectorstore = None
                meta.bm25 = None
                meta.documents = []
        
        logger.info("âœ… IndexManager ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")


# ================================================================
# 3. ì „ì—­ ì ‘ê·¼ í•¨ìˆ˜ë“¤
# ================================================================

def get_index_manager() -> IndexManager:
    """ì „ì—­ IndexManager ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    return IndexManager()


def preload_all_indexes() -> Dict[str, bool]:
    """ëª¨ë“  ì¸ë±ìŠ¤ ì‚¬ì „ ë¡œë“œ (ì•± ì´ˆê¸°í™”ìš©)"""
    manager = get_index_manager()
    return manager.preload_all()


def get_vectorstore(domain: str) -> Optional[FAISS]:
    """ë„ë©”ì¸ë³„ ë²¡í„°ìŠ¤í† ì–´ ë°˜í™˜ (í•¸ë“¤ëŸ¬ìš©)"""
    manager = get_index_manager()
    return manager.get_vectorstore(domain)


def hybrid_search(domain: str, query: str, k: int = 10) -> List[Tuple[str, float, Dict[str, Any]]]:
    """ë„ë©”ì¸ë³„ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (í•¸ë“¤ëŸ¬ìš©)"""
    manager = get_index_manager()
    return manager.hybrid_search(domain, query, k)


def index_health_check() -> Dict[str, Any]:
    """ì¸ë±ìŠ¤ ìƒíƒœ í™•ì¸ (ëª¨ë‹ˆí„°ë§ìš©)"""
    manager = get_index_manager()
    return manager.health_check()


# ================================================================
# 4. ê°œë°œ/í…ŒìŠ¤íŠ¸ìš© í•¨ìˆ˜ë“¤
# ================================================================

def test_index_manager():
    """IndexManager ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    logger.info("ğŸ§ª IndexManager í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    try:
        # 1. ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í…ŒìŠ¤íŠ¸
        manager = get_index_manager()
        logger.info("âœ… ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì„±ê³µ")
        
        # 2. í—¬ìŠ¤ì²´í¬
        health = manager.health_check()
        logger.info(f"ğŸ“Š ì´ˆê¸° ìƒíƒœ: {health['overall_health']}")
        
        # 3. ì‚¬ì „ ë¡œë“œ í…ŒìŠ¤íŠ¸
        results = manager.preload_all()
        success_count = sum(1 for success in results.values() if success)
        logger.info(f"ğŸ“š ì‚¬ì „ ë¡œë“œ ê²°ê³¼: {success_count}/{len(results)} ì„±ê³µ")
        
        # 4. ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        test_queries = {
            "satisfaction": "êµìœ¡ê³¼ì • ë§Œì¡±ë„",
            "general": "í•™ì¹™ ê·œì •",
            "menu": "ì‹ë‹¨ ë©”ë‰´",
            "cyber": "ì‚¬ì´ë²„êµìœ¡",
            "publish": "êµìœ¡ê³„íš",
            "notice": "ê³µì§€ì‚¬í•­"
        }
        
        for domain, query in test_queries.items():
            try:
                results = manager.hybrid_search(domain, query, k=3)
                logger.info(f"ğŸ” {domain} ê²€ìƒ‰ í…ŒìŠ¤íŠ¸: {len(results)}ê±´ ë°˜í™˜")
            except Exception as e:
                logger.error(f"âŒ {domain} ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        
        # 5. ìµœì¢… í—¬ìŠ¤ì²´í¬
        final_health = manager.health_check()
        logger.info(f"ğŸ ìµœì¢… ìƒíƒœ: {final_health['overall_health']}")
        logger.info(f"ğŸ“„ ì´ ë¬¸ì„œ ìˆ˜: {final_health['total_documents']}")
        
        return final_health
        
    except Exception as e:
        logger.error(f"âŒ IndexManager í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return None


if __name__ == "__main__":
    import logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_index_manager()
