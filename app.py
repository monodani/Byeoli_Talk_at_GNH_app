import streamlit as st
from langchain.chat_models import ChatOpenAI
from langchain.callbacks.base import BaseCallbackHandler

# í™˜ê²½ ë³€ìˆ˜/Secretsì—ì„œ API KEY ê°€ì ¸ì˜¤ê¸°
openai_api_key = st.secrets["OPENAI_API_KEY"]

# 1. ìŠ¤íŠ¸ë¦¬ë° í•¸ë“¤ëŸ¬ ì •ì˜
class StreamHandler(BaseCallbackHandler):
    def __init__(self):
        self.text_area = st.empty()
        self.full_text = ""

    def on_llm_new_token(self, token: str, **kwargs):
        self.full_text += token
        self.text_area.markdown(self.full_text)

# 2. ëŒ€í™”ë‚´ì—­ ì´ˆê¸°í™”
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []

st.title("ğŸ“ ê³µê³µ ë¯¼ì› ì±—ë´‡")

# 3. ì‚¬ìš©ì ì…ë ¥
user_input = st.chat_input("ë¯¼ì›ì„ ì…ë ¥í•˜ì„¸ìš”:")

# 4. ì…ë ¥ì‹œ ì²˜ë¦¬
if user_input:
    st.session_state.chat_history.append(("ë¯¼ì›ì¸", user_input))
    handler = StreamHandler()
    llm = ChatOpenAI(
        streaming=True,
        callbacks=[handler],
        openai_api_key=openai_api_key,
        model_name="gpt-4o",  # ì›í•˜ëŠ” ëª¨ë¸ ì´ë¦„ ì‚¬ìš© (ì˜ˆ: gpt-4o, gpt-4-turbo ë“±)
        temperature=0.0,
    )
    response = llm.predict(user_input)
    st.session_state.chat_history.append(("ì±—ë´‡", response))

# 5. ëˆ„ì  ëŒ€í™” ì¶œë ¥
for role, msg in st.session_state.chat_history:
    with st.chat_message(role):
        st.markdown(msg)
