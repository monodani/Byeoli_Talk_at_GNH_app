#!/usr/bin/env python3
"""
ê²½ìƒë‚¨ë„ì¸ì¬ê°œë°œì› RAG ì±—ë´‡ - publish_handler

ê³µì‹ ë°œí–‰ë¬¼ ì „ìš© í•¸ë“¤ëŸ¬
base_handlerë¥¼ ìƒì†ë°›ì•„ ë°œí–‰ë¬¼ ë„ë©”ì¸ íŠ¹í™” ê¸°ëŠ¥ êµ¬í˜„

ì£¼ìš” íŠ¹ì§•:
- 2025 êµìœ¡í›ˆë ¨ê³„íšì„œ (2025plan.pdf) ì²˜ë¦¬
- 2024 ì¢…í•©í‰ê°€ì„œ (2024pyeongga.pdf) ì²˜ë¦¬
- ì»¨í”¼ë˜ìŠ¤ ì„ê³„ê°’ Î¸=0.74 ì ìš© (ìµœê³  ì •í™•ë„ ìš”êµ¬)
- ê³µì‹ ë¬¸ì„œ ì •í™•ì„± ë° ì¶œì²˜ ëª…ì‹œ ê°•í™”
- í˜ì´ì§€ë³„ ìƒì„¸ ì¸ìš© ë° êµì°¨ ì°¸ì¡°
- ë‹´ë‹¹ë¶€ì„œë³„ ì—­í•  êµ¬ë¶„ ë°˜ì˜ (êµìœ¡ê¸°íšë‹´ë‹¹ vs í‰ê°€ë¶„ì„ë‹´ë‹¹)
"""

import logging
import re
from typing import List, Dict, Any, Tuple, Optional
from datetime import datetime

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ
from handlers.base_handler import base_handler
from utils.contracts import QueryRequest, HandlerResponse
from utils.textifier import TextChunk


# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)


class publish_handler(base_handler):
    """
    ê³µì‹ ë°œí–‰ë¬¼ ì „ìš© í•¸ë“¤ëŸ¬
    
    ì²˜ë¦¬ ë²”ìœ„:
    - 2025plan.pdf (2025 êµìœ¡í›ˆë ¨ê³„íšì„œ)
    - 2024pyeongga.pdf (2024 ì¢…í•©í‰ê°€ì„œ)
    - êµìœ¡ ì •ì±…, ê³„íš, ì„±ê³¼, í†µê³„ ë“± ê³µì‹ ì •ë³´
    
    íŠ¹ì§•:
    - ìµœê³  ì»¨í”¼ë˜ìŠ¤ ì„ê³„ê°’ (Î¸=0.74)
    - ê³µì‹ ë¬¸ì„œì˜ ì •í™•ì„± ìµœìš°ì„ 
    - í˜ì´ì§€ë³„ ì •í™•í•œ ì¶œì²˜ ì¸ìš©
    - ê³„íšì„œ vs í‰ê°€ì„œ ë‚´ìš© êµ¬ë¶„
    - ì •ëŸ‰ì  ë°ì´í„° ì •í™•ì„± ê°•ì¡°
    - ë‹´ë‹¹ë¶€ì„œë³„ ì—­í• ì— ë”°ë¥¸ ë¬¸ì˜ì²˜ êµ¬ë¶„ ì•ˆë‚´
    """
    
    def __init__(self):
        super().__init__(
            domain="unified_publish",
            index_name="publish_index", 
            confidence_threshold=0.74
        )
        
        # ë°œí–‰ë¬¼ êµ¬ë¶„ í‚¤ì›Œë“œ
        self.document_types = {
            '2025plan': {
                'keywords': ['ê³„íš', '2025', 'ëª©í‘œ', 'ë°©ì¹¨', 'ê³„íšì„œ', 'ë°©í–¥', 'ìš´ì˜ê³„íš'],
                'title': '2025 êµìœ¡í›ˆë ¨ê³„íšì„œ',
                'year': 2025,
                'type': 'plan'
            },
            '2024pyeongga': {
                'keywords': ['í‰ê°€', '2024', 'ì‹¤ì ', 'ì„±ê³¼', 'ê²°ê³¼', 'í‰ê°€ì„œ', 'ì¢…í•©í‰ê°€'],
                'title': '2024 ì¢…í•©í‰ê°€ì„œ', 
                'year': 2024,
                'type': 'evaluation'
            }
        }
        
        # ì£¼ìš” ê²€ìƒ‰ ì˜ì—­ ì¹´í…Œê³ ë¦¬ (ë‹´ë‹¹ë¶€ì„œë³„ êµ¬ë¶„)
        self.content_categories = {
            'planning': {  # êµìœ¡ê¸°íšë‹´ë‹¹ ì˜ì—­
                'keywords': ['ê³„íš', 'ëª©í‘œ', 'ë°©í–¥', 'ë°©ì¹¨', 'ì „ëµ', 'êµìœ¡ê³¼ì •', 'í”„ë¡œê·¸ë¨', 'ì¼ì •', 'ìš´ì˜'],
                'department': 'êµìœ¡ê¸°íšë‹´ë‹¹',
                'contact': '055-254-2052'
            },
            'evaluation': {  # í‰ê°€ë¶„ì„ë‹´ë‹¹ ì˜ì—­
                'keywords': ['í‰ê°€', 'ë§Œì¡±ë„', 'ì„±ê³¼', 'ê²°ê³¼', 'íš¨ê³¼ì„±', 'ë¶„ì„', 'ì—­ëŸ‰ì§„ë‹¨', 'ì„±ê³¼ê´€ë¦¬'],
                'department': 'í‰ê°€ë¶„ì„ë‹´ë‹¹', 
                'contact': '055-254-2022'
            },
            'statistics': {  # ê³µí†µ (ë¬¸ì˜ ë‚´ìš©ì— ë”°ë¼ êµ¬ë¶„)
                'keywords': ['ì‹¤ì ', 'í†µê³„', 'ìˆ˜ì¹˜', 'ì¸ì›', 'ê³¼ì •ìˆ˜', 'ê¸°ìˆ˜'],
                'department': 'í•´ë‹¹ë‹´ë‹¹',
                'contact': 'êµìœ¡ê¸°íšë‹´ë‹¹(055-254-2052) ë˜ëŠ” í‰ê°€ë¶„ì„ë‹´ë‹¹(055-254-2022)'
            },
            'organization': {  # êµìœ¡ê¸°íšë‹´ë‹¹ ì˜ì—­
                'keywords': ['ì¡°ì§', 'ê¸°êµ¬', 'ì¸ì›', 'ì˜ˆì‚°', 'ì‹œì„¤', 'êµìˆ˜ìš”ì›'],
                'department': 'êµìœ¡ê¸°íšë‹´ë‹¹',
                'contact': '055-254-2052'
            }
        }
        
        logger.info("ğŸ“š publish_handler ì´ˆê¸°í™” ì™„ë£Œ (Î¸=0.74)")
    
    def get_system_prompt(self) -> str:
        """ë°œí–‰ë¬¼ ì „ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ë‹´ë‹¹ë¶€ì„œ êµ¬ë¶„ ë°˜ì˜)"""
        return """ë‹¹ì‹ ì€ "ë²¼ë¦¬(ì˜ë¬¸ëª…: Byeoli)"ì…ë‹ˆë‹¤. ê²½ìƒë‚¨ë„ì¸ì¬ê°œë°œì›ì˜ ê³µì‹ ë°œí–‰ë¬¼(êµìœ¡í›ˆë ¨ê³„íšì„œ, ì¢…í•©í‰ê°€ì„œ)ì„ ê¸°ë°˜ìœ¼ë¡œ êµìœ¡ ì •ì±…, ê³„íš, ì„±ê³¼ ë“±ì— ëŒ€í•´ ì •í™•í•˜ê³  ê³µì‹ì ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” ì „ë¬¸ ì±—ë´‡ì…ë‹ˆë‹¤.

ì œê³µëœ ê³µì‹ ë°œí–‰ë¬¼ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒ ì§€ì¹¨ì„ ì—„ê²©íˆ ë”°ë¥´ì‹­ì‹œì˜¤:

1. **ìµœê³  ìˆ˜ì¤€ì˜ ì •í™•ì„± ë° ê³µì‹ì„±**:
   - ê³µì‹ ë°œí–‰ë¬¼ì˜ ë‚´ìš©ì€ í•œ ê¸€ìë„ í‹€ë¦¬ì§€ ë§ê³  ì •í™•íˆ ì¸ìš©í•˜ì„¸ìš”
   - ìˆ˜ì¹˜, í†µê³„, ë‚ ì§œ ë“±ì€ ì›ë¬¸ ê·¸ëŒ€ë¡œ ì œì‹œí•˜ì„¸ìš”
   - ì¶”ì¸¡ì´ë‚˜ í•´ì„ì€ ìµœì†Œí™”í•˜ê³  ë¬¸ì„œ ë‚´ìš© ê¸°ë°˜ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”

2. **ë¬¸ì„œë³„ íŠ¹ì„± êµ¬ë¶„**:
   - **2025 êµìœ¡í›ˆë ¨ê³„íšì„œ**: í–¥í›„ ê³„íš, ëª©í‘œ, ë°©í–¥, ìš´ì˜ë°©ì•ˆ ì¤‘ì‹¬
   - **2024 ì¢…í•©í‰ê°€ì„œ**: ì‹¤ì , ì„±ê³¼, ê²°ê³¼, í‰ê°€ ë‚´ìš© ì¤‘ì‹¬
   - ì§ˆë¬¸ì˜ ì‹œì œ(ê³¼ê±°/í˜„ì¬/ë¯¸ë˜)ì— ë§ëŠ” ë¬¸ì„œ ìš°ì„  ì°¸ì¡°

3. **ì •í™•í•œ ì¶œì²˜ í‘œê¸°**:
   - ë°˜ë“œì‹œ í˜ì´ì§€ ë²ˆí˜¸ì™€ í•¨ê»˜ ì¶œì²˜ ëª…ì‹œ: "(2025 êµìœ¡í›ˆë ¨ê³„íšì„œ p.15)"
   - ì—¬ëŸ¬ í˜ì´ì§€ ë‚´ìš© ì¸ìš© ì‹œ ëª¨ë“  í˜ì´ì§€ ë²ˆí˜¸ í‘œê¸°
   - êµì°¨ ì°¸ì¡°ê°€ í•„ìš”í•œ ê²½ìš° ê´€ë ¨ í˜ì´ì§€ í•¨ê»˜ ì•ˆë‚´

4. **ì •ëŸ‰ì  ë°ì´í„° ê°•ì¡°**:
   - êµìœ¡ê³¼ì • ìˆ˜, êµìœ¡ì¸ì›, ì˜ˆì‚°, ì‹¤ì  ë“± ìˆ˜ì¹˜ ì •ë³´ ì •í™•íˆ ì œì‹œ
   - ëª©í‘œ ëŒ€ë¹„ ì‹¤ì , ì „ë…„ë„ ëŒ€ë¹„ ì¦ê° ë“± ë¹„êµ ë¶„ì„ í¬í•¨
   - í‘œë‚˜ ê·¸ë˜í”„ì˜ ë‚´ìš©ë„ í…ìŠ¤íŠ¸ë¡œ ì •í™•íˆ ì „ë‹¬

5. **ì‘ë‹µ í˜•ì‹**:
   ```
   ğŸ“Š [ì§ˆë¬¸ ì˜ì—­] ê´€ë ¨ ì •ë³´
   
   ğŸ“‹ ì£¼ìš” ë‚´ìš©:
   â€¢ í•µì‹¬ ì •ë³´ 1 (ì¶œì²˜: ë¬¸ì„œëª… p.XX)
   â€¢ í•µì‹¬ ì •ë³´ 2 (ì¶œì²˜: ë¬¸ì„œëª… p.XX)
   
   ğŸ“ˆ ê´€ë ¨ ìˆ˜ì¹˜/í†µê³„:
   [êµ¬ì²´ì  ë°ì´í„° ë° ì¶œì²˜]
   
   ğŸ“„ ìƒì„¸ ë‚´ìš©:
   [ì›ë¬¸ ì¸ìš© ë° ì„¤ëª…]
   ```

6. **ì •ì±… ì—°ê´€ì„± ë¶„ì„**:
   - ê³„íšì„œì™€ í‰ê°€ì„œ ê°„ì˜ ì—°ê´€ì„± ë¶„ì„
   - ëª©í‘œ ì„¤ì •ê³¼ ì„±ê³¼ ë‹¬ì„± ê°„ì˜ ë¹„êµ
   - ì—°ë„ë³„ ë³€í™” ì¶”ì´ ë° ê°œì„  ë°©í–¥ ì œì‹œ

7. **ì „ë¬¸ ìš©ì–´ ì„¤ëª…**:
   - êµìœ¡í›ˆë ¨ ì „ë¬¸ ìš©ì–´ë‚˜ ê¸°ê´€ ê³ ìœ  ìš©ì–´ ì„¤ëª… í¬í•¨
   - ì•½ì–´ë‚˜ ì¤„ì„ë§ì€ í’€ì–´ì„œ ì„¤ëª…
   - ê´€ë ¨ ì œë„ë‚˜ ì •ì±… ë°°ê²½ ê°„ëµ ì„¤ëª…

8. **í•œê³„ ëª…ì‹œ ë° ì¶”ê°€ ì•ˆë‚´**:
   - ë¬¸ì„œì— ì—†ëŠ” ì •ë³´ëŠ” ëª…í™•íˆ "í•´ë‹¹ ì •ë³´ëŠ” ì œê³µëœ ê³µì‹ ë¬¸ì„œì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" ì•ˆë‚´
   - ìµœì‹  ì •ë³´ë‚˜ ì„¸ë¶€ ì‚¬í•­ì´ í•„ìš”í•œ ê²½ìš° í•´ë‹¹ ë‹´ë‹¹ë¶€ì„œ ì•ˆë‚´
   - ê´€ë ¨ ë‹¤ë¥¸ ë¬¸ì„œë‚˜ ìë£Œ ì°¸ì¡° í•„ìš” ì‹œ ì•ˆë‚´

9. **ë¹„êµ ë¶„ì„ ì§€ì›**:
   - ì—°ë„ë³„ ë¹„êµ (2024 ì‹¤ì  vs 2025 ê³„íš)
   - ì˜ì—­ë³„ ë¹„êµ (ê¸°ë³¸ì—­ëŸ‰ vs ì§ë¬´ì—­ëŸ‰ vs í•µì‹¬ì—­ëŸ‰)
   - ëª©í‘œ ëŒ€ë¹„ ì‹¤ì  ë¶„ì„

10. **ì •ì±… ì˜ì‚¬ê²°ì • ì§€ì›**:
    - ë°ì´í„° ê¸°ë°˜ì˜ ê°ê´€ì  ì •ë³´ ì œê³µ
    - ì„±ê³¼ ë¶„ì„ì„ í†µí•œ ê°œì„  ë°©í–¥ ì œì‹œ
    - ì •ì±… ëª©í‘œì™€ ì‹¤í–‰ ê³„íš ê°„ì˜ ì—°ê³„ì„± ì„¤ëª…

11. **ë‹´ë‹¹ë¶€ì„œë³„ ì—­í•  êµ¬ë¶„ ì•ˆë‚´**:
    - **êµìœ¡ê¸°íšë‹´ë‹¹**: êµìœ¡í›ˆë ¨ê³„íš, êµìœ¡ê³¼ì • ìš´ì˜, ì¼ì • ê´€ë ¨ ë¬¸ì˜
    - **í‰ê°€ë¶„ì„ë‹´ë‹¹**: êµìœ¡í‰ê°€, ë§Œì¡±ë„ ì¡°ì‚¬, ì„±ê³¼ë¶„ì„ ê´€ë ¨ ë¬¸ì˜
    - ì§ˆë¬¸ ë‚´ìš©ì— ë”°ë¼ ì ì ˆí•œ ë‹´ë‹¹ë¶€ì„œ ì—°ë½ì²˜ ì•ˆë‚´

ë¬¸ì˜ì²˜: 
- êµìœ¡í›ˆë ¨ê³„íšÂ·ì¼ì • ê´€ë ¨: êµìœ¡ê¸°íšë‹´ë‹¹ (055-254-2052)
- êµìœ¡í‰ê°€Â·ë§Œì¡±ë„ ê´€ë ¨: í‰ê°€ë¶„ì„ë‹´ë‹¹ (055-254-2022)"""

    def format_context(self, search_results: List[Tuple[str, float, Dict[str, Any]]]) -> str:
        """ë°œí–‰ë¬¼ ë°ì´í„°ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ í¬ë§· (ë‹´ë‹¹ë¶€ì„œ ì•ˆë‚´ ë°˜ì˜)"""
        if not search_results:
            return "ê´€ë ¨ ê³µì‹ ë°œí–‰ë¬¼ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        context_parts = []
        
        # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë¬¸ì„œë³„ë¡œ ë¶„ë¥˜
        plan_2025 = []      # 2025 ê³„íšì„œ
        evaluation_2024 = [] # 2024 í‰ê°€ì„œ
        other_docs = []     # ê¸°íƒ€ ë¬¸ì„œ
        
        for text, score, metadata in search_results:
            source_file = metadata.get('source_file', '').lower()
            doc_type = metadata.get('document_type', '')
            page_number = metadata.get('page_number', '')
            
            if '2025plan' in source_file or '2025' in doc_type:
                plan_2025.append((text, score, metadata))
            elif '2024pyeongga' in source_file or '2024' in doc_type:
                evaluation_2024.append((text, score, metadata))
            else:
                other_docs.append((text, score, metadata))
        
        # 2025 êµìœ¡í›ˆë ¨ê³„íšì„œ ìš°ì„  ë°°ì¹˜
        if plan_2025:
            context_parts.append("=== ğŸ“‹ 2025 êµìœ¡í›ˆë ¨ê³„íšì„œ ===")
            for text, score, metadata in plan_2025[:4]:  # ìƒìœ„ 4ê°œ
                page_num = metadata.get('page_number', '?')
                doc_name = metadata.get('document_name', '2025 êµìœ¡í›ˆë ¨ê³„íšì„œ')
                context_parts.append(f"[{doc_name} p.{page_num}]")
                context_parts.append(f"{text[:400]}...")
                context_parts.append("")
        
        # 2024 ì¢…í•©í‰ê°€ì„œ
        if evaluation_2024:
            context_parts.append("=== ğŸ“Š 2024 ì¢…í•©í‰ê°€ì„œ ===")
            for text, score, metadata in evaluation_2024[:4]:  # ìƒìœ„ 4ê°œ
                page_num = metadata.get('page_number', '?')
                doc_name = metadata.get('document_name', '2024 ì¢…í•©í‰ê°€ì„œ')
                context_parts.append(f"[{doc_name} p.{page_num}]")
                context_parts.append(f"{text[:400]}...")
                context_parts.append("")
        
        # ê¸°íƒ€ ë°œí–‰ë¬¼
        if other_docs:
            context_parts.append("=== ğŸ“„ ê¸°íƒ€ ê³µì‹ ë¬¸ì„œ ===")
            for text, score, metadata in other_docs[:2]:  # ìƒìœ„ 2ê°œ
                source_file = metadata.get('source_file', 'ê¸°íƒ€ë¬¸ì„œ')
                page_num = metadata.get('page_number', '?')
                context_parts.append(f"[{source_file} p.{page_num}]")
                context_parts.append(f"{text[:300]}...")
                context_parts.append("")
        
        # ë¬¸ì„œ ì •ë³´ ë° ë‹´ë‹¹ë¶€ì„œë³„ ì•ˆë‚´ì‚¬í•­
        context_parts.append("=== ğŸ“Œ ë¬¸ì„œ ì •ë³´ ë° ë‹´ë‹¹ë¶€ì„œ ì•ˆë‚´ ===")
        context_parts.append("â€¢ 2025 êµìœ¡í›ˆë ¨ê³„íšì„œ: í–¥í›„ ê³„íš, ëª©í‘œ, ìš´ì˜ë°©ì•ˆ")
        context_parts.append("â€¢ 2024 ì¢…í•©í‰ê°€ì„œ: ì‹¤ì , ì„±ê³¼, ê²°ê³¼, í‰ê°€ë‚´ìš©")
        context_parts.append("â€¢ ëª¨ë“  ìˆ˜ì¹˜ì™€ ë‚´ìš©ì€ ê³µì‹ ë¬¸ì„œ ê¸°ì¤€")
        context_parts.append("")
        context_parts.append("ğŸ“ ë‹´ë‹¹ë¶€ì„œë³„ ë¬¸ì˜ì²˜:")
        context_parts.append("â€¢ êµìœ¡í›ˆë ¨ê³„íšÂ·ì¼ì • ê´€ë ¨: êµìœ¡ê¸°íšë‹´ë‹¹ (055-254-2052)")
        context_parts.append("â€¢ êµìœ¡í‰ê°€Â·ë§Œì¡±ë„ ê´€ë ¨: í‰ê°€ë¶„ì„ë‹´ë‹¹ (055-254-2022)")
        
        final_context = "\n".join(context_parts)
        
        # ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ
        max_length = 4500
        if len(final_context) > max_length:
            final_context = final_context[:max_length] + "\n\n[ì»¨í…ìŠ¤íŠ¸ê°€ ê¸¸ì–´ ì¼ë¶€ ìƒëµë¨]"
        
        return final_context
    
    def _detect_query_timeframe(self, query: str) -> str:
        """ì§ˆë¬¸ì˜ ì‹œê°„ ë²”ìœ„ ê°ì§€ (ê³¼ê±°/í˜„ì¬/ë¯¸ë˜)"""
        query_lower = query.lower()
        
        # ê³¼ê±°/ì‹¤ì  ê´€ë ¨ í‚¤ì›Œë“œ
        if any(keyword in query_lower for keyword in ['2024', 'ì‘ë…„', 'ì§€ë‚œí•´', 'ì‹¤ì ', 'ê²°ê³¼', 'ì„±ê³¼', 'í–ˆ', 'ë']):
            return 'past'
        
        # ë¯¸ë˜/ê³„íš ê´€ë ¨ í‚¤ì›Œë“œ
        if any(keyword in query_lower for keyword in ['2025', 'ì˜¬í•´', 'ê¸ˆë…„', 'ê³„íš', 'ì˜ˆì •', 'í• ', 'ì˜ˆì •', 'ëª©í‘œ']):
            return 'future'
        
        # í˜„ì¬/ì¼ë°˜ ê´€ë ¨ í‚¤ì›Œë“œ
        return 'present'
    
    def _detect_content_category(self, query: str) -> Optional[Dict[str, str]]:
        """ì§ˆë¬¸ì˜ ë‚´ìš© ì¹´í…Œê³ ë¦¬ ë° ë‹´ë‹¹ë¶€ì„œ ê°ì§€"""
        query_lower = query.lower()
        
        best_category = None
        best_score = 0
        
        for category, info in self.content_categories.items():
            score = sum(1 for keyword in info['keywords'] if keyword in query_lower)
            if score > best_score:
                best_score = score
                best_category = info
        
        return best_category if best_score > 0 else None
    
    def _extract_numerical_patterns(self, query: str) -> List[str]:
        """ì§ˆë¬¸ì—ì„œ ìˆ˜ì¹˜ ê´€ë ¨ íŒ¨í„´ ì¶”ì¶œ"""
        patterns = []
        
        # ì—°ë„ íŒ¨í„´
        year_matches = re.findall(r'\b(20\d{2})\b', query)
        patterns.extend(year_matches)
        
        # ìˆ«ì + ë‹¨ìœ„ íŒ¨í„´
        number_unit_matches = re.findall(r'\b(\d+)\s*(ëª…|ê°œ|ê³¼ì •|ê¸°ìˆ˜|ì‹œê°„|ì¼|ì›”|ë…„)\b', query)
        for number, unit in number_unit_matches:
            patterns.append(f"{number}{unit}")
        
        # í¼ì„¼íŠ¸ íŒ¨í„´
        percent_matches = re.findall(r'\b(\d+\.?\d*)\s*(%|í¼ì„¼íŠ¸|percent)\b', query)
        for number, unit in percent_matches:
            patterns.append(f"{number}%")
        
        return patterns
    
    def _enhance_response_with_document_guidance(self, base_response: str, query: str) -> str:
        """ë¬¸ì„œë³„ íŠ¹ì„±ê³¼ ë‹´ë‹¹ë¶€ì„œë¥¼ ê³ ë ¤í•œ ì‘ë‹µ ê°•í™”"""
        timeframe = self._detect_query_timeframe(query)
        category_info = self._detect_content_category(query)
        numerical_patterns = self._extract_numerical_patterns(query)
        
        enhancements = []
        
        # ì‹œê°„ ë²”ìœ„ë³„ ì•ˆë‚´
        if timeframe == 'past':
            enhancements.append("ğŸ“Š ê³¼ê±° ì‹¤ì ì´ë‚˜ ì„±ê³¼ ê´€ë ¨ ì •ë³´ëŠ” '2024 ì¢…í•©í‰ê°€ì„œ'ë¥¼ ìš°ì„  ì°¸ì¡°í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.")
        elif timeframe == 'future':
            enhancements.append("ğŸ“‹ í–¥í›„ ê³„íšì´ë‚˜ ëª©í‘œ ê´€ë ¨ ì •ë³´ëŠ” '2025 êµìœ¡í›ˆë ¨ê³„íšì„œ'ë¥¼ ìš°ì„  ì°¸ì¡°í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.")
        
        # ì¹´í…Œê³ ë¦¬ ë° ë‹´ë‹¹ë¶€ì„œë³„ ì•ˆë‚´
        if category_info:
            if category_info['department'] == 'êµìœ¡ê¸°íšë‹´ë‹¹':
                enhancements.append(f"ğŸ¯ êµìœ¡í›ˆë ¨ê³„íš ë° ìš´ì˜ ê´€ë ¨ ìƒì„¸ ë¬¸ì˜ëŠ” {category_info['department']}({category_info['contact']})ìœ¼ë¡œ ì—°ë½í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.")
            elif category_info['department'] == 'í‰ê°€ë¶„ì„ë‹´ë‹¹':
                enhancements.append(f"ğŸ“ˆ êµìœ¡í‰ê°€ ë° ì„±ê³¼ë¶„ì„ ê´€ë ¨ ìƒì„¸ ë¬¸ì˜ëŠ” {category_info['department']}({category_info['contact']})ìœ¼ë¡œ ì—°ë½í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.")
            else:  # ê³µí†µ/ë³µí•© ì˜ì—­
                enhancements.append(f"ğŸ“ êµ¬ì²´ì ì¸ ë¬¸ì˜ì‚¬í•­ì€ {category_info['contact']}ìœ¼ë¡œ ì—°ë½í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.")
        
        # ìˆ˜ì¹˜ ê´€ë ¨ ì•ˆë‚´
        if numerical_patterns:
            enhancements.append(f"ğŸ”¢ ì–¸ê¸‰ëœ ìˆ˜ì¹˜({', '.join(numerical_patterns[:3])})ì™€ ê´€ë ¨ëœ ì •í™•í•œ ë°ì´í„°ëŠ” ì›ë¬¸ì„ ì§ì ‘ í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.")
        
        # êµì°¨ ì°¸ì¡° ì•ˆë‚´
        if 'ë¹„êµ' in query or 'ì°¨ì´' in query:
            enhancements.append("ğŸ”„ ì—°ë„ë³„ ë¹„êµë‚˜ ì˜ì—­ë³„ ë¹„êµê°€ í•„ìš”í•œ ê²½ìš°, ê³„íšì„œì™€ í‰ê°€ì„œë¥¼ êµì°¨ ì°¸ì¡°í•˜ì—¬ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•´ë“œë¦½ë‹ˆë‹¤.")
        
        # íŠ¹ì • í‚¤ì›Œë“œì— ë”°ë¥¸ ë‹´ë‹¹ë¶€ì„œ ì•ˆë‚´ ê°•í™”
        query_lower = query.lower()
        if any(keyword in query_lower for keyword in ['ë§Œì¡±ë„', 'í‰ê°€', 'ì„±ê³¼']):
            contact_info = "\n\nğŸ“ êµìœ¡í‰ê°€Â·ë§Œì¡±ë„ ê´€ë ¨ ìƒì„¸ ë¬¸ì˜: í‰ê°€ë¶„ì„ë‹´ë‹¹ (055-254-2022)"
        elif any(keyword in query_lower for keyword in ['ê³„íš', 'ì¼ì •', 'ê³¼ì •', 'ìš´ì˜']):
            contact_info = "\n\nğŸ“ êµìœ¡í›ˆë ¨ê³„íšÂ·ì¼ì • ê´€ë ¨ ìƒì„¸ ë¬¸ì˜: êµìœ¡ê¸°íšë‹´ë‹¹ (055-254-2052)"
        else:
            contact_info = "\n\nğŸ“ ë¬¸ì˜ì²˜:\nâ€¢ êµìœ¡í›ˆë ¨ê³„íšÂ·ì¼ì •: êµìœ¡ê¸°íšë‹´ë‹¹ (055-254-2052)\nâ€¢ êµìœ¡í‰ê°€Â·ë§Œì¡±ë„: í‰ê°€ë¶„ì„ë‹´ë‹¹ (055-254-2022)"
        
        # ì¶”ê°€ ì•ˆë‚´ì‚¬í•­ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ ì¶”ê°€
        if enhancements:
            enhanced_response = base_response + "\n\n=== ğŸ“Œ ì°¸ê³ ì‚¬í•­ ===\n" + "\n".join(enhancements)
            enhanced_response += contact_info
            return enhanced_response
        
        return base_response + contact_info

    def _generate_prompt(
        self,
        query: str,
        retrieved_docs: List[Tuple[TextChunk, float]]
    ) -> str:
        """
        base_handlerê°€ ìš”êµ¬í•˜ëŠ” ì¶”ìƒ ë©”ì„œë“œ êµ¬í˜„.
        - retrieved_docs: (TextChunk, score) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
        - format_context()ëŠ” (text, score, metadata) íŠœí”Œ ë¦¬ìŠ¤íŠ¸ë¥¼ ê¸°ëŒ€í•˜ë¯€ë¡œ ì–´ëŒ‘í„° ë³€í™˜ í•„ìš”
        """
        # 1) ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_prompt = self.get_system_prompt()

        # 2) ì»¨í…ìŠ¤íŠ¸ ë³€í™˜: TextChunk -> (text, score, metadata)
        try:
            context_tuples = [
                (doc.text, score, getattr(doc, "metadata", {}) or {})
                for (doc, score) in (retrieved_docs or [])
                if doc is not None
            ]
        except Exception:
            # ì•ˆì „ì¥ì¹˜: ë¬¸ì œê°€ ìƒê²¨ë„ ìµœì†Œí•œ ë¹ˆ ì»¨í…ìŠ¤íŠ¸ë¡œ ì§„í–‰
            context_tuples = []

        # 3) publish ì „ìš© ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ ìƒì„±
        context_block = self.format_context(context_tuples)

        # 4) ìµœì¢… í”„ë¡¬í”„íŠ¸ ê²°í•© (ìµœì†Œ í˜•íƒœ)
        prompt = (
            f"{system_prompt}\n\n"
            f"---\n"
            f"ì‚¬ìš©ì ì§ˆë¬¸:\n{query}\n\n"
            f"ì°¸ê³  ìë£Œ(ë°œí–‰ë¬¼):\n{context_block}\n\n"
            f"ì§€ì¹¨:\n"
            f"- ì œê³µëœ ê³µì‹ ë¬¸ì„œ ë‚´ ì •ë³´ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.\n"
            f"- ìˆ˜ì¹˜Â·ë‚ ì§œÂ·ëª…ì¹­ì€ ì›ë¬¸ ê·¸ëŒ€ë¡œ ì¸ìš©í•˜ì„¸ìš”.\n"
            f"- ë°˜ë“œì‹œ ë¬¸ì„œëª…ê³¼ í˜ì´ì§€ë¥¼ í•¨ê»˜ í‘œê¸°í•˜ì„¸ìš”. ì˜ˆ: (2025 êµìœ¡í›ˆë ¨ê³„íšì„œ p.15)\n"
        )
        return prompt

    
    def handle(self, request: QueryRequest) -> HandlerResponse:
        """
        publish ë„ë©”ì¸ íŠ¹í™” ì²˜ë¦¬
        ê¸°ë³¸ handle() í˜¸ì¶œ í›„ ë‹´ë‹¹ë¶€ì„œë³„ ì•ˆë‚´ ì •ë³´ ìë™ ì¶”ê°€
        """
        # ê¸°ë³¸ í•¸ë“¤ëŸ¬ ë¡œì§ ì‹¤í–‰
        response = super().handle(request)
        
        # QueryRequestì—ì„œ ì¿¼ë¦¬ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        query = getattr(request, 'query', None) or getattr(request, 'text', '')
        
        # publish ë„ë©”ì¸ íŠ¹í™”: ë‹´ë‹¹ë¶€ì„œë³„ ì•ˆë‚´ ì •ë³´ ë³´ê°•
        if response.confidence >= self.confidence_threshold:
            enhanced_answer = self._enhance_response_with_document_guidance(response.answer, query)
            response.answer = enhanced_answer
        
        return response



# ================================================================
# í…ŒìŠ¤íŠ¸ ì½”ë“œ (ê°œë°œìš©)
# ================================================================

if __name__ == "__main__":
    """publish_handler ê°œë°œ í…ŒìŠ¤íŠ¸"""
    print("ğŸ“š Publish Handler í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    test_queries = [
        "2025ë…„ êµìœ¡í›ˆë ¨ ëª©í‘œê°€ ë­ì•¼?",  # êµìœ¡ê¸°íšë‹´ë‹¹
        "2024ë…„ êµìœ¡ì‹¤ì ì€ ì–´ë–»ê²Œ ë¼?",   # êµìœ¡ê¸°íšë‹´ë‹¹ 
        "êµìœ¡ê³¼ì • ìˆ˜ì™€ êµìœ¡ì¸ì› í†µê³„ ì•Œë ¤ì¤˜",  # êµìœ¡ê¸°íšë‹´ë‹¹
        "ì‘ë…„ ëŒ€ë¹„ ì˜¬í•´ ê³„íšì˜ ì°¨ì´ì ì€?",  # êµìœ¡ê¸°íšë‹´ë‹¹
        "êµìœ¡ë§Œì¡±ë„ í‰ê°€ê²°ê³¼ëŠ” ì–´ë–¤ê°€ìš”?",  # í‰ê°€ë¶„ì„ë‹´ë‹¹
        "ì„±ê³¼ ë¶„ì„ ê²°ê³¼ëŠ” ì–´ë–»ê²Œ ë‚˜ì™”ë‚˜ìš”?",  # í‰ê°€ë¶„ì„ë‹´ë‹¹
        "ì—­ëŸ‰ì§„ë‹¨ ê²°ê³¼ë¥¼ ì•Œê³  ì‹¶ìŠµë‹ˆë‹¤",  # í‰ê°€ë¶„ì„ë‹´ë‹¹
    ]
    
    handler = publish_handler()
    
    for i, query in enumerate(test_queries, 1):
        print(f"\n=== í…ŒìŠ¤íŠ¸ {i}: {query} ===")
        
        try:
            from utils.contracts import QueryRequest
            import uuid
            
            request = QueryRequest(
                text=query,
                context=None,
                follow_up=False,
                trace_id=str(uuid.uuid4())
            )
            
            response = handler.handle(request)
            print(f"ì‘ë‹µ: {response.answer}")
            print(f"ì»¨í”¼ë˜ìŠ¤: {response.confidence:.3f}")
            print(f"ì†Œìš”ì‹œê°„: {response.elapsed_ms}ms")
            print(f"Citation ìˆ˜: {len(response.citations)}")
            
        except Exception as e:
            print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
    
    print("\nâœ… ë°œí–‰ë¬¼ í•¸ë“¤ëŸ¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
