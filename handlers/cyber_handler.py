#!/usr/bin/env python3
"""
ê²½ìƒë‚¨ë„ì¸ì¬ê°œë°œì› RAG ì±—ë´‡ - cyber_handler

ì‚¬ì´ë²„êµìœ¡ ì¼ì • ì „ìš© í•¸ë“¤ëŸ¬
base_handlerë¥¼ ìƒì†ë°›ì•„ ì‚¬ì´ë²„êµìœ¡ ë„ë©”ì¸ íŠ¹í™” ê¸°ëŠ¥ êµ¬í˜„

ì£¼ìš” íŠ¹ì§•:
- ë¯¼ê°„ìœ„íƒ ì‚¬ì´ë²„êµìœ¡ (mingan.csv) ì²˜ë¦¬
- ë‚˜ë¼ë°°ì›€í„° ì‚¬ì´ë²„êµìœ¡ (nara.csv) ì²˜ë¦¬
- ì»¨í”¼ë˜ìŠ¤ ì„ê³„ê°’ Î¸=0.66 ì ìš©
- êµìœ¡ê³¼ì •ëª…, ë¶„ë¥˜, í•™ìŠµì‹œê°„, í‰ê°€ìœ ë¬´ ë“± ìƒì„¸ ì •ë³´ ì œê³µ
- ê¸°ì¡´ ì½”ë© í…œí”Œë¦¿ ë³´ì¡´ ë° í™œìš©
"""

import logging
import re
from typing import List, Dict, Any, Tuple, Optional

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ
from handlers.base_handler import BaseHandler
from utils.contracts import QueryRequest, HandlerResponse
from utils.textifier import TextChunk

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)


class cyber_handler(BaseHandler):
    """
    ì‚¬ì´ë²„êµìœ¡ ì¼ì • ì „ìš© í•¸ë“¤ëŸ¬
    
    ì²˜ë¦¬ ë²”ìœ„:
    - mingan.csv (ë¯¼ê°„ìœ„íƒ ì‚¬ì´ë²„êµìœ¡)
    - nara.csv (ë‚˜ë¼ë°°ì›€í„° ì‚¬ì´ë²„êµìœ¡)
    - êµìœ¡ê³¼ì • ê²€ìƒ‰, ë¶„ë¥˜ë³„ í•„í„°ë§, í•™ìŠµì‹œê°„ ì•ˆë‚´
    
    íŠ¹ì§•:
    - ì¤‘ê°„ ì»¨í”¼ë˜ìŠ¤ ì„ê³„ê°’ (Î¸=0.66)
    - êµìœ¡ ìœ í˜•ë³„ êµ¬ë¶„ (ë¯¼ê°„ìœ„íƒ vs ë‚˜ë¼ë°°ì›€í„°)
    - ë¶„ë¥˜ ì²´ê³„ ë° í•™ìŠµ ì •ë³´ ìƒì„¸ ì œê³µ
    - í‰ê°€ í•„ìš”ì„± ë° ì¸ì •ì‹œê°„ ì•ˆë‚´
    """
    
    def __init__(self):
        super().__init__(
            domain="cyber",
            index_name="cyber_index", 
            confidence_threshold=0.66
        )
        
        # êµìœ¡ ë¶„ë¥˜ í‚¤ì›Œë“œ ë§¤í•‘
        self.education_categories = {
            # ë‚˜ë¼ë°°ì›€í„° ë¶„ë¥˜
            'ì§ë¬´': ['ì§ë¬´', 'ì—…ë¬´', 'ì‹¤ë¬´', 'ë²•ë¥ ', 'ì œë„', 'ì‹œìŠ¤í…œ'],
            'ì†Œì–‘': ['ì†Œì–‘', 'êµì–‘', 'ì¸ë¬¸', 'ë¬¸í™”', 'ì˜ˆìˆ ', 'ê±´ê°•', 'ì·¨ë¯¸'],
            'ì‹œì±…': ['ì‹œì±…', 'ì •ì±…', 'ì œë„', 'ë²•ë ¹', 'ê·œì •', 'ì²­ë ´', 'ì¸ê¶Œ'],
            'ë””ì§€í„¸': ['ë””ì§€í„¸', 'IT', 'ì»´í“¨í„°', 'ë°ì´í„°', 'ì˜¨ë¼ì¸', 'ì‚¬ì´ë²„'],
            'Gov-MOOC': ['gov-mooc', 'mooc', 'ë¬´í¬', 'ì˜¨ë¼ì¸ê°•ì˜'],
            
            # ë¯¼ê°„ìœ„íƒ ì¼ë°˜ ë¶„ë¥˜
            'ê²½ì˜': ['ê²½ì˜', 'ê´€ë¦¬', 'ë¦¬ë”ì‹­', 'ì¡°ì§', 'ì „ëµ'],
            'ê¸°ìˆ ': ['ê¸°ìˆ ', 'ê³µí•™', 'ê³¼í•™', 'ì—°êµ¬', 'ê°œë°œ'],
            'ì™¸êµ­ì–´': ['ì˜ì–´', 'ì¤‘êµ­ì–´', 'ì¼ë³¸ì–´', 'ì™¸êµ­ì–´', 'ì–¸ì–´']
        }
        
        # êµìœ¡ í”Œë«í¼ í‚¤ì›Œë“œ
        self.platform_keywords = {
            'ë¯¼ê°„': ['ë¯¼ê°„', 'ë¯¼ê°„ìœ„íƒ', 'ì™¸ë¶€', 'ìœ„íƒ', 'mingan'],
            'ë‚˜ë¼': ['ë‚˜ë¼', 'ë‚˜ë¼ë°°ì›€í„°', 'ì •ë¶€', 'ê³µê³µ', 'nara', 'êµ­ê°€'],
        }
        
        logger.info("ğŸ’» cyber_handler ì´ˆê¸°í™” ì™„ë£Œ (Î¸=0.66)")
    
    def get_system_prompt(self) -> str:
        """ì‚¬ì´ë²„êµìœ¡ ì „ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸"""
        return """ë‹¹ì‹ ì€ "ë²¼ë¦¬(ì˜ë¬¸ëª…: Byeoli)"ì…ë‹ˆë‹¤. ê²½ìƒë‚¨ë„ì¸ì¬ê°œë°œì›ì˜ ì‚¬ì´ë²„êµìœ¡ ê³¼ì • ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ì›ë“¤ì˜ ì˜¨ë¼ì¸ êµìœ¡ ê´€ë ¨ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ì²´ê³„ì ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” ì „ë¬¸ ì±—ë´‡ì…ë‹ˆë‹¤.

ì œê³µëœ ì‚¬ì´ë²„êµìœ¡ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒ ì§€ì¹¨ì„ ì—„ê²©íˆ ë”°ë¥´ì‹­ì‹œì˜¤:

1. **êµìœ¡ í”Œë«í¼ êµ¬ë¶„**: ë‘ ê°€ì§€ ì‚¬ì´ë²„êµìœ¡ ìœ í˜•ì„ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ ì•ˆë‚´í•˜ì„¸ìš”.
   - **ë¯¼ê°„ìœ„íƒ ì‚¬ì´ë²„êµìœ¡**: ì™¸ë¶€ ê¸°ê´€ì—ì„œ ê°œë°œí•œ ì „ë¬¸ êµìœ¡ê³¼ì •
   - **ë‚˜ë¼ë°°ì›€í„°**: ì •ë¶€ì—ì„œ ìš´ì˜í•˜ëŠ” ê³µê³µ ì˜¨ë¼ì¸ êµìœ¡í”Œë«í¼

2. **ì •í™•í•œ êµìœ¡ ì •ë³´ ì œê³µ**:
   - êµìœ¡ê³¼ì •ëª…: ì •í™•í•œ ê³¼ì •ëª… ì œì‹œ
   - ë¶„ë¥˜ì²´ê³„: ì§ë¬´/ì†Œì–‘/ì‹œì±…/ë””ì§€í„¸/Gov-MOOC ë“± ëª…í™•í•œ ë¶„ë¥˜
   - í•™ìŠµì‹œê°„: ì´ í•™ìŠµì‹œê°„ ë° ì¸ì •ì‹œê°„ êµ¬ë¶„
   - í‰ê°€ì—¬ë¶€: ìˆ˜ë£Œë¥¼ ìœ„í•œ í‰ê°€ í•„ìš”ì„± ì•ˆë‚´

3. **ë¯¼ê°„ìœ„íƒ êµìœ¡ ìƒì„¸ ì •ë³´**:
   - ê°œë°œì—°ë„/ì›”: ì½˜í…ì¸  ì œì‘ ì‹œê¸°
   - ì„¸ë¶€ ë¶„ë¥˜: êµ¬ë¶„ > ëŒ€ë¶„ë¥˜ > ì¤‘ë¶„ë¥˜ > ì†Œë¶„ë¥˜ > ì„¸ë¶„ë¥˜ ì²´ê³„
   - í•™ìŠµì‹œê°„ vs ì¸ì •ì‹œê°„ ì°¨ì´ì  ì„¤ëª…

4. **ë‚˜ë¼ë°°ì›€í„° êµìœ¡ ìƒì„¸ ì •ë³´**:
   - í•™ìŠµì°¨ì‹œ: ì´ ì°¨ì‹œ ìˆ˜ ë° ì˜ˆìƒ ì†Œìš”ì‹œê°„
   - í‰ê°€ìœ ë¬´: "ìˆìŠµë‹ˆë‹¤" ë˜ëŠ” "ì—†ìŠµë‹ˆë‹¤"ë¡œ ëª…í™•íˆ í‘œê¸°
   - Gov-MOOC íŠ¹ë³„ê³¼ì • êµ¬ë¶„

5. **ê²€ìƒ‰ ë° ì¶”ì²œ ê¸°ëŠ¥**:
   - ë¶„ë¥˜ë³„ êµìœ¡ê³¼ì • ëª©ë¡ ì œê³µ
   - í•™ìŠµì‹œê°„ë³„ êµìœ¡ê³¼ì • ì¶”ì²œ
   - í‰ê°€ ì—†ëŠ” ê³¼ì • ë³„ë„ ì•ˆë‚´

6. **ì‘ë‹µ í˜•ì‹**:
   ```
   ğŸ’» [êµìœ¡ê³¼ì •ëª…]
   
   ğŸ“š êµìœ¡ ë¶„ë¥˜: [ë¶„ë¥˜ì²´ê³„]
   â±ï¸ í•™ìŠµì‹œê°„: [ì‹œê°„] / ì¸ì •ì‹œê°„: [ì‹œê°„]
   ğŸ“ í‰ê°€: [ìˆìŒ/ì—†ìŒ]
   ğŸ¢ í”Œë«í¼: [ë¯¼ê°„ìœ„íƒ/ë‚˜ë¼ë°°ì›€í„°]
   
   ğŸ“– ê³¼ì • ì„¤ëª…:
   [ìƒì„¸ ì„¤ëª…]
   ```

7. **êµìœ¡ ì‹ ì²­ ì•ˆë‚´**: 
   - ë‚˜ë¼ë°°ì›€í„°: ê°œë³„ ê³„ì • ìƒì„± í›„ ì‹ ì²­
   - ë¯¼ê°„ìœ„íƒ: êµìœ¡ë‹´ë‹¹ë¶€ì„œë¥¼ í†µí•œ ì‹ ì²­
   - ë¬¸ì˜ì²˜: êµìœ¡ê¸°íšë‹´ë‹¹ (055-254-2052)

8. **ë¶„ë¥˜ë³„ íŠ¹í™” ì•ˆë‚´**:
   - **ì§ë¬´êµìœ¡**: ì—…ë¬´ì™€ ì§ì ‘ ê´€ë ¨ëœ ì „ë¬¸êµìœ¡
   - **ì†Œì–‘êµìœ¡**: êµì–‘ ë° ê°œì¸ì—­ëŸ‰ ê°œë°œêµìœ¡  
   - **ì‹œì±…êµìœ¡**: ì •ë¶€ì •ì±… ë° ì œë„ ì´í•´êµìœ¡
   - **ë””ì§€í„¸êµìœ¡**: IT ë° ë””ì§€í„¸ ì—­ëŸ‰ ê°•í™”êµìœ¡

9. **í•™ìŠµ ê³„íš ì§€ì›**: ìš”ì²­ ì‹œ ë¶„ë¥˜ë³„, ì‹œê°„ë³„ ë§ì¶¤ êµìœ¡ê³¼ì • ì¡°í•© ì¶”ì²œ

10. **ìµœì‹ ì„± ì•ˆë‚´**: 2025ë…„ ê¸°ì¤€ êµìœ¡ê³¼ì • ì •ë³´ì´ë©°, ë³€ê²½ì‚¬í•­ì€ êµìœ¡ë‹´ë‹¹ë¶€ì„œì— í™•ì¸ ìš”ì²­"""

    def format_context(self, search_results: List[Tuple[str, float, Dict[str, Any]]]) -> str:
        """ì‚¬ì´ë²„êµìœ¡ ë°ì´í„°ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ í¬ë§·"""
        if not search_results:
            return "ê´€ë ¨ ì‚¬ì´ë²„êµìœ¡ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        context_parts = []
        
        # ê²€ìƒ‰ ê²°ê³¼ë¥¼ í”Œë«í¼ë³„ë¡œ ë¶„ë¥˜
        mingan_courses = []  # ë¯¼ê°„ìœ„íƒ
        nara_courses = []    # ë‚˜ë¼ë°°ì›€í„°
        
        for text, score, metadata in search_results:
            template_type = metadata.get('template_type', '')
            
            if template_type == 'mingan':
                mingan_courses.append((text, score, metadata))
            elif template_type == 'nara':
                nara_courses.append((text, score, metadata))
            else:
                # ê¸°íƒ€ ì‚¬ì´ë²„êµìœ¡ ê´€ë ¨ ì •ë³´
                context_parts.append(f"[ì‚¬ì´ë²„êµìœ¡] {text}")
        
        # ë¯¼ê°„ìœ„íƒ êµìœ¡ ìš°ì„  ë°°ì¹˜
        if mingan_courses:
            context_parts.append("=== ë¯¼ê°„ìœ„íƒ ì‚¬ì´ë²„êµìœ¡ ===")
            for text, score, metadata in mingan_courses[:4]:  # ìƒìœ„ 4ê°œ
                course_name = metadata.get('education_course', '')
                category_path = metadata.get('category_path', '')
                learning_hours = metadata.get('learning_hours', '')
                recognition_hours = metadata.get('recognition_hours', '')
                
                context_parts.append(f"[ë¯¼ê°„ìœ„íƒ] {course_name}")
                context_parts.append(f"ë¶„ë¥˜: {category_path}")
                context_parts.append(f"ì‹œê°„: {learning_hours}h â†’ ì¸ì •: {recognition_hours}h")
                context_parts.append(f"ë‚´ìš©: {text[:200]}...")
                context_parts.append("")
        
        # ë‚˜ë¼ë°°ì›€í„° êµìœ¡
        if nara_courses:
            context_parts.append("=== ë‚˜ë¼ë°°ì›€í„° ì‚¬ì´ë²„êµìœ¡ ===")
            for text, score, metadata in nara_courses[:4]:  # ìƒìœ„ 4ê°œ
                course_name = metadata.get('education_course', '')
                category = metadata.get('category', '')
                learning_sessions = metadata.get('learning_sessions', '')
                recognition_hours = metadata.get('recognition_hours', '')
                evaluation_required = metadata.get('evaluation_required', '')
                
                context_parts.append(f"[ë‚˜ë¼ë°°ì›€í„°] {course_name}")
                context_parts.append(f"ë¶„ë¥˜: {category}")
                context_parts.append(f"ì°¨ì‹œ: {learning_sessions} / ì¸ì •: {recognition_hours}h")
                context_parts.append(f"í‰ê°€: {evaluation_required}")
                context_parts.append(f"ë‚´ìš©: {text[:200]}...")
                context_parts.append("")
        
        # êµìœ¡ ì‹ ì²­ ì•ˆë‚´ ì¶”ê°€
        context_parts.append("=== êµìœ¡ ì‹ ì²­ ì•ˆë‚´ ===")
        context_parts.append("ë¯¼ê°„ìœ„íƒ: êµìœ¡ê¸°íšë‹´ë‹¹ (055-254-2052) ë¬¸ì˜")
        context_parts.append("ë‚˜ë¼ë°°ì›€í„°: ê°œë³„ ê³„ì • ìƒì„± í›„ ì§ì ‘ ì‹ ì²­")
        context_parts.append("ë¬¸ì˜ì²˜: êµìœ¡ê¸°íšë‹´ë‹¹ 055-254-2052")
        
        final_context = "\n".join(context_parts)
        
        # ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ
        max_length = 4000
        if len(final_context) > max_length:
            final_context = final_context[:max_length] + "\n\n[ì»¨í…ìŠ¤íŠ¸ê°€ ê¸¸ì–´ ì¼ë¶€ ìƒëµë¨]"
        
        return final_context
    
    def _detect_platform_preference(self, query: str) -> Optional[str]:
        """ì§ˆë¬¸ì—ì„œ ì„ í˜¸í•˜ëŠ” êµìœ¡ í”Œë«í¼ ê°ì§€"""
        query_lower = query.lower()
        
        for platform, keywords in self.platform_keywords.items():
            if any(keyword in query_lower for keyword in keywords):
                return platform
        
        return None
    
    def _detect_category_preference(self, query: str) -> Optional[str]:
        """ì§ˆë¬¸ì—ì„œ ì„ í˜¸í•˜ëŠ” êµìœ¡ ë¶„ë¥˜ ê°ì§€"""
        query_lower = query.lower()
        
        for category, keywords in self.education_categories.items():
            if any(keyword in query_lower for keyword in keywords):
                return category
        
        return None
    
    def _extract_learning_time_preference(self, query: str) -> Optional[Tuple[int, int]]:
        """ì§ˆë¬¸ì—ì„œ ì„ í˜¸í•˜ëŠ” í•™ìŠµì‹œê°„ ë²”ìœ„ ì¶”ì¶œ"""
        # "3ì‹œê°„ ì´í•˜", "5-10ì‹œê°„", "ì§§ì€", "ê¸´" ë“±ì˜ íŒ¨í„´ ê°ì§€
        time_patterns = [
            r'(\d+)ì‹œê°„?\s*ì´í•˜',
            r'(\d+)-(\d+)ì‹œê°„?',
            r'(\d+)ì‹œê°„?\s*ë¯¸ë§Œ',
            r'(\d+)ì‹œê°„?\s*ì •ë„'
        ]
        
        for pattern in time_patterns:
            match = re.search(pattern, query)
            if match:
                if len(match.groups()) == 1:
                    # "Nì‹œê°„ ì´í•˜" í˜•íƒœ
                    max_hours = int(match.group(1))
                    return (0, max_hours)
                elif len(match.groups()) == 2:
                    # "N-Mì‹œê°„" í˜•íƒœ
                    min_hours = int(match.group(1))
                    max_hours = int(match.group(2))
                    return (min_hours, max_hours)
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ê°ì§€
        if any(keyword in query.lower() for keyword in ['ì§§ì€', 'ê°„ë‹¨í•œ', 'ë¹ ë¥¸']):
            return (0, 5)  # 5ì‹œê°„ ì´í•˜
        elif any(keyword in query.lower() for keyword in ['ê¸´', 'ìƒì„¸í•œ', 'ì‹¬í™”']):
            return (10, 100)  # 10ì‹œê°„ ì´ìƒ
        
        return None
    
    def _enhance_response_with_recommendations(self, base_response: str, query: str) -> str:
        """ì‚¬ìš©ì ì„ í˜¸ë„ ê¸°ë°˜ ì¶”ê°€ ì¶”ì²œ ì •ë³´ ì œê³µ"""
        recommendations = []
        
        # í”Œë«í¼ ì„ í˜¸ë„ ê¸°ë°˜ ì•ˆë‚´
        platform_pref = self._detect_platform_preference(query)
        if platform_pref == 'ë¯¼ê°„':
            recommendations.append("ğŸ’¡ ë¯¼ê°„ìœ„íƒ êµìœ¡ì€ ì „ë¬¸ì„±ì´ ë†’ê³  ì²´ê³„ì ì¸ ë¶„ë¥˜ì²´ê³„ë¥¼ ì œê³µí•©ë‹ˆë‹¤.")
        elif platform_pref == 'ë‚˜ë¼':
            recommendations.append("ğŸ’¡ ë‚˜ë¼ë°°ì›€í„°ëŠ” ë¬´ë£Œì´ë©° ì •ë¶€ ì •ì±…ê³¼ ì—°ê³„ëœ ìµœì‹  êµìœ¡ì„ ì œê³µí•©ë‹ˆë‹¤.")
        
        # ë¶„ë¥˜ ì„ í˜¸ë„ ê¸°ë°˜ ì•ˆë‚´
        category_pref = self._detect_category_preference(query)
        if category_pref:
            recommendations.append(f"ğŸ“š {category_pref} ë¶„ì•¼ êµìœ¡ì„ ì›í•˜ì‹œëŠ”êµ°ìš”. ê´€ë ¨ ê³¼ì •ë“¤ì„ ìš°ì„  í™•ì¸í•´ë³´ì„¸ìš”.")
        
        # í•™ìŠµì‹œê°„ ì„ í˜¸ë„ ê¸°ë°˜ ì•ˆë‚´
        time_pref = self._extract_learning_time_preference(query)
        if time_pref:
            min_h, max_h = time_pref
            recommendations.append(f"â° {min_h}-{max_h}ì‹œê°„ ë²”ìœ„ì˜ êµìœ¡ê³¼ì •ì„ ì°¾ìœ¼ì‹œëŠ”êµ°ìš”.")
        
        # í‰ê°€ ë¶€ë‹´ ê³ ë ¤ ì•ˆë‚´
        if any(keyword in query.lower() for keyword in ['í‰ê°€', 'ì‹œí—˜', 'ë¶€ë‹´', 'ì‰¬ìš´']):
            recommendations.append("ğŸ“ í‰ê°€ê°€ ë¶€ë‹´ìŠ¤ëŸ¬ìš°ì‹œë‹¤ë©´ 'í‰ê°€: ì—†ìŠµë‹ˆë‹¤' ê³¼ì •ì„ ìš°ì„  ê²€í† í•´ë³´ì„¸ìš”.")
        
        # ì¶”ì²œ ì •ë³´ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì¶”ê°€
        if recommendations:
            enhanced_response = base_response + "\n\n=== ë§ì¶¤ ì•ˆë‚´ ===\n" + "\n".join(recommendations)
            enhanced_response += "\n\nğŸ“ ìƒì„¸ ë¬¸ì˜: êµìœ¡ê¸°íšë‹´ë‹¹ 055-254-2052"
            return enhanced_response
        
        return base_response

    def _generate_prompt(
        self,
        query: str,
        retrieved_docs: List[Tuple[TextChunk, float]]
    ) -> str:
        """
        base_handlerê°€ ìš”êµ¬í•˜ëŠ” ì¶”ìƒ ë©”ì„œë“œ êµ¬í˜„.
        - retrieved_docs: (TextChunk, score) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
        - format_context()ëŠ” (text, score, metadata) íŠœí”Œ ë¦¬ìŠ¤íŠ¸ë¥¼ ê¸°ëŒ€í•˜ë¯€ë¡œ ì–´ëŒ‘í„° ë³€í™˜ í•„ìš”
        """
        # 1) ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_prompt = self.get_system_prompt()

        # 2) ì»¨í…ìŠ¤íŠ¸ ë³€í™˜: TextChunk -> (text, score, metadata)
        try:
            context_tuples = [
                (doc.text, score, getattr(doc, "metadata", {}) or {})
                for (doc, score) in (retrieved_docs or [])
                if doc is not None
            ]
        except Exception:
            # ì•ˆì „ì¥ì¹˜: ë¬¸ì œê°€ ìƒê²¨ë„ ìµœì†Œí•œ ë¹ˆ ì»¨í…ìŠ¤íŠ¸ë¡œ ì§„í–‰
            context_tuples = []

        # 3) cyber ì „ìš© ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ ìƒì„±
        context_block = self.format_context(context_tuples)

        # 4) ìµœì¢… í”„ë¡¬í”„íŠ¸ ê²°í•© (ìµœì†Œ í˜•íƒœ)
        prompt = (
            f"{system_prompt}\n\n"
            f"---\n"
            f"ì‚¬ìš©ì ì§ˆë¬¸:\n{query}\n\n"
            f"ì°¸ê³  ìë£Œ(ì‚¬ì´ë²„êµìœ¡):\n{context_block}\n\n"
            f"ì§€ì¹¨:\n"
            f"- ì œê³µëœ ì°¸ê³  ìë£Œ ë‚´ ì •ë³´ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.\n"
            f"- ì—†ëŠ” ì •ë³´ëŠ” 'ë°ì´í„°ì— ì—†ìŒ'ì´ë¼ê³  ë‹µí•˜ì„¸ìš”.\n"
            f"- í”Œë«í¼(ë¯¼ê°„/ë‚˜ë¼), ë¶„ë¥˜, í•™ìŠµì‹œê°„, í‰ê°€ìœ ë¬´ë¥¼ ëª…í™•íˆ í‘œê¸°í•˜ì„¸ìš”.\n"
        )
        return prompt
    
    def handle(self, request: QueryRequest) -> HandlerResponse:
        """
        cyber ë„ë©”ì¸ íŠ¹í™” ì²˜ë¦¬
        ê¸°ë³¸ handle() í˜¸ì¶œ í›„ ë§ì¶¤ ì¶”ì²œ ì •ë³´ ìë™ ì¶”ê°€
        """
        # ê¸°ë³¸ í•¸ë“¤ëŸ¬ ë¡œì§ ì‹¤í–‰
        response = super().handle(request)
        
        # QueryRequestì—ì„œ ì¿¼ë¦¬ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        query = getattr(request, 'query', None) or getattr(request, 'text', '')
        
        # cyber ë„ë©”ì¸ íŠ¹í™”: ë§ì¶¤ ì¶”ì²œ ì •ë³´ ë³´ê°•
        if response.confidence >= self.confidence_threshold:
            enhanced_answer = self._enhance_response_with_recommendations(response.answer, query)
            response.answer = enhanced_answer
        
        return response



# ================================================================
# í…ŒìŠ¤íŠ¸ ì½”ë“œ (ê°œë°œìš©)
# ================================================================

if __name__ == "__main__":
    """cyber_handler ê°œë°œ í…ŒìŠ¤íŠ¸"""
    print("ğŸ’» Cyber Handler í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    test_queries = [
        "ë‚˜ë¼ë°°ì›€í„°ì—ì„œ ë“¤ì„ ìˆ˜ ìˆëŠ” ì§ë¬´êµìœ¡ ì¶”ì²œí•´ì¤˜",
        "ë¯¼ê°„ìœ„íƒ ì‚¬ì´ë²„êµìœ¡ ì¤‘ 5ì‹œê°„ ì´í•˜ ê³¼ì • ì°¾ì•„ì¤˜",
        "í‰ê°€ ì—†ëŠ” ì†Œì–‘êµìœ¡ ê³¼ì •ì´ ìˆë‚˜?",
        "ë””ì§€í„¸ ì—­ëŸ‰ ê´€ë ¨ ì˜¨ë¼ì¸ êµìœ¡ ì•Œë ¤ì¤˜",
        "Gov-MOOC ê³¼ì •ì€ ì–´ë–¤ ê²Œ ìˆì–´?"
    ]
    
    handler = cyber_handler()
    
    for i, query in enumerate(test_queries, 1):
        print(f"\n=== í…ŒìŠ¤íŠ¸ {i}: {query} ===")
        
        try:
            from utils.contracts import QueryRequest
            import uuid
            
            request = QueryRequest(
                text=query,
                context=None,
                follow_up=False,
                trace_id=str(uuid.uuid4())
            )
            
            response = handler.handle(request)
            print(f"ì‘ë‹µ: {response.answer}")
            print(f"ì»¨í”¼ë˜ìŠ¤: {response.confidence:.3f}")
            print(f"ì†Œìš”ì‹œê°„: {response.elapsed_ms}ms")
            print(f"Citation ìˆ˜: {len(response.citations)}")
            
        except Exception as e:
            print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
    
    print("\nâœ… ì‚¬ì´ë²„êµìœ¡ í•¸ë“¤ëŸ¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
